2025-05-16 14:38:07 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-05-16 14:38:07 | INFO | tasks.main | Redis server not found, starting it now...
2025-05-16 14:38:17 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-05-16 14:38:17 | INFO | tasks.main | Redis server not found, starting it now...
2025-05-16 14:39:56 | INFO | tasks.setup | Installing Docker
2025-05-16 14:53:42 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-05-16 14:53:42 | INFO | tasks.main | Redis server not found, starting it now...
2025-05-19 10:54:28 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-05-19 10:54:28 | INFO | tasks.main | Redis server not found, starting it now...
2025-05-19 10:55:40 | INFO | __main__ | Starting chatbot with arguments: {
  "engine": "gpt-4o-mini",
  "do_refine": false,
  "corpus_id": "wikipedia_20250320",
  "retriever_endpoint": "https://search.genie.stanford.edu/wikipedia_20250320",
  "do_reranking": true,
  "query_pre_reranking_num": 20,
  "query_post_reranking_num": 3,
  "claim_pre_reranking_num": 10,
  "claim_post_reranking_num": 2,
  "quit_commands": [
    "quit",
    "q",
    "Exit",
    "exit"
  ]
}
2025-05-19 10:57:46 | INFO | pipelines.chatbot | Search queries: [
  "back propagation in neural networks",
  "back propagation algorithm"
]
2025-05-19 11:05:28 | INFO | pipelines.chatbot | Search queries: [
  "simplified explanation of backpropagation"
]
2025-05-19 11:05:45 | INFO | pipelines.chatbot | No search needed.
2025-05-19 11:06:01 | INFO | pipelines.chatbot | Search queries: [
  "backpropagation in Greek",
  "backpropagation neural networks Greek"
]
2025-05-19 11:11:21 | INFO | pipelines.chatbot | No search needed.
2025-05-19 11:39:33 | DEBUG | tasks.main | Redis server is already running.
2025-05-19 11:39:33 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-05-19 12:54:15 | DEBUG | tasks.main | Redis server is already running.
2025-05-19 12:54:15 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-05-19 12:54:39 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-05-19 12:58:30 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-05-19 12:58:45 | INFO | pipelines.chatbot | Search queries: [
  "who is Kyriakos Mitsotakis",
  "Mitsotakis biography"
]
2025-05-19 13:16:56 | INFO | database | Initializing Cosmos DB connection
2025-05-19 13:19:36 | INFO | database | Initializing Cosmos DB connection
2025-05-19 13:59:35 | INFO | database | Initializing Cosmos DB connection
2025-06-10 10:39:08 | INFO | tasks.main | Redis server not found, starting it now...
2025-06-10 10:39:08 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-06-10 10:49:34 | DEBUG | tasks.main | Redis server is already running.
2025-06-10 10:49:34 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-06-10 10:49:56 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-06-10 11:39:26 | DEBUG | tasks.main | Redis server is already running.
2025-06-10 11:39:26 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-06-10 11:43:45 | DEBUG | tasks.main | Redis server is already running.
2025-06-10 11:43:45 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-06-10 11:44:50 | DEBUG | tasks.main | Redis server is already running.
2025-06-10 11:44:50 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-06-10 11:45:40 | DEBUG | tasks.main | Redis server is already running.
2025-06-10 11:45:40 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-06-10 11:45:53 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-06-10 11:46:22 | INFO | pipelines.chatbot | Search queries: [
  "A* algorithm explanation",
  "A* algorithm applications",
  "A* algorithm in computer science"
]
2025-06-10 11:48:40 | INFO | pipelines.chatbot | Search queries: [
  "A* algorithm inventor"
]
2025-06-10 13:02:33 | INFO | database | Initializing Cosmos DB connection
2025-09-28 12:10:55 | DEBUG | tasks.main | Redis server is already running.
2025-09-28 12:10:55 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-09-28 12:11:36 | DEBUG | tasks.main | Redis server is already running.
2025-09-28 12:11:36 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-09-28 12:11:59 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-09-28 14:56:23 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-09-28 16:55:32 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-09-30 12:22:32 | DEBUG | tasks.main | Redis server is already running.
2025-09-30 12:22:32 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-09-30 12:23:49 | DEBUG | tasks.main | Redis server is already running.
2025-09-30 12:23:49 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-09-30 12:24:36 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-09-30 12:24:49 | INFO | pipelines.chatbot | Search queries: [
  "algorithms",
  "types of algorithms",
  "applications of algorithms"
]
2025-09-30 12:34:10 | INFO | database | Initializing Cosmos DB connection
2025-09-30 13:30:31 | DEBUG | tasks.main | Redis server is already running.
2025-09-30 13:30:31 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-09-30 13:30:43 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-12 11:23:14 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 11:23:15 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 11:23:15 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 11:23:39 | ERROR | tasks.docker_tasks | Failed to start text-embeddings-inference-0 container: 500 Server Error for http+docker://localhost/v1.49/containers/05780173c85d802c0ec1572b1c481ecd70a4fbbbf67612994afb68a5431416d5/start: Internal Server Error ("could not select device driver "" with capabilities: [[gpu]]")
2025-10-12 11:23:39 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 11:23:39 | DEBUG | utils.docker_utils | No container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 11:23:39 | ERROR | tasks.docker_tasks | Failed to create directory /home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index: [Errno 13] Permission denied: '/home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index'. Please ensure parent directories exist and have correct permissions.
2025-10-12 11:23:39 | ERROR | tasks.docker_tasks | Correct ownership required for qdrant_index. Aborting.
2025-10-12 11:41:45 | DEBUG | tasks.main | Redis server is already running.
2025-10-12 11:41:45 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 11:42:39 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 11:42:39 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 11:42:39 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 11:42:39 | ERROR | tasks.docker_tasks | Failed to start text-embeddings-inference-0 container: 500 Server Error for http+docker://localhost/v1.49/containers/6e761f7bdde594f7eccee425132e927cc748141d1adbc0720b3282e18ac0b2c4/start: Internal Server Error ("could not select device driver "" with capabilities: [[gpu]]")
2025-10-12 11:42:39 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 11:42:39 | DEBUG | utils.docker_utils | No container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 11:42:39 | ERROR | tasks.docker_tasks | Failed to create directory /home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index: [Errno 13] Permission denied: '/home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index'. Please ensure parent directories exist and have correct permissions.
2025-10-12 11:42:39 | ERROR | tasks.docker_tasks | Correct ownership required for qdrant_index. Aborting.
2025-10-12 11:43:06 | DEBUG | tasks.main | Redis server is already running.
2025-10-12 11:43:06 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 11:43:22 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 11:43:22 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 11:43:22 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 11:43:23 | ERROR | tasks.docker_tasks | Failed to start text-embeddings-inference-0 container: 500 Server Error for http+docker://localhost/v1.49/containers/8223f87666395654c0b4150786f55c9829d2bb90e66a96060bc4e8a7dbf9cb8c/start: Internal Server Error ("could not select device driver "" with capabilities: [[gpu]]")
2025-10-12 11:43:23 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 11:43:23 | DEBUG | utils.docker_utils | No container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 11:43:23 | ERROR | tasks.docker_tasks | Failed to create directory /home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index: [Errno 13] Permission denied: '/home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index'. Please ensure parent directories exist and have correct permissions.
2025-10-12 11:43:23 | ERROR | tasks.docker_tasks | Correct ownership required for qdrant_index. Aborting.
2025-10-12 12:28:52 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 12:28:52 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:28:52 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:29:05 | ERROR | tasks.docker_tasks | Failed to start text-embeddings-inference-0 container: 500 Server Error for http+docker://localhost/v1.49/containers/27c7a287bc44d72897575f99a80bb7f315f900b909cf00ff6f8056782e269df3/start: Internal Server Error ("failed to set up container networking: driver failed programming external connectivity on endpoint text-embedding-inference-v1.7.0-gpu0 (adfc11a8667c059b2618a223afa755ceaabd1dd24050bab4b284137696f9ab48): failed to bind host port for 0.0.0.0:6338:172.17.0.3:80/tcp: address already in use")
2025-10-12 12:29:05 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 12:29:05 | DEBUG | utils.docker_utils | No container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 12:29:05 | ERROR | tasks.docker_tasks | Failed to create directory /home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index: [Errno 13] Permission denied: '/home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_index'. Please ensure parent directories exist and have correct permissions.
2025-10-12 12:29:05 | ERROR | tasks.docker_tasks | Correct ownership required for qdrant_index. Aborting.
2025-10-12 12:31:07 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 12:31:07 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:31:07 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:31:08 | ERROR | tasks.docker_tasks | Failed to start text-embeddings-inference-0 container: 500 Server Error for http+docker://localhost/v1.49/containers/355f53c019a75574ce3867293eb929d63041bca49b51ac0ec86164b45202c10f/start: Internal Server Error ("failed to set up container networking: driver failed programming external connectivity on endpoint text-embedding-inference-v1.7.0-gpu0 (fb897a865288f07f7b68215acdab89b592386ab31a9550645c089df742ab915c): failed to bind host port for 0.0.0.0:6338:172.17.0.3:80/tcp: address already in use")
2025-10-12 12:31:08 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 12:31:08 | DEBUG | utils.docker_utils | No container found with the exact name 'qdrant-v1.13.6'.
2025-10-12 12:31:08 | INFO | tasks.docker_tasks | Created directory: /home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_snapshots
2025-10-12 12:31:08 | INFO | tasks.docker_tasks | Set ownership of /home/ubuntu/operations/chatbots/WikiChat/workdir/qdrant_snapshots to 1000:1000
2025-10-12 12:31:17 | INFO | tasks.docker_tasks | Container 'qdrant-v1.13.6' started, id=c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98
2025-10-12 12:31:17 | INFO | utils.docker_utils | Waiting for container 'qdrant-v1.13.6' to be ready (timeout: 600s)...
2025-10-12 12:31:19 | INFO | utils.docker_utils | Container 'qdrant-v1.13.6' new logs:
_                 _    
  __ _  __| |_ __ __ _ _ __ | |_  
 / _` |/ _` | '__/ _` | '_ \| __| 
| (_| | (_| | | | (_| | | | | |_  
 \__, |\__,_|_|  \__,_|_| |_|\__| 
    |_|                           

Version: 1.13.6
Access web UI at http://localhost:6333/dashboard

2025-10-12T12:31:17.575152Z  INFO storage::content_manager::consensus::persistent: Initializing new raft state at ./storage/raft_state.json    
2025-10-12T12:31:17.588653Z  INFO qdrant: Distributed mode disabled    
2025-10-12T12:31:17.588706Z  INFO qdrant: Telemetry reporting enabled, id: 4e540b2b-68ce-4790-802a-91e1451fa503    
2025-10-12T12:31:17.588749Z  INFO qdrant: Inference service is not configured.    
2025-10-12T12:31:17.590350Z  WARN qdrant::startup: Failed to create init file indicator: Read-only file system (os error 30)    
2025-10-12T12:31:17.595087Z  INFO qdrant::actix: TLS disabled for REST API    
2025-10-12T12:31:17.595359Z  INFO qdrant::actix: Qdrant HTTP listening on 6333    
2025-10-12T12:31:17.595440Z  INFO actix_server::builder: Starting 1 workers
2025-10-12T12:31:17.595469Z  INFO actix_server::server: Actix runtime found; starting in Actix runtime
2025-10-12T12:31:17.614661Z  INFO qdrant::tonic: Qdrant gRPC listening on 6334    
2025-10-12T12:31:17.614697Z  INFO qdrant::tonic: TLS disabled for gRPC API
2025-10-12 12:31:19 | INFO | utils.docker_utils | Container 'qdrant-v1.13.6' is ready.
2025-10-12 12:31:25 | INFO | retrieval.retrieval_commons | Did not find collection 'audio_segments_index' in VectorDB, creating it...
2025-10-12 12:31:25 | INFO | retrieval.retrieval_commons | Collection creation was successful
2025-10-12 12:32:19 | DEBUG | tasks.main | Redis server is already running.
2025-10-12 12:32:19 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 12:32:34 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 12:32:34 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:32:34 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:32:34 | INFO | tasks.docker_tasks | text-embeddings-inference-0 docker container started, id=1031a32aaaef1a5898206f31ef2545da74332a7ae8c1a8df4bcaafb93b9ee6d5
2025-10-12 12:32:34 | INFO | utils.docker_utils | Waiting for container 'text-embedding-inference-v1.7.0-gpu0' to be ready (timeout: 600s)...
2025-10-12 12:32:36 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:32:34.531946Z  INFO text_embeddings_router: router/src/main.rs:185: Args { model_id: "Sno******/*********-******-*****-*-v2.0", revision: None, tokenization_workers: Some(8), dtype: Some(Float32), pooling: None, max_concurrent_requests: 256, max_batch_tokens: 50000, max_batch_requests: None, max_client_batch_size: 128, auto_truncate: false, default_prompt_name: None, default_prompt: None, hf_api_token: None, hf_token: None, hostname: "0.0.0.0", port: 80, uds_path: "/tmp/text-embeddings-inference-server", huggingface_hub_cache: Some("/data"), payload_limit: 2000000, api_key: None, json_output: false, disable_spans: false, otlp_endpoint: None, otlp_service_name: "text-embeddings-inference.server", cors_allow_origin: None }
2025-10-12T12:32:34.746651Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:20: Starting download
2025-10-12T12:32:34.746683Z  INFO download_artifacts:download_pool_config: text_embeddings_core::download: core/src/download.rs:53: Downloading `1_Pooling/config.json`
2025-10-12T12:32:35.761792Z  INFO download_artifacts:download_new_st_config: text_embeddings_core::download: core/src/download.rs:77: Downloading `config_sentence_transformers.json`
2025-10-12T12:32:35.982964Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:40: Downloading `config.json`
2025-10-12T12:32:36.201512Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:43: Downloading `tokenizer.json`
2025-10-12 12:32:38 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:32:36.704066Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:47: Model artifacts downloaded in 1.957417071s
2025-10-12T12:32:37.700761Z  WARN text_embeddings_router: router/src/lib.rs:188: Could not find a Sentence Transformers config
2025-10-12T12:32:37.701019Z  INFO text_embeddings_router: router/src/lib.rs:192: Maximum number of tokens per request: 8192
2025-10-12T12:32:37.701088Z  INFO text_embeddings_core::tokenization: core/src/tokenization.rs:28: Starting 8 tokenization workers
2025-10-12 12:32:42 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:32:40.943165Z  INFO text_embeddings_router: router/src/lib.rs:234: Starting model backend
2025-10-12T12:32:40.944988Z  INFO text_embeddings_backend: backends/src/lib.rs:534: Downloading `model.onnx`
2025-10-12T12:32:41.054887Z  WARN text_embeddings_backend: backends/src/lib.rs:538: Could not download `model.onnx`: request error: HTTP status client error (404 Not Found) for url (https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0/resolve/main/model.onnx)
2025-10-12T12:32:41.054937Z  INFO text_embeddings_backend: backends/src/lib.rs:539: Downloading `onnx/model.onnx`
2025-10-12T12:32:41.309708Z  INFO text_embeddings_backend: backends/src/lib.rs:548: Downloading `model.onnx_data`
2025-10-12T12:32:41.418509Z  WARN text_embeddings_backend: backends/src/lib.rs:552: Could not download `model.onnx_data`: request error: HTTP status client error (404 Not Found) for url (https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0/resolve/main/model.onnx_data)
2025-10-12T12:32:41.418535Z  INFO text_embeddings_backend: backends/src/lib.rs:553: Downloading `onnx/model.onnx_data`
2025-10-12 12:33:28 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:33:26.904196Z  INFO text_embeddings_backend: backends/src/lib.rs:349: Model ONNX weights downloaded in 45.959206955s
2025-10-12 12:33:36 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:33:35.998720Z  WARN text_embeddings_router: router/src/lib.rs:262: Backend does not support a batch size > 8
2025-10-12T12:33:35.999596Z  WARN text_embeddings_router: router/src/lib.rs:263: forcing `max_batch_requests=8`
2025-10-12T12:33:36.016640Z  INFO text_embeddings_router::http::server: router/src/http/server.rs:1804: Starting HTTP server: 0.0.0.0:80
2025-10-12T12:33:36.016664Z  INFO text_embeddings_router::http::server: router/src/http/server.rs:1805: Ready
2025-10-12 12:33:36 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' is ready.
2025-10-12 12:33:37 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-12 12:33:37 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-12 12:43:56 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-12 12:43:57 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:43:57 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-12 12:43:57 | INFO | tasks.docker_tasks | text-embeddings-inference-0 docker container started, id=203f17ae604609c9248e0ee2f0b9cc45db5a3650b5b2638c830c3a1369490d01
2025-10-12 12:43:57 | INFO | utils.docker_utils | Waiting for container 'text-embedding-inference-v1.7.0-gpu0' to be ready (timeout: 600s)...
2025-10-12 12:43:59 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:43:57.592395Z  INFO text_embeddings_router: router/src/main.rs:185: Args { model_id: "Sno******/*********-******-*****-*-v2.0", revision: None, tokenization_workers: Some(8), dtype: Some(Float32), pooling: None, max_concurrent_requests: 256, max_batch_tokens: 50000, max_batch_requests: None, max_client_batch_size: 128, auto_truncate: false, default_prompt_name: None, default_prompt: None, hf_api_token: None, hf_token: None, hostname: "0.0.0.0", port: 80, uds_path: "/tmp/text-embeddings-inference-server", huggingface_hub_cache: Some("/data"), payload_limit: 2000000, api_key: None, json_output: false, disable_spans: false, otlp_endpoint: None, otlp_service_name: "text-embeddings-inference.server", cors_allow_origin: None }
2025-10-12T12:43:57.812065Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:20: Starting download
2025-10-12T12:43:57.812103Z  INFO download_artifacts:download_pool_config: text_embeddings_core::download: core/src/download.rs:53: Downloading `1_Pooling/config.json`
2025-10-12T12:43:58.625747Z  INFO download_artifacts:download_new_st_config: text_embeddings_core::download: core/src/download.rs:77: Downloading `config_sentence_transformers.json`
2025-10-12T12:43:58.625922Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:40: Downloading `config.json`
2025-10-12T12:43:58.625978Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:43: Downloading `tokenizer.json`
2025-10-12T12:43:58.626712Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:47: Model artifacts downloaded in 814.649401ms
2025-10-12 12:44:01 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:43:59.560825Z  WARN text_embeddings_router: router/src/lib.rs:188: Could not find a Sentence Transformers config
2025-10-12T12:43:59.560858Z  INFO text_embeddings_router: router/src/lib.rs:192: Maximum number of tokens per request: 8192
2025-10-12T12:43:59.561513Z  INFO text_embeddings_core::tokenization: core/src/tokenization.rs:28: Starting 8 tokenization workers
2025-10-12 12:44:03 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:44:02.683548Z  INFO text_embeddings_router: router/src/lib.rs:234: Starting model backend
2025-10-12T12:44:02.685612Z  INFO text_embeddings_backend: backends/src/lib.rs:534: Downloading `model.onnx`
2025-10-12T12:44:02.799120Z  WARN text_embeddings_backend: backends/src/lib.rs:538: Could not download `model.onnx`: request error: HTTP status client error (404 Not Found) for url (https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0/resolve/main/model.onnx)
2025-10-12T12:44:02.799243Z  INFO text_embeddings_backend: backends/src/lib.rs:539: Downloading `onnx/model.onnx`
2025-10-12T12:44:02.801411Z  INFO text_embeddings_backend: backends/src/lib.rs:548: Downloading `model.onnx_data`
2025-10-12T12:44:02.924439Z  WARN text_embeddings_backend: backends/src/lib.rs:552: Could not download `model.onnx_data`: request error: HTTP status client error (404 Not Found) for url (https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0/resolve/main/model.onnx_data)
2025-10-12T12:44:02.924468Z  INFO text_embeddings_backend: backends/src/lib.rs:553: Downloading `onnx/model.onnx_data`
2025-10-12T12:44:02.925612Z  INFO text_embeddings_backend: backends/src/lib.rs:349: Model ONNX weights downloaded in 240.001054ms
2025-10-12 12:44:13 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-12T12:44:12.067402Z  WARN text_embeddings_router: router/src/lib.rs:262: Backend does not support a batch size > 8
2025-10-12T12:44:12.068096Z  WARN text_embeddings_router: router/src/lib.rs:263: forcing `max_batch_requests=8`
2025-10-12T12:44:12.087927Z  INFO text_embeddings_router::http::server: router/src/http/server.rs:1804: Starting HTTP server: 0.0.0.0:80
2025-10-12T12:44:12.087954Z  INFO text_embeddings_router::http::server: router/src/http/server.rs:1805: Ready
2025-10-12 12:44:13 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' is ready.
2025-10-12 12:44:13 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-12 12:44:13 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 10:55:43 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 10:55:43 | DEBUG | utils.docker_utils | No *running* container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-16 10:55:43 | DEBUG | utils.docker_utils | No container found with the exact name 'text-embedding-inference-v1.7.0-gpu0'.
2025-10-16 10:55:44 | INFO | tasks.docker_tasks | text-embeddings-inference-0 docker container started, id=f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b
2025-10-16 10:55:44 | INFO | utils.docker_utils | Waiting for container 'text-embedding-inference-v1.7.0-gpu0' to be ready (timeout: 600s)...
2025-10-16 10:55:46 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-16T10:55:44.405090Z  INFO text_embeddings_router: router/src/main.rs:185: Args { model_id: "Sno******/*********-******-*****-*-v2.0", revision: None, tokenization_workers: Some(8), dtype: Some(Float32), pooling: None, max_concurrent_requests: 256, max_batch_tokens: 50000, max_batch_requests: None, max_client_batch_size: 128, auto_truncate: false, default_prompt_name: None, default_prompt: None, hf_api_token: None, hf_token: None, hostname: "0.0.0.0", port: 80, uds_path: "/tmp/text-embeddings-inference-server", huggingface_hub_cache: Some("/data"), payload_limit: 2000000, api_key: None, json_output: false, disable_spans: false, otlp_endpoint: None, otlp_service_name: "text-embeddings-inference.server", cors_allow_origin: None }
2025-10-16T10:55:44.625210Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:20: Starting download
2025-10-16T10:55:44.625476Z  INFO download_artifacts:download_pool_config: text_embeddings_core::download: core/src/download.rs:53: Downloading `1_Pooling/config.json`
2025-10-16T10:55:45.445654Z  INFO download_artifacts:download_new_st_config: text_embeddings_core::download: core/src/download.rs:77: Downloading `config_sentence_transformers.json`
2025-10-16T10:55:45.445748Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:40: Downloading `config.json`
2025-10-16T10:55:45.445775Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:43: Downloading `tokenizer.json`
2025-10-16T10:55:45.445807Z  INFO download_artifacts: text_embeddings_core::download: core/src/download.rs:47: Model artifacts downloaded in 820.602063ms
2025-10-16 10:55:48 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-16T10:55:46.423597Z  WARN text_embeddings_router: router/src/lib.rs:188: Could not find a Sentence Transformers config
2025-10-16T10:55:46.423628Z  INFO text_embeddings_router: router/src/lib.rs:192: Maximum number of tokens per request: 8192
2025-10-16T10:55:46.424298Z  INFO text_embeddings_core::tokenization: core/src/tokenization.rs:28: Starting 8 tokenization workers
2025-10-16 10:55:50 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-16T10:55:49.603259Z  INFO text_embeddings_router: router/src/lib.rs:234: Starting model backend
2025-10-16T10:55:49.604850Z  INFO text_embeddings_backend: backends/src/lib.rs:534: Downloading `model.onnx`
2025-10-16T10:55:49.719830Z  WARN text_embeddings_backend: backends/src/lib.rs:538: Could not download `model.onnx`: request error: HTTP status client error (404 Not Found) for url (https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0/resolve/main/model.onnx)
2025-10-16T10:55:49.720134Z  INFO text_embeddings_backend: backends/src/lib.rs:539: Downloading `onnx/model.onnx`
2025-10-16T10:55:49.721552Z  INFO text_embeddings_backend: backends/src/lib.rs:548: Downloading `model.onnx_data`
2025-10-16T10:55:49.856281Z  WARN text_embeddings_backend: backends/src/lib.rs:552: Could not download `model.onnx_data`: request error: HTTP status client error (404 Not Found) for url (https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0/resolve/main/model.onnx_data)
2025-10-16T10:55:49.856404Z  INFO text_embeddings_backend: backends/src/lib.rs:553: Downloading `onnx/model.onnx_data`
2025-10-16T10:55:49.857302Z  INFO text_embeddings_backend: backends/src/lib.rs:349: Model ONNX weights downloaded in 252.453495ms
2025-10-16 10:56:00 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' new logs:
2025-10-16T10:55:58.752200Z  WARN text_embeddings_router: router/src/lib.rs:262: Backend does not support a batch size > 8
2025-10-16T10:55:58.752244Z  WARN text_embeddings_router: router/src/lib.rs:263: forcing `max_batch_requests=8`
2025-10-16T10:55:58.758271Z  INFO text_embeddings_router::http::server: router/src/http/server.rs:1804: Starting HTTP server: 0.0.0.0:80
2025-10-16T10:55:58.758296Z  INFO text_embeddings_router::http::server: router/src/http/server.rs:1805: Ready
2025-10-16 10:56:00 | INFO | utils.docker_utils | Container 'text-embedding-inference-v1.7.0-gpu0' is ready.
2025-10-16 10:56:00 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 10:56:00 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 10:56:50 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 10:56:50 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 10:56:50 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 10:56:50 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 10:56:50 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 12:51:29 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 12:51:29 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 12:51:29 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 12:51:29 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 12:51:29 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 13:08:24 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 13:08:24 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 13:08:24 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 13:08:24 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 13:08:24 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 13:32:44 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 13:32:44 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 13:32:44 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 13:32:44 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 13:32:44 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 13:44:05 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 13:44:05 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 13:44:05 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 13:44:05 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 13:44:05 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 15:10:28 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 15:10:28 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 15:10:28 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 15:10:28 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 15:10:28 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 15:14:09 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 15:14:09 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 15:14:09 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 15:14:09 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 15:14:09 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-16 15:14:21 | INFO | retrieval.retrieval_commons | Did not find collection 'gpt_segments_index' in VectorDB, creating it...
2025-10-16 15:14:22 | INFO | retrieval.retrieval_commons | Collection creation was successful
2025-10-16 15:25:35 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-16 15:25:35 | DEBUG | utils.docker_utils | Found running container 'text-embedding-inference-v1.7.0-gpu0' (ID: f9f67f3b691ffba431e63efd47adc80c82a735c3392d0a0602aec1e70c97c44b).
2025-10-16 15:25:35 | INFO | tasks.docker_tasks | 'text-embedding-inference-0' docker container is already running.
2025-10-16 15:25:35 | DEBUG | utils.docker_utils | Found running container 'qdrant-v1.13.6' (ID: c3a29b022317f6ca9b08f7732145cd5137f39e3272ab7aa3c2edac72eb85df98).
2025-10-16 15:25:35 | INFO | tasks.docker_tasks | 'qdrant-v1.13.6' docker container is already running.
2025-10-18 11:01:53 | DEBUG | tasks.main | Redis server is already running.
2025-10-18 11:01:53 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-18 11:04:18 | DEBUG | tasks.main | Redis server is already running.
2025-10-18 11:04:18 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-18 11:04:40 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-18 11:04:52 | INFO | pipelines.chatbot | Search queries: [
  "what are algorithms",
  "types of algorithms",
  "applications of algorithms"
]
2025-10-18 11:07:28 | INFO | database | Initializing Cosmos DB connection
2025-10-18 11:27:05 | INFO | pipelines.chatbot | Search queries: [
  "definition of algorithms",
  "types of algorithms",
  "applications of algorithms"
]
2025-10-18 11:32:19 | INFO | pipelines.chatbot | Search queries: [
  "ethics in artificial intelligence",
  "ethical considerations in AI",
  "AI ethics guidelines"
]
2025-10-18 14:30:44 | INFO | pipelines.chatbot | Search queries: [
  "A* algorithm explanation",
  "A* search algorithm"
]
2025-10-18 16:16:09 | INFO | database | Initializing Cosmos DB connection
2025-10-19 01:22:06 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 09:52:00 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 13:08:50 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 13:08:50 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 13:09:31 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 15:44:46 | INFO | pipelines.chatbot | Search queries: [
  "What are algorithms?",
  "Types of algorithms",
  "How do algorithms work?"
]
2025-10-19 15:48:41 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 15:48:56 | INFO | pipelines.chatbot | Search queries: [
  "definition of computer science",
  "what is computer science?"
]
2025-10-19 15:50:47 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 15:50:47 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 15:51:37 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 15:51:44 | INFO | pipelines.chatbot | Search queries: [
  "definition of algorithms",
  "types of algorithms",
  "applications of algorithms"
]
2025-10-19 17:33:17 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 17:33:17 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 17:33:30 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 17:33:32 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 17:33:44 | INFO | pipelines.chatbot | Search queries: [
  "artificial intelligence overview",
  "history of artificial intelligence",
  "applications of artificial intelligence"
]
2025-10-19 17:55:13 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 17:55:13 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 17:55:23 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 17:55:26 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 17:55:39 | INFO | pipelines.chatbot | Search queries: [
  "definition of artificial intelligence",
  "what is artificial intelligence"
]
2025-10-19 18:14:55 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 18:14:55 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 18:15:10 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 18:15:10 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 18:15:18 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-19 19:38:57 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 19:38:57 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 19:39:08 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 19:39:10 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 19:39:32 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-19 21:49:01 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 21:49:01 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 21:52:05 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 21:52:09 | INFO | pipelines.chatbot | Search queries: [
  "What are algorithms?",
  "Types of algorithms",
  "How do algorithms work?"
]
2025-10-19 22:44:23 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 22:44:23 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 22:47:01 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 22:47:01 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 22:55:14 | DEBUG | tasks.main | Redis server is already running.
2025-10-19 22:55:14 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 22:55:38 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 22:55:50 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | retrieval 13)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | results
 Okay. On to the new stuff. So. I would like to tell you a little bit about what this funny animal artificial intelligence might be. And I'll reveal to you that we really, really don't know ourselves. And I'll try to answer these kind of questions. What is AI? What have we achieved? We're going to take a very quick walk through the topics we're going to cover this semester. And of course, with all that talent in the room, I'm going to make a very quick advertisement about this stuff. You can do research about in my group. There must be some advantage of me actually standing up in front of you. Good. So, what is AI? There's a couple of definitions. Wikipedia has one. AI is intelligence exhibited by machines. Big surprise. Now. Philostomies. Philosophically, that's fine. All right. It basically says it's artificial, i.e. exhibited by a machine. Intelligence. Now, if I told you here's the definition, go and build AI. Would you know what to do? No. I wouldn't either. All right. It's a nice definition. But it's not, if you think about it, operational. All right. There are definitions. There are definitions where you know exactly what to do. This one isn't one of those. You can find that beautiful or you can find it annoying. All right. So, there are other definitions. AI is a subfield of computer science that is concerned with automation of intelligent behavior. Now, that has a little bit more information. It basically says, truly or falsely, it's a field of computer science. Right? We're not building AI by teaching anthills to do certain things, which one could think is a good way of arriving at AI. And some people do think that. Right? You may have heard about swarm intelligence and all of those kind of things. That's not what we're doing. We're using computers. Helpful. But then the rest is kind of automation. Right? Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. A definition that I like is due to Elaine Rich, which says AI studies how we can make the computer do things that humans still do better at the moment. It's slightly more operational. It basically tells us what we don't have to do, i.e. what is not AI. Right? There are certain things like regulating the temperature in a room that a thermostat does very well, thank you very much. Right? So that's not AI. That's, I don't know, domestic engineering or whatever. There are a lot of, I've been advertising these seats in the front here without much success. But there is place here and you can actually reach it without climbing. You can reach it without sitting over anybody. Okay? So for some parts of AI, I'm going to adopt Elaine Rich's definition. It's slightly problematic. And that's also something you can like or not. But it describes reality pretty well. AI is... It's somewhat the study of problems that are just too hard to be actually solved. Right? We haven't solved the AI problem after 70 years of trying. The wonderful thing is we've developed loads of very, very useful stuff. Many of the things that we're calling computer science nowadays started out as AI. Right? Including things like functional programming languages. Right? That are just in the age of parallelism are making a great contribution. They were invented because the old imperative languages weren't actually cutting it when you were trying to build systems or programs that would build... Would build... Would build... Would build... Would build... Would build... Intelligent behavior. Intelligent behavior. Parallel programming was actually very much driven forward by AI. And many other things. We're going to see a couple this semester. Constraint programming. Constraint solving is an old AI problem. Planning, which some people think is no longer AI because we are pretty good at it. We're pretty good at planning stuff. You could not actually be successful in the Ukraine War if you didn't have very complex planning algorithms that tells you where to move your trucks and your tanks and all of those kind of things. They do it automatically. Scheduling is something that I still remember being done with... I think it was a computer science thing. I think it was a computer science thing. I think it was a computer science thing. I think it was a computer science thing. They had these wonderful big boards that had all these little loads and loads and loads of little tiny paper pockets in them and you could stick nice and colorful cards in them and then you would have people standing in front of this board for two weeks trying to schedule where which course went. We can do this now by pressing a button. Okay? So, all of those things which are now considered engineering and have been taken over by the engineers are not considered AI anymore. So AI is kind of always stuck in this corner of problems that are too hard to solve. I like that corner. The big problems still. We don't know how to solve them. We have lots of crazy ideas of how this might... And the instant we solve a problem, it automatically becomes computer science. It's like pathology in medicine. The department of therapy resistant cases. I think it's important. Okay. And we can have a lot of fun here. But, I think it's important. Okay. But, we also invent lots of things that later become really, really, really well understood as part of computer science. Right. So, this is a definition of AI. The main problem in this, and you will have noticed, is that the last definition here is the only one. That... I'm laughing right now. This is IT. The last... So if you believe that hemos, the first one was the yo-yo depression, right, ago a long time ago. And this is what boobs means then. To evaluate intelligence class. What Robinson has written about intelligence class. Now, right here. Here is time period that not all psychiatrists can follow. So, all of you can wanna adapt this. Then obviously Share practiced intelligence effectively here. What it should do no less, is to apply зал of intelligence classes... It is not a set list, but is still an integral part of the program and does effectively satisfy its use. We now we've got a final statement that points out what is intelligent. We don't have enough ideas to explain. This has to do, these are the images you see here, exist. You can define intelligence as... knowing what intelligence is, they'll tell you, I know it when I see it, but I cannot define it. Okay, and if you press them really hard about what intelligence is, then they say, well, it's that what an intelligence test measures. Right, you can pull your hair out at this answer. Right, so, but Elaine Rich's definition, and that's why I like it, actually gets by without saying anything about intelligence. So, we can also try and look at artificial intelligence by saying, well, what are the components of artificial intelligence? And I'm going to give you five that we're pretty sure are part of intelligence. Not all of them we thought would be there 50 years ago. So, one of the things that we do consider part of AI, and necessary and important component, is the ability to learn. Right, everything that we would probably call intelligence. Right, we'll see other things. The ability to learn has some kind of an ability to learn. Ambrose Cherlency, who's doing a lot of writing here, he's also on the Library ofction Board. Just some time ago, in the last session in university. I can tell you by looking in the round table at the UE steak, and all that stuff about magic and most of these details don't get in. One thing I remember from reading over work until now, even something like the meme 그 I learned in Poland, that isn gruenbos bora, is that if you put out more of those words as your report, right. So learning seems to be important. Inference. The ability to process knowledge and to come up with things we consider to be true or valid from other things that we consider true or valid is an important thing in AI. Humans do it.)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | results
 Of, um, rational agents. So remember, we're doing AI here. And traditionally, traditionally, the way an AI class starts is saying, let G be a grammar, blahdy blahdy blah. We're going to call this funny animal propositional logic and then da da da da da. Okay. And now, you can ask yourself, why am I hearing about this in an AI class? Let me tell you why. We're going to think of all of those things as the internals of an agent. Agents being the metaphor I want to use here, and in particular, rational agents. Now, I'm going to tell you what an agent is, and I'm going to tell you what rationality is. Just bear with me for a second. So, if we think again about our definition of AI, right? How we can make computer programs to do things that human beings can't do. How humans do better at the moment. And there's an interesting word here. Namely, the word do. The better is less important. So, really, there's this idea of doing stuff in there. And in particular, doing things better than humans. Right? You think probably before we do better than humans, we should try and do it like humans. Right? So, and there's another, there's kind of two things of doing. One is doing things physically. And the other thing is doing things mentally. Right? AKA, thinking. So, this basically gives us four ways of actually interpreting this. Right? We can think like humans, or act like humans. Or, and because like humans is very difficult to do, we can maybe have something, some kind of a computer science equivalent to that, that we can actually implement easier. That's what rationality is. So, the things we can do is we can build systems that think like humans, or think like humans. And that's what we're trying to do. So, we can do things that we can do, and we can do things that we can do, and we can do things that we can do, and we can do things that we can do, or think like humans, or think rationally, act like humans, or act rationally. And those are things that AI has actually been quite involved with over the decades. Right? So, there's a couple of, for each of these corners, there's a quote that you could go back to and read. So, we have, we have these four things. Acting humanly. That's indeed one of the first conceptions of AI that we have. It's essentially the Turing test. Alan Turing, one of the heroes of all of computer science, and math, I would say. The guy who cracked the enigma. You've probably seen the movie. If you haven't, it's a good watch. So, he also had this idea. He was a scientist, and he was a scientist, and he was a scientist, and he was, he was wondering, with very primitive computers as his only example, how would we actually find out that a machine is intelligent? And he basically proposed what we now think of as the Turing test, which is really about acting. They have this party game that you would be able to talk to somebody via a teletext, high technology at the time, and kind of write what we would think of as a chat over a wire into the next room. And so you can talk with a system, which might be an AI system or a human agent, and exchange messages about whatever. And if the human interrogator is about, who wants to find out whether the system is artificial or human, if they're wrong 50% of the time, then the system has to be called intelligent. Right? The difficult part and the topical part of this is, of course, you can talk about whatever you want. Right? And you can imagine already that this is very difficult to achieve. So, basically, he published a paper about that in 1950, and basically anticipated all the major arguments we've seen against AI, right? Man is... Humans are created by God, and God is not bound to the laws of computation and so on. Right? That's one argument. And all the arguments, and there are more, we've... He already discussed in this paper 72 years ago. And, of course, he also suggested all the major components of AI. And it has been estimated that a machine might have 30% of the chance to fool a lay person for 30... for five minutes, which was about right. I mean, all these chatbots, right? They can do... I mean, we get... We can generate papers by linguistic world models, world models that get accepted at conferences, which probably says more about the refereeing process than... than the AI. But... So, that's kind of... The idea here is acting humanly. That's the only thing we can judge via this setup, whether something acts in a chat humanly.)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | results
 So, also Sie sind alle hier, weil Sie Interesse haben oder die Vorlesung hören müssen am Thema KI, was ich persönlich sehr schön finde, weil es ein sehr spannendes Thema ist und Interesse ist ja immer gut. Also natürlich freue ich mich, wenn Sie hier sind, weil Sie hier sein wollen und nicht, weil Sie hier sein müssen. Der geplante Ablauf der Vorlesung der Themen wird so sein. Heute machen wir eine kurze Einführung. Ich hoffe, Sie verzeihen mir, dass es da jetzt noch nicht ans Eingemachte geht, aber ich finde, gerade beim Thema KI, gerade wenn Sie noch im ersten, zweiten Semester sind oder auch im sechsten Semester, also zumindest bei mir war es so, dass die Vorstellung von was KI ist, vielleicht ein bisschen davon abweicht, was KI wirklich ist und da hilft das Ganze ein bisschen in Perspektive zu setzen und mal einzuordnen, was die KI eigentlich ist, wo sie herkommt, wo sie gerade hingeht, damit sie auch hoffentlich keine falschen Erwartungen haben. Einfach, damit sie ein bisschen geerdet sind, was wir eigentlich machen wollen. Als zweites Kapitel oder als erstes inhaltliches, richtiges Kapitel geht es dann um intelligente Agenten. Das ist die Frage, was ist ein Agent, was ist intelligenter Agent. Abschnitt drei, danach kommen logische Agenten. Da werden wir ein bisschen Aussagenlogik machen und Prädikatenlogik und wie man damit intelligente Agenten, also die sich intelligent verhalten, programmieren kann. Danach kommt bäsische Wahrscheinlichkeit. Das haben Sie vielleicht schon in anderen Vorlesungen gehört, vielleicht auch nicht, deswegen wird es auf jeden Fall nochmal wiederholt und inwiefern man damit intelligentes Verhalten provozieren kann, sage ich mal. Danach kommt probabilistisches Schließen. Also schließen heißt hier Schlussfolger im englischen Reasoning, also wie man aufgrund von Wahrscheinlichkeiten Schlüsse ziehen kann, gute Schlüsse ziehen kann. Probabilistisches Schließen über Zeit, also wenn sich das Ganze noch zeitlich entwickelt und zum Schluss noch etwas lernen durch Beispiele. Das ist jetzt das quasi eine abgeschweckte Fassung, eine Einführung des Maschinenlernens und eine kurze Übersicht. Das heißt, die Leute, die Grundlagen des Maschinenlernens hören, werden das dann deutlicher oder intensiver gehört haben, aber da die Visual Computing Studierenden das noch nicht belegen können, wäre es ein bisschen unfair, ihnen das Fach vorzuhalten. Das heißt, da werden wir ein bisschen drauf eingehen. Oben stehen ganz groß geplante Themen. Das liegt daran, dass sich vielleicht im Laufe des Semesters aufgrund Ihres Feedbacks oder aufgrund von, sage ich mal, sich ergebenden Problemen oder auch Wünschen vielleicht noch ein paar Verschiebungen ergeben, aber das ist so der grobe Fahrplan und Änderungen sind vorbehalten. Das heißt, heute fangen wir erst mal an mit der philosophischen Frage, was ist Intelligenz? Und ich habe mir einfach mal den Spaß gemacht und habe gegoogelt und habe die Google Bilder so bemüht, einfach nach Intelligenz und geschaut, was da so rumkommt. Das war also vor circa einem Monat. Ja, und da sehen Sie ja vielleicht, was da, also das ist, schauen Sie erst mal nur auf die Bilder, jetzt nicht auf die Texte, aber ganz oft in den Gehirn, Zahnräder, Daten, also irgendwelche coolen Visualisierungen, aber ganz oft ist das Gehirn zu sehen. Und die Seiten unten sagen dann schon, also gibt es Intelligenz, IQ lässt sich verändern. Also, es gibt sehr viele verschiedene Dinge zum Thema Intelligenz. Und wenn wir jetzt mal fragen wollen, was Intelligenz ist, dann gibt es ein schönes Zitat von William Stern von 1912. Intelligenz ist die allgemeine Fähigkeit eines Individuums, sein Denken bewusst auf neue Forderungen einzustellen. Sie ist allgemeine geistige Anpassungsfähigkeit an neue Aufgaben und Bedingungen des Lebens. Das ist natürlich jetzt von 1912 eine sehr anthropozentrische Sichtweise auf Intelligenz. Natürlich hat man sich damals, die meisten sich nicht vorstellen können, dass Intelligenz auch mal künstlich sein könnte, aber Sie sehen hier schon, das sind Fähigkeiten, es ist Denken, neue Forderungen, Anpassungsfähigkeit, das sind so das, was immer vorkommt. Und ich gehe immer gern zu Wikipedia vor solche Definitionen, weil es sich einfach ausgestellt hat, dass Wikipedia oft die kürzesten und bekanntesten Zusammenfassungen für einen Begriff hat. Intelligenz ist in der Psychologie ein Sammelbegriff für die kognitive bzw. geistige Leistungsfähigkeit. Der Begriff bezeichnet vor allem die Fähigkeit, die Gesamtheit unterschiedlich ausgeprägter kognitiver Fähigkeiten zur Lösung eines logischen, sprachlichen, mathematischen oder sinnorientierten Problems einzusetzen. Da einzelne kognitive Fähigkeiten unterschiedlich stark ausgeprägt sein können, keine Einigkeit besteht, wie diese zu bestimmen und zu unterscheiden sind, gibt es keine allgemeingültige Definition der Intelligenz. Und der letzte Abschnitt ist wahrscheinlich das Wichtigste an der ganzen Sache. Es gibt keine allgemeingültige Definition. Auch der IQ, wir wissen es wahrscheinlich, es wird oft darüber gestritten, ob der IQ wirklich Intelligenz widerspiegelt und was er genau wieder zu interpretieren ist. Es gibt, die meisten Leute würden wahrscheinlich sagen, sie haben ein intuitives Verständnis davon, was Intelligenz ist, aber richtig definieren wird schwierig. Und das hängt auch damit zusammen, aus welchem Bereich sie kommen. Sie haben natürlich dann auch sprachliche Intelligenz, Sie haben es bestimmt schon mal gehört, logische Intelligenz, emotionale Intelligenz. Und es ist natürlich schwierig zu sagen, was künstliche Intelligenz ist, wenn man nicht genau weiß, was eigentlich natürliche Intelligenz ist. Da können Sie sich denken, dass wir uns hier auf die logischen mathematischen Aspekte konzentrieren und wir schauen mal, wo wir damit hinkommen. Was sind denn intelligente Leistungen? Vielleicht fangen wir mal so an. Jemand, der intelligent ist, sollte lernfähig sein. Also Lernen aus Erfahrung ist schon mal eine wichtige Eigenschaft. Anwenden von Wissen, im Prinzip ist es ja die Konsequenz von Lernen. Wenn Sie Wissen lernen und das Wissen anwenden sollen, dann ist es schon eine intelligente Leistung. Zielorientiertes Handeln, beziehungsweise Planen, also Sie haben ein Ziel und Sie arbeiten auf dieses Ziel hin, auf intelligente Art und Weise, also dass Sie das Ziel auch erreichen oder schnell erreichen. Kommunikation, das würde ich mal sagen, das bezieht sich vor allem auf die menschliche Kommunikation. Sie müssen, was Sie sagen wollen, verpacken, kodieren, irgendwie formulieren. Man muss es auch verstehen. Der Umgang mit Mehrdurchkeiten und Fehlern, das ist eine ganz wichtige Sache. Also die Folie habe ich jetzt nicht draufgebracht, aber eine Folie, die ich ganz oft auch im Studium gesehen habe, ist, wo Sie einen Text sehen und die Buchstaben oft vertauscht wurden. Oder Buchstaben wurden durch Zahlen ausgetauscht und trotzdem können es die meisten Leute lesen, weil wir gut mit Mehrdurchkeiten und Fehlern umgehen können. Unsere Gehirne können das gut kompensieren. Die Fähigkeit, auf neue Situationen reagieren zu können. Also wenn Sie nur das tun könnten, was man Ihnen vorher mal gesagt hat, dann wären Sie nicht so intelligent. Also in der Schule nennt man es auch Transfer. Also dass Sie auch Fähigkeiten auf Probleme anwenden können, die Sie vorher noch nicht gesehen haben. Einfach, weil Sie verallgemeinern können. Und natürlich das Zerlegen von komplexen Problemen und überschaubare Aufgaben. Das ist auch das im Prinzip, was Sie, wenn Sie mal Softwareentwickler oder Softwareingenieur werden, das ist ja nichts anderes. Sie haben ein großes Problem, Ihr Programm soll ein Problem lösen und das müssen Sie jetzt erstmal in kleine Teilprobleme zerlegen. Und alleine schon diese Fähigkeit, ein Problem in Teilprobleme zu zerlegen, benötigt schon Intelligenz. Wenn wir jetzt wissen wollen oder uns damit beschäftigen, was künstliche Intelligenz ist, dann haben wir auch erstmal die Definition, also einmal ist es ein Teilgebiet Informatik. Ich denke, das ist Ihnen auch allen klar, sonst wären Sie nicht hier. Dass ich mit der Automatisierung Verhaltens und dem maschinellen Lernen befasse. Der Begriff ist schwer definierbar, da es bereits an einer genauen Definition von Intelligenz mangelt, haben wir ja vorhin gesehen. Dennoch wird er in Forschung und Entwicklung verwendet. Meist bezeichnet künstliche Intelligenz den Versuch, bestimmte Entscheidungsstrukturen des Menschen nachzubilden, indem zum Beispiel ein Computer so gebaut und programmiert wird, dass er relativ eigenständig Probleme bearbeiten kann. Oftmals wird damit aber auch eine nachgeahmte Intelligenz bezeichnet, wobei durch Meist-Einfach-Algorithmen ein intelligentes Verhalten simuliert werden soll. Etwa bei Computergegnern und Computerspielen. Hier ist auch der letzte Punkt interessant. Es gibt auch Programme, die wirken nur intelligent, sie sind es aber nicht. Man kann darüber streiten, ob sie es sind und trotzdem erfüllen sie damit ihren Zweck. Also die künstliche Intelligenz bezieht sich nicht nur darauf, dass man eine intelligente Intelligenz erstellt, sondern auch nur vielleicht intelligentes Verhalten simuliert. Jetzt können wir natürlich sehr Philosoph darüber werden, wo der Unterschied ist. Aber vielleicht kommen wir später auch mal zu einem Beispiel, wenn wir so in die Richtung gehen, was es bedeuten würde, intelligentes Verhalten zu simulieren. Da sich diese Vorlesung an dem Lehrbuch orientiert, also wir können da jetzt dutzende verschiedene Wege finden, wie wir an das Thema rangehen und die Herangehensweise, die hier gewählt wird oder die wir jetzt wählen, ist über Agenten zu gehen, über den Menschen zu gehen und zu sagen, wir gehen von Menschen aus und sagen, also ist künstliche Intelligenz vielleicht menschlich zu denken? Also wir sagen, Computer sollen denken wie Menschen, im tatsächlichen Sinne. Und was heißt menschlich denken? Also hier steht zum Beispiel, Determination of activities that we associate with human thinking, activities such as decision making, problem solving and learning. Da haben sie dieselben Sachen, sehen sie wieder, also Entscheidungen, Entscheidungstreffen, also Entscheidungen machen, zu deutsch vielleicht hier Problemlösen und Lernen.)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | results
 Die Mitarbeiter wissen es immer besser. Und ich habe hier auch noch ein paar Sachen. Und alle Informationen über unsere Gruppe und so etwas finden sie auf Quark.info. Insbesondere auch die Notes der Vorlesung. Und so weiter. Was möchte ich heute machen? Ich möchte heute irgendwie sowas wie eine Motivation abgeben. Was ist KI? Was machen wir? Wie können wir darüber nachdenken? Was gibt es bereits? Wir werden Admin machen. Wie wird das mit den Noten funktionieren? Und so weiter und so fort. Und so ein bisschen würde ich Sie bitten mir darzulegen, was Sie alles schon wissen. So dass ich weiß, auf was ich aufbauen kann. Dann werden wir einen relativ kurzen Gang durch die Themengebiete machen. Und dann... werde ich so ein bisschen was über die Forschung, die wir in der KI an meinem... ... ich darf hier in Bayern nicht sagen... ... hier in meiner Arbeitskasse sagen. Okay? Was ist KI? Und natürlich guckt man immer erstmal bei Wikipedia. Und da findet man sowas wie Artificial Intelligence ist... ... Intelligenz von Maschinen. Okay? Wenn sich Maschinen intelligent zeigen, dann ist das künstliche Intelligenz. Es gibt massenhaft Definitionen für künstliche Intelligenz. Und wir werden durch einige so ein bisschen systematischer durchgehen. Andere Definitionen sagen, künstliche Intelligenz ist ein Teilgebiet der Informatik. Ähm... Das war nicht immer klar. Ich weiß noch, dass... ... es am Anfang für künstliche Intelligenz... ... große Schlachten gab, ob vielleicht die Informatik ein Teilgebiet der künstlichen Intelligenz sei. Man kann sich vorstellen, dass die Datenbanker das nicht so gut fanden. Und... Aber mittlerweile denkt man, das ist so ein Teilgebiet der... ... der Informatik. Das sich mit der Automatisierung... ... Intelligenz und Verhaltens... ... ähm... ... beschäftigt. Ja, die Frage ist natürlich... ... wir haben einmal künstliche Intelligenz im Wesentlichen erklärt durch natürliche Intelligenz und dann im Wesentlichen nochmal. Ähm... Was ist eigentlich Intelligenz? Wer von Ihnen hat eine Ahnung, was Intelligenz ist? ... ... ... ... Und ich hör immer mal wieder, dass jemand sagt ... ... der ist aber doof! Ja, doof ist typischerweise nicht intelligent. Ja, das heißt, wir haben eigentlich alle eine sehr gute Vorstellung, was intelligent ist. Ja? ... ... ... ... Wissen selbst zu generieren. Ja, das ist sicherlich eine gute Definition. Bezeichnet ist, dass selbst jemand wie die Psychologen Schwierigkeiten haben, offensichtlich Intelligenz zu definieren. Schwierig ist es auch, Pornografie zu definieren. Ein Senator in den USA hat mal gesagt, ich erkenne es, wenn ich sehe. Und das ist meistens so, was wir auch mit Intelligenz können. Wir können das relativ gut erkennen. Meistens wissen wir, dass dieses hier, ein Tisch, ist typischerweise nicht intelligent. Und ich nehme mal an, dass alle Sie hier, hier intelligent sind. Und man hört häufig von intelligenten Gebäuden. Ich persönlich bin da etwas skeptisch. Aber wir bewegen uns in einem Fach, in dem wir gar nicht so richtig wissen, worum es eigentlich so richtig geht. Und das ist eigentlich auch ganz schön. Denn man weiß nicht so genau, wie man Intelligenz definieren soll. Es scheint aber sehr wichtig zu sein, Intelligenz. Sonst wären Sie wahrscheinlich alle nicht hier an der Uni. Also das ist so ein Problem, mit dem wir uns hier stellen müssen. Und eine der schönen Sachen an der künstlichen Intelligenz ist, dass man einer Definition oder einem Verständnis von Intelligenz näher kommt. Dass künstliche Intelligenz auch dadurch Intelligenz ist, dass man eine Definition oder ein Verständnis von Intelligenz näher kommt. Und man kann Intelligenz erklären oder besser verstehen lassen, indem man versucht, Intelligenz nachzubauen. Und dann kann man einfach gewisse Definitionen und so etwas ausprobieren. Das ist wie wenn man ein Motorrad auseinander nimmt und es wieder zusammenbaut. Und dann sind irgendwie vier Schrauben übrig. Und es fährt trotzdem ganz prima. Dann weiß man, also diese vier Schrauben brauchte man nicht. Das kommt bei Motorrädern nicht so häufig vor. Aber bei der Intelligenz, angenommen, irgendjemand Kluges sagt, ja Intelligenz ist. Und dann kommt irgendwas. Und dann kann man das nachbauen. Und dann kann man gucken, ob irgendetwas übrig bleibt aus der Definition. Und wenn das nicht gebraucht wird, dann hat man diese Definition getestet. Und das ist für mich auch einer der Reize, die man haben kann an diesem Fach. Elaine Rich hat eine Definition, die einerseits sehr problematisch, andererseits sehr schön ist. Die sagt nämlich einfach, künstliche Intelligenz ist es, wenn man versucht, einem Computer Dinge machen zu lassen, die Menschen noch besser können. Ja, also wir sind uns ziemlich einig, Intelligenz ist etwas, was man besonders bei Menschen findet. Und viele Sachen können Computer besser als Menschen. Zum Beispiel Kopf rechnen. Ja, also wenn man die meisten von Ihnen, ich ganz besonders nicht, werden es nicht schaffen, zwei 10-stellige Zahlen zu multiplizieren im Kopf. Ja, das kann schon mein, ja meine Uhr jetzt gerade nicht, aber das kann schon der einfachste Computer. Ein Taschenrechner. Ein Taschenrechner kann das. Und zwar viel schneller als wir. Es gab eine Zeit, da war das ein Zeichen von Intelligenz, wenn man mit Zahlen gut umgehen konnte. Heutzutage hat sich das geändert. Sagt man, na ja, gut, kann ja sogar mein Taschenrechner. Intelligenz ist auch eine Sache, die, die, also die, was wir von Intelligenz verstehen, ist auch eine Sache, die sich, die sich eben durch die Beschäftigung mit der künstlichen Intelligenz sehr stark wandelt. Ja, Schachspiel war lange Zeit landläufig als ein sehr starkes Indiz für Intelligenz. Ja, das war zum Teil die Krönung der Intelligenz. Und dann, vor etwa 20 Jahren, hat ein Computer den Großmeister geschlagen. Ja, was heißt das jetzt für uns und unsere Intelligenz? Und seitdem denkt man, ja, so Schachspielen ist nur dann wirklich mit Intelligenz verbunden, wenn Menschen das machen. Deswegen muss ich sagen, mag ich diese Definition von Elaine Rich recht gerne. Man versucht irgendwie nachzubauen und zu verstehen, was Intelligenz ist mit Maschinen. Ja. Und versucht dadurch, dass man Sachen versteht, nämlich im Computer abbilden kann, ein genaueres Bild dadurch zu kriegen, was Intelligenz ist. Ja, was, was, was sind so die, die, die Teile, die wir brauchen, um ein Motorrad zusammenbauen? Und was sind die Sachen, die wir weglassen können? Ja. Was wir brauchen, ist auf jeden Fall landläufig. Das ist wahrscheinlich auch so Sachen, die Ihnen sofort einfallen würden. Ja, man muss lernen können für Intelligenz. Ja, und ich habe jetzt mal hier so ein Bildchen von so einem kleinen Kind dazu getan, weil wir Menschen, auch wenn wir intelligent sind und wir vermuten, dass wir schon zu Geburt intelligent sind, aber wir kommen relativ mit einem nahezu leeren Gehirn auf die Welt. Wir wissen nichts. Wir können nicht sprechen. Wir können nicht laufen. Ja. Wir haben keine Ahnung, was ein Computer ist. Und Autofahren können wir auch nicht. Ja. Aber alle diese Sachen kriegen wir auf die Dauer beigebracht oder lernen wir von selber. Und dann, irgendwann, ja, manche Leute sagen, wenn man seinen Doktor kriegt, andere Leute sagen, wenn man in die Schule kommt, dann ist man plötzlich intelligent. Ja, also Lernen ist irgendwie wichtig. Und doofe Leute, erkennt man, erkennt man typischerweise daran, dass sie nichts lernen. Ja, vorher nicht und nachher auch nicht. Eine andere Sache, die für's, die wichtig sind, ist Schlüsse ziehen. Ja. Schlüsse ziehen kann in verschiedensten Kontexten passieren. Ja, das ist in der Mathematikklausur, ja, da muss man irgendwie Sachen beweisen. Das ist sicherlich Schlüsse ziehen. Beim Schachspielen oder überhaupt spielen ziehen wir Schlüsse. Ja. Wenn einer von Ihnen hier rausgeht und nach einer Weile mit dem Stuhl wiederkommt, ja, dann ist gerade dieser Raum so gebaut, dass ich nicht sehen kann, was Sie da getan haben. Ja. Aber ich ziehe den Schluss, na ja, wahrscheinlich ist diese Person jetzt rausgegangen in einen anderen Zipfel. Ja. Oder in einen anderen Zippel, hat sich da einen Stuhl geholt und ist jetzt mit dem Stuhl wieder da. Ja. Ganz einfache Sache. Meine Katze kann's nicht, ja. Aber Hunde können sowas schon ansatzweise. Ja. Die verstehen, dass Leute sich nicht einfach in Luft auflösen, wenn ich sie nicht mehr sehen kann. Sondern, dass sie weitermachen und irgendwelche Dinge tun. Ja. Und dass es eine Welt außerhalb dessen gibt, was ich sehen kann. Ja. Dass es Schlüsse zieht. Oder auch einfach so etwas wie sehen. Fühlen, schmecken, riechen. Ja. Ähm. Es ist nicht so, dass unsere Augen einfach Kameras sind. Wie man am Anfang dachte. Sondern, dass das hochentwickelte neuronale Systeme sind. Also auch eine Linse und so ein Krempel. Aber, dass wir schon in der, in der Netzhaut, Verarbeitung machen. Dass wir zum Beispiel Linienerkenner und so etwas direkt in der Netzhaut haben. Im Auge. Und dass da gewisse Verarbeitung der Bildinformation geschieht, bevor das Ganze irgendwie hinten, nach hinten geleitet wird ins Gehirn. Ja. Dass wir relativ gut sehen können als Menschen. Und relativ schlecht riechen. Ja. Was macht das mit unserer Intelligenz? Was können wir da tun? Was sind die Grenzen? Wie können wir aus solchen Sachen, ähm, Schlüsse ziehen? Eine andere Sache, die sicherlich wichtig ist, ist Sprachverstehen. Zumindest soweit landläufig ist die Meinung, dass nur Menschen das tun. Manche Leute denken, sie könnten mit ihrem Hund reden. Und ähm, ähm, das können sie natürlich auch. Aber die Frage ist, was der versteht. Ähm, und Kommunikation von extrem komplexen Sachen über Sprache. Ja, wenn man sich jetzt mal wirklich vorstellt, was da passiert. Ja. Ich erzähle Ihnen ein, ein, etwas über künstliche Intelligenz. Und wenn man sich mal überlegt, was da passiert. Ja, da sind in meinem Kopf irgendwelche Bilder. Und ich serialisiere die in entweder einem, Sequenz von Schwingungen oder aber auch von Wörtern. Ja. Und über diesen doch sehr engen Kanal. Das sind nicht Terabit oder sowas. Ja, was, was für dieses sehr komplizierte und komplexe, äh, Sujet eigentlich das, das Richtige wäre. Und dann entstehen am anderen Ende in Ihren Gehirnen irgendwelche Bilder auch. Ja. Ja. Von komplexen Zusammenhängen. Und das Faszinierende ist, die sind auch noch ähnlich. Ja, sonst könnten wir uns das hier ganz sparen. Was ich ja eigentlich will, hier, und was Sie natürlich auch wollen, ist, dass irgendwie von den komplexen Zusammenhängen und Bildern und Wissen und so etwas von hier oben nach da oben, transportiert wird. Und im Prinzip das Einzige, was wir haben, ist Sprache. Na ja, gut, ab und zu mal ein Bild, aber das ist mehr so Dekoration. Das ist nicht so wichtig wie in der Biologie, wo es heißt, na, gucken Sie sich mal die Zelle an oder sowas. Wir machen hier das relativ stark sprachlich. Ja. Das heißt, wir machen ein komplexes multidimensionales Gebilde, linearisieren wir über ein eindimensionales Gebilde, und dann entstehen irgendwelche, also passieren irgendwelche magische Dinge in Ihren Köpfen, und Sie machen daraus wieder komplexe Zusammenhänge. Hoffe ich jedenfalls. Wissen tut man es natürlich nicht genau. Also, Sprachverstehen und natürlich Schlüssel ziehen darin und Sinneseindrücke, Sie müssen das Ganze ja auch erst hören, ähm, sind sehr, sehr wichtige Bausteine. Richtig. Perception. Ich versag jetzt immer hier drauf zu drücken. Sprachverstehen, ja, dass man miteinander kommunizieren kann. Und was richtig ist, ist, dass es nicht nur die Sprachproduktion ist, die hochgradig nicht trivial ist, auch das Sprachverstehen ist nicht trivial. Und die beiden hängen sehr stark miteinander zusammen. Ich werde mich bemühen, Sprache zu produzieren, von denen, von der ich antizipiere, dass Sie das auch verstehen können. Und dann kommt die ganze Ebene der Emotion. Ja, das, äh, gehört sicherlich auch zur künstlichen Intelligenz dazu. Ähm, wir sind noch relativ schlecht. Wir sind, können einigermaßen Emotionen aus, aus Texten identifizieren, ja. Krieg eine E-Mail, ist der jetzt wütend auf mich oder nicht? Ja. Oder was passiert hier eigentlich? Ist eigentlich ziemlich wichtig. Wir machen das mühelos. Ja. Maschinen haben das noch relativ, haben, haben das noch relativ schwer. Was wir, was wir noch gar nicht können, ist, dass sich ein Computer mal verliebt oder sowas, ja. Ähm, ist nicht klar, wie das geht. Gut. Ja, das ist jetzt so mal so, so, so ein erster Eindruck. Und sagen, was, was muss man überhaupt so als, als Teilfelder, ähm, verstehen. Und wenn man sich, ähm, ah, kann nur vorwärts, auch lustig. Gut, ähm, interessant ist, ist, die KI ist etwa 1950 gegründet worden, oder genau 1950, auf der Dartmouth Conference, ähm, gegründet worden. Wir haben jetzt 2016. Und, ähm, das heißt, Leute haben 50 Jahre daran gearbeitet. Was gibt's denn? Und warum braucht man dafür künstliche Intelligenz? Also, zum Beispiel so, ich, ich will dir einfach mal ein paar, ähm, Beispiele aufführen, ja. Ähm, natürlich wissen Sie alle, große Diskussion, selbstfahrende Autos. Ja, das ist künstliche Intelligenz. Ähm, nun ist es aber so, dass wir, in Erlangen brauchen wir keine selbstfahrenden Autos, weil die meisten Leute, die von A nach B mit dem Auto wollen, ähm, können das Ding selber fahren. Das stimmt nicht ganz, ja, es gibt viele Leute, die zu alt sind, die sollten ihren Führerschein abgeben, ähm, und wollen aber trotzdem noch von A nach B, da wären selbstfahrende Autos wunderbar. Ähm, wenn ich jetzt hier, ähm, wie heute Morgen geschehen, ähm, mit dem Auto zur Uni fahre, konnte leider nicht anders, ähm, dann hätte ich doch sehr gerne gehabt, dass das Auto mich an der Tür absetzt, und dann hätte ich ihm am liebsten gesagt, so, geh mal spielen, ja, oder geh mal einen Parkplatz finden, ja, so musste ich selber rumfahren, um den Parkplatz zu finden, und das war ziemlich lästig. Ähm, ja, da wär's. Aber zum Beispiel, wenn wir uns sagen, wenn wir, wenn wir, es gibt Situationen, da kommen wir gar nicht drum herum. Ja, wenn wir zum Beispiel eine Raumsonde irgendwie zum Jupiter senden, dann kann man die nicht mehr ordentlich fernsteuern. Warum nicht? Ja, weil die Signallaufzeiten einfach so lange sind, und, ähm, auch dieser Mars Rover hier, das ist, sind wir im Minutenbereich, im Hin und Her, wenn man den versuchen würde fernzusteuern, wäre der längst in die Schlucht gestürzt, oder müsste so langsam fahren, ja, dass der nach seinen, wie viel ist er jetzt unterwegs, 16 Jahren oder sowas, ähm, dass er immer noch irgendwie so in Sichtweite wäre. Ja, da muss man einfach, ähm, da braucht man Autonomie, da braucht man eigenes Steuern, ähm, um dann, ähm, die Systeme überhaupt vernünftig fahren zu können. Ja. Ähm. Wenn gewisse Fähigkeiten von Menschen eingeschränkt sind, zum Beispiel wenn der Arm ab ist, ja, dann möchte man trotzdem irgendwie, ähm, Dinge greifen können, man will sich einen Kaffee einschenken können, ähm, man will allerlei solche Dinge tun. Und da braucht man weitgehende Autonomie von diesen Prothesen, weil, wenn viele Dinge, die wir tun, ja, wenn wir Sachen anfassen, wenn wir Tischtennis spielen, wenn wir, ähm, eine heiße Herdplatte anfassen und so etwas, die passieren nicht hier oben. Das ist nicht irgendwie so, dass wir da, ähm, Deliberation und Schließen machen. Oh, mein Finger wird warm. Hm, was könnte das bedeuten? Ja. Oh, vielleicht mache ich mal lieber einen Rückzug, ja, viel zu langsam. Passiert hier irgendwo, ja, im Rückenmark oder so etwas. Viel schneller muss das Ganze gehen. Das heißt, wir haben auch da, haben wir Verarbeitung, relativ eingeschränkt, relativ einfach, ähm, die schon in, die schon, ähm, viel vor dem Gehirn passiert. Ja, wenn Sie sich vorstellen, dass wir gar keine Schwierigkeiten haben, ein Ei zu heben. Ja, war lange Zeit ein, ein in der Robotik ein, ein, ein Challenge-Thema, ähm, Eier zu heben. Denn Sie können sich vorstellen, dass so ein Industrie-Roboter, ja, der soll eigentlich, ähm, Bäche schweißen oder so etwas, und wenn der irgendwie ein Ei, ähm, versucht zu heben, ähm, dann, ja, dann, dann, dann, dann packt er zu fest zu. Ja, Menschen können sogar mit Eiern jonglieren. Nicht alle, ich nicht. Aber, ähm, aber wir können sie so fein anfassen. Und auch da geht es um Geschwindigkeit. Das heißt, wir haben, wir haben Verarbeitung, wir haben, ich möchte es nicht unbedingt Intelligenz nennen, ähm, und alle diese Sachen können wir jetzt. Wir können, wir haben Roboter, die Eier, bin mir nicht sicher über jonglieren, aber zumindest aus, aus, sortieren können und so etwas, ja. Ähm, und machen das nicht mehr so wie am Anfang, dass man das irgendwie durch irgendwie einen Saugnapf macht. Sondern die haben einfach Finger und können das. Ja. Also allerlei Dinge in der, grad, in der, grad, ähm, wenn es dann in die Robotik geht, und das ist eine Sache, die wir vorher überhaupt nicht verstanden haben, die, über die Intelligenz. Ja, dass es, dass es nicht trivial ist, ganz einfache Dinge zu machen, wie sich die Schuhe zu binden. Ja, das lernen wir als Kleinkinder. Ist das ein Roboter kann? Dauert. Ist das ein Roboter kann? Bei verschiedenfarbigen Schuhen und mit verschieden dicken Schnürbändern und so was? Nicht so einfach. Ja, künstliche Intelligenz. Sie haben sicher alle von dem Rumba gehört. Ähm, und der macht sauber, der kann, es gibt Versionen, die können wischen und so weiter und so fort. Ähm, und, ähm, der fährt auch immer, wenn er, ich muss sagen, hungrig ist, fährt er zur Ladestation und, ähm, holt sich wieder eine Menge Strom ab. Wenn er, wenn er voll ist, der Staubbeutel, dann deponiert er den irgendwo und so etwas. Ja. Ähm, funktioniert ganz gut. Außer, es gibt ein fantastisches Video von VW. Oder so was, wo, ähm, es in dem Haushalt irgendwie einen, ähm, einen jungen Hund gab, der noch nicht, ähm, noch nicht ordentlich, ähm, wie sagt man das? Jedenfalls hat er einen Haufen hinterlassen und den hat der Rumba gefunden. Und Sie können sich vorstellen, dass da sozusagen es Grenzen der Intelligenz gibt, die so ein Ding jetzt hat, ja. Ähm, ein Forschungsprojekt in Japan. Ähm, die haben immer so eine Vorliebe für interessante Farben. Ähm, ist es solche Sachen, die wir kein Problem mit haben, ja. Einfach eine Maschine aus, eine Spülmaschine auszuräumen, ohne alles hinzuschmeißen. Ja. Nicht so einfach. Ja, das sind, das sind, ähm, das sind Sachen, ähm, die für eine bekannte Spülmaschine und Sie sehen, der hat's einfach gekriegt, ja. Die Teller haben alle verschiedene Farben. Ähm, das macht das einfacher, ohne dass die Menschen das sehen. Ja, wenn die, wenn, da kann man nämlich, was für ein Teller das ist, kann man dann in die Farbe kodieren und dann weiß der Roboter schon wieder besser, was er machen soll. Ja. Ähm, es ist immer noch ungelöst, wie wir, äh, das Problem, eine beliebige Spülmaschine, eine bekannte Spülmaschine ist gelöst. Eine beliebige Spülmaschine mit beliebigen Zeugs drin auszunehmen. Auszuräumen ist ein ungelöstes Problem. Ja. Für Roboter. Ich bin mir sicher, Sie können das alle. Ja. Gut. Was noch? Ja. Ähm, Roboter werden eingesetzt in Kliniken. In den USA werden 90% aller Prostata-Operationen von dem da gemacht. RoboDoc. Ähm, ich find's etwas scary. Ähm. Ähm. Ähm, ich weiß nicht, man sieht da unten die, die, jetzt tut's doch, jetzt sieht man, ich glaub das ist die Hand und der scheint auch irgendwie nicht so ganz so. Ähm, aber die können das besser als Menschen. Ja, das gibt's sozusagen ganz eng definierte Sachen, wo man sehr genau weiß, was die Ausgangslage ist. Können die das präziser? Ja. Ne andere Richtung, ähm, das ist der Paro. Dies hier sind drei Paros. Ähm, das ist so ein, also im Prinzip ein Schmuseroboter. Ja, der wird in der Altenpflege eingesetzt und, ähm, scheint enorme, ähm, enorme Erfolge zu haben. Leute, die keinen Besuch kriegen, die kriegen dann irgendwie einmal die Woche, kriegen die eine Stunde den Paro, dann können die den streicheln und wenn der gestreichelt wird, also der ist warm und dann wenn er gestreichelt wird, fängt der an so ein bisschen zu schnurren und sowas und macht mal ab und zu die Augen auf und zu und sowas und dann sind die Leute glücklich. Ja. Will ich später beparot werden? Ich weiß es nicht, ja, aber. Aber, aber, da diese Sachen sind im Einsatz. Ja. Ähm, überhaupt, so so hier die, die emotionale, diesen emotionalen Rückkopplungskreis hinreichend zu verstehen und dann in so einem Ding zu implementieren. Ja. zu implementieren, ist künstliche Intelligenz. Wo braucht man noch künstliche Intelligenz? Bei sehr vielen sicherheitsrelevanten Dingen ist künstliche Intelligenz drin. Also zum Beispiel ist es so, ich weiß nicht, erinnern Sie sich noch an das Pentium-Desaster von Intel? Das ist eine Weile her, aber irgendwann war es dann so, dass die Pentium-Chips, die haben in irgendeinem Fall falsch dividiert. Nicht oft, aber manchmal haben die eben falsch dividiert. Mit dem Erfolg, als das jemand rausgekriegt hatte, musste Intel aus jedem Computer, der einen Pentium-Chip hatte, den Chip rausnehmen und durch einen anderen. Ersetzen lassen. Rückrufeaktion. Kostete Milliarden. Ich glaube, es ist wohl eine Milliarde. Seitdem macht Intel folgendes. Seitdem haben die eine Reihe von KI-Forschern, die sich mit automatischen Beweisen oder halbautomatischen Beweisen auskennen. Also ein guter Kollege von mir leitet diese Gruppe. Und die beweisen den ganzen Micro-Code in ihren Karten. Und die beweisen ihren Chips als korrekt. Dass ihnen das nicht mehr passiert. Es ist immer noch billiger, KI-Forscher zu bezahlen, damit die das beweisen, dass nichts schief gehen kann, als immer mal wieder rückzubeziehen. Was sie sogar machen, ist, dass die C-Library für Intel-Prozessoren, die haben ja ihre eigene optimierte C-Library.)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | results
 So, also Sie sind alle hier, weil Sie Interesse haben oder die Vorlesung hören müssen am Thema KI, was ich persönlich sehr schön finde, weil es ein sehr spannendes Thema ist und Interesse ist ja immer gut. Also natürlich freue ich mich, wenn Sie hier sind, weil Sie hier sein wollen und nicht, weil Sie hier sein müssen. Der geplante Ablauf der Vorlesung der Themen wird so sein. Heute machen wir eine kurze Einführung. Ich hoffe, Sie verzeihen mir, dass es da jetzt noch nicht ans Eingemachte geht, aber ich finde, gerade beim Thema KI, gerade wenn Sie noch im ersten, zweiten Semester sind oder auch im sechsten Semester, also zumindest bei mir war es so, dass die Vorstellung von was KI ist, vielleicht ein bisschen davon abweicht, was KI wirklich ist und da hilft das Ganze ein bisschen in Perspektive zu setzen und mal einzuordnen, was die KI eigentlich ist, wo sie herkommt, wo sie gerade hingeht, damit sie auch hoffentlich keine falschen Erwartungen haben. Einfach, damit sie ein bisschen geerdet sind, was wir eigentlich machen wollen. Als zweites Kapitel oder als erstes inhaltliches, richtiges Kapitel geht es dann um intelligente Agenten. Das ist die Frage, was ist ein Agent, was ist intelligenter Agent. Abschnitt drei, danach kommen logische Agenten. Da werden wir ein bisschen Aussagenlogik machen und Prädikatenlogik und wie man damit intelligente Agenten, also die sich intelligent verhalten, programmieren kann. Danach kommt bäsische Wahrscheinlichkeit. Das haben Sie vielleicht schon in anderen Vorlesungen gehört, vielleicht auch nicht, deswegen wird es auf jeden Fall nochmal wiederholt und inwiefern man damit intelligentes Verhalten provozieren kann, sage ich mal. Danach kommt probabilistisches Schließen. Also schließen heißt hier Schlussfolger im englischen Reasoning, also wie man aufgrund von Wahrscheinlichkeiten Schlüsse ziehen kann, gute Schlüsse ziehen kann. Probabilistisches Schließen über Zeit, also wenn sich das Ganze noch zeitlich entwickelt und zum Schluss noch etwas lernen durch Beispiele. Das ist jetzt das quasi eine abgeschweckte Fassung, eine Einführung des Maschinenlernens und eine kurze Übersicht. Das heißt, die Leute, die Grundlagen des Maschinenlernens hören, werden das dann deutlicher oder intensiver gehört haben, aber da die Visual Computing Studierenden das noch nicht belegen können, wäre es ein bisschen unfair, ihnen das Fach vorzuhalten. Das heißt, da werden wir ein bisschen drauf eingehen. Oben stehen ganz groß geplante Themen. Das liegt daran, dass sich vielleicht im Laufe des Semesters aufgrund Ihres Feedbacks oder aufgrund von, sage ich mal, sich ergebenden Problemen oder auch Wünschen vielleicht noch ein paar Verschiebungen ergeben, aber das ist so der grobe Fahrplan und Änderungen sind vorbehalten. Das heißt, heute fangen wir erst mal an mit der philosophischen Frage, was ist Intelligenz? Und ich habe mir einfach mal den Spaß gemacht und habe gegoogelt und habe die Google Bilder so bemüht, einfach nach Intelligenz und geschaut, was da so rumkommt. Das war also vor circa einem Monat. Ja, und da sehen Sie ja vielleicht, was da, also das ist, schauen Sie erst mal nur auf die Bilder, jetzt nicht auf die Texte, aber ganz oft in den Gehirn, Zahnräder, Daten, also irgendwelche coolen Visualisierungen, aber ganz oft ist das Gehirn zu sehen. Und die Seiten unten sagen dann schon, also gibt es Intelligenz, IQ lässt sich verändern. Also, es gibt sehr viele verschiedene Dinge zum Thema Intelligenz. Und wenn wir jetzt mal fragen wollen, was Intelligenz ist, dann gibt es ein schönes Zitat von William Stern von 1912.)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | results
 Alles intelligente, menschliche Denkvorgänge und die möchte man nachbilden. Oder aber möchte man nur menschlich handeln. The art of creating machines that perform functions that require intelligence when performed by people. Also dass man sagt, das wofür Menschen Intelligenz brauchen, wenn sie etwas tun, das wäre doch dann auch, könnte man nachbilden. Oder the study of how to make computers do things at which at the moment people are better. Da kommen wir auch gleich noch zu, was das nach sich zieht. Jetzt ist aber so, dass menschlich ja nicht immer rational ist oder gut ist. Und deswegen kann man noch eins weitergehen und sagen, vielleicht ist KI ja Rationalität. The study of mental faculties through the use of computational models. Also hier würde man jetzt nicht von Menschen direkt ausgehen, sondern man würde davon ausgehen, was man als Rational bezeichnet. Oder the study of the computations that make it possible to perceive, reason and act. Das ist, wenn Sie später noch sehen, das war der Anfänger der KI, man ging sehr stark von Logik aus. Logisch handeln, logisch denken, logisch agieren, das ist das, was man als Rational betrachtet. Und rational handeln, also vorher war ja Denken, also perceive, reason and act. Act kommen wir zum Handeln. Computational intelligence, the study of design of intelligent agents. Und AI is concerned with intelligent behavior and artifacts. Also das bringt Ihnen ja nichts, wenn Ihr Computerprogramm, was intelligent ist, nur intelligent denkt. Es soll ja irgendwas lösen, es soll irgendwas machen auf intelligente Art und Weise. Und deswegen geht es ja darum, dass man intelligent oder in dem Fall rational handelt. Und das ist auch der Kern oder das, woran diese Vorlesung ausgerichtet ist. Wir versuchen, Agenten, Artefakte, also irgendwelche Programme zu ergründen und zu programmieren, die rational denken. Dann gibt es nämlich ein schönes Zitat von Edgar Dijkstra. Der hat gesagt, the question of whether a computer can think is no more interesting than the question of whether a submarine can swim. Also ich habe auch das schon mal gehört im Vergleich, dass ein Bulldozer beim Gewichtheben jetzt keine Überraschung ist. Und das ist ein sehr schönes Zitat, weil er sagt, ein U-Boot kann natürlich schwimmen, aber es ist nicht das, was man meint, wenn ein Mensch schwimmt. Und das ist bei vielen Forschern und Leuten noch diese vorherrschende Meinung, dass man sich denkt, also das ist wirklich, die Frage ist nicht so interessant. Und deswegen, und da hat auch Alan Turing, den kennen Sie bestimmt, gab es vor einigen Jahren auch einen Film drüber, über, ich glaube, The Imitation Game. Der war auch beteiligt an dem Knacken des Enigma-Verschlüssungscodes im Zweiten Weltkrieg. Also Alan Turing hat sich den Turing Test ausgedacht und der sagt, es geht folgendermaßen, Sie haben also einen männlichen Fragesteller, einen Interrogator, und der redet, also chattet, würde man heute sagen, mit zwei unbekannten Gesprächspartnern. Einer davon ist ein Mensch und einer ist ein Computer. Und wenn man auch nach intensiver Befragung nicht entscheiden kann, welcher von beiden der Mensch ist und welcher der Computer ist, dann hat der Computer den Turing Test bestanden. Es gibt bis heute noch keinen Computer, der den Turing Test bestanden hat, weil das Schöne an diesem Test ist, er ist zwar sehr kurz beschrieben, aber im Prinzip müsste der Computer ja alles können, was der Mensch kann oder alle Fragen beantworten können. Es geht ja nur um Frage-Antwort-Spiel, aber naja, Sie werden immer eine Frage finden, mit der Sie den Computer heute noch austricksen können. Beachten Sie, der Test sagt nicht, der Computer ist intelligent. Es geht nur darum, ob der Computer oder das Programm den Test bestanden hat. Das sagt noch nichts darüber aus, was der Computer kann oder ob man ihn als intelligent betrachten kann. Es geht nur darum, es ist nur eine Einteilung, hat er den Test bestanden oder nicht. Das habe ich vorgegriffen. Also kann eine Maschine, die den Turing Test besteht, denken? Reden wir mal drüber. Es gibt die Ansicht oder die Einteilung, also wenn eine Maschine nur so tut, nur so agiert, als wäre sie intelligent, dann spricht man von schwacher KI, also weak AI. Und wenn Maschinen wirklich denken können, dann spricht man von starker KI, strong AI. Und von den meisten Forschern heutzutage wird die schwache KI-Hypothese akzeptiert und die Frage, ob KI jetzt wirklich denken kann oder nicht, ist irrelevant. Sie können sich auch fragen, wo ist der Unterschied? Also Sie können ja Ihrem Gegenüber auch nicht in den Kopf schauen. Er handelt vielleicht intelligent, aber ob da Intelligenz im Oberstübchen vorhanden ist, wissen Sie ja auch nicht. Deswegen ist es also mittlerweile eigentlich die übliche Denkweise, es ist uns egal. Hauptsache die KI handelt intelligent.)
2025-10-19 22:56:23 | INFO | retrieval.faiss_segments | 

joined deduped 13)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | retrieval 15)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | results
 Gut, genau, hier Überblick, was wir dieses Semester so machen. Und was nächstes Semester vielleicht, wahrscheinlich, möglicherweise eher so dann gemacht werden würde. Ha, genau. Das ist neu. Ja, Professor Kohlhase wollte das Thema so ein bisschen vermeiden. Ich wollte das nicht, weil, ja. Es gibt diese Unterscheidung zwischen strong AI und narrow AI, mit jeweils noch einer Liste von Synonymen hinten dran gepackt. Narrow AI ist das, was man üblicherweise erwartet, dass Informatiker sich so ein bisschen damit auseinandersetzen. Ja, ich habe irgendwie so ein konkretes Ziel, wie, keine Ahnung, ich will Schach spielen oder ich will Musik automatisch komponiert haben oder was auch immer. Also schreibe ich mir irgendwie so ein pseudo-intelligentes Programm, das dann irgendwie das Problem für mich löst. Das ist narrow AI. Das ist das, womit wir uns hauptsächlich beschäftigen werden. Auf der anderen Seite ist das, was Hollywood üblicherweise denkt, was künstliche Intelligenz ist, nennt sich dann strong AI oder full AI oder AGI für Artificial General Intelligence. Ja. Also Artificial General Intelligence. Ich bin mir nicht ganz sicher, warum sie das G unbedingt in die Mitte packen mussten, aber, ja, okay. Ja, also weak AI ist das, was irgendwie momentan noch irgendwie feasible ist. Strong AI ist das, wo dann auch irgendwie Futuristen und so sich darüber auslassen, was passieren könnte irgendwann in den nächsten, je nachdem, wen man fragt, 10.000 bis 10.000 Jahren. Ja. Und ein paar Worte dazu. Also die Leute, die sich ernstzunehmend mit AGI auseinandersetzen und es gibt diese Leute tatsächlich. Was die konzeptuell oder mathematisch prinzipiell machen, ist im Großen und Ganzen, zumindest vom Framework her, dasselbe wie narrow AI. Also wenn ihr euch irgendwie für AGI interessiert, seid ihr hier trotzdem im richtigen Kurs. Auch wenn ich das jetzt mit zwei Slides abhandeln werde und danach nie wieder erwähnen. Plus, was diese Leute halt üblicherweise noch irgendwie machen, ist dann irgendwie Decision Theory und Game Theory und so. Ich weiß nicht, das werden wir hier dann eher nicht machen. Gibt aber bestimmt auch irgendwie Kurse dazu. Das Hauptproblem ist, glaube ich, mit AGI, dass so ein bisschen fragwürdig ist, je nachdem, mit wem man redet und wessen Arbeit man sich gerade anschaut. Ja. Ja. Und wie man anschaut, wie viel Sinn das eigentlich überhaupt macht oder wie respektabel das ist oder wie viel esoterischer Blödsinn da mit drin steckt. Ich sag ja, es gibt Leute, die machen das ernsthaft. Es gibt auch Leute, die machen das völlig blödsinnig und meinen, sie machen es ernsthaft und ja. Aber warum ich glaube, dass das irgendwie sinnvoll ist, das Thema mal irgendwie anzusprechen, ist, weil halt irgendwie so in den letzten Jahren, ne, wer kam da alles an? Stephen Hawking hat angefangen und dann, ja er hat nicht angefangen, weil Nick Bostrom war vorher schon da und Elisa Yudkowsky war da. Lütkowski war davor noch da, aber irgendwann kam halt dann auch Stephen Hawking an und dann gab es die Headlines. Stephen Hawking bahnt davor, dass, keine Ahnung, KIs die Weltherrschaft an sich reißen und alles kaputt machen. Irgendwann musste dann Obama auch noch Statements dazu abgeben. Also so negligible scheint das Thema an sich halt leider nicht mehr zu sein, dass man das irgendwie ignorieren könnte. Falls es euch interessiert, da sind irgendwie so eine Liste von Leuten, die sich halt tatsächlich damit auseinandersetzen. Nicht nach einer bestimmten Ordnung, aber ich sage ja, bei manchen davon wäre ich vorsichtig. Die kommen mir so ein bisschen esoterisch vor. Also insbesondere alles, was irgendwie mit Les Ron und Lütkowski und so vielleicht nicht so hundertprozentig ernst nehmen. Oder vielleicht halt auch doch, ich weiß es nicht. Was ich empfehlen kann, weil es lohnt sich. Wurstig ist, sind die People for the Ethical Treatment of Reinforcement Learners. In erster Linie, weil das ein ziemlich guter Kumpel von mir mit da drin steckt. Aber seid halt irgendwie skeptisch mit allem, was irgendwie in die Richtung geht. Sowohl in die eine Richtung als auch auf die andere. Ja, also wenn euch irgendjemand behauptet, es wird niemals künstliche Intelligenz geben, weil XYZ, dann ist sehr wahrscheinlich, dass XYZ Blödsinn ist. Ja. Gut, also so viel zu dem. Thema. Wo wir auch nicht dazu gekommen sind am Montag, ist eigentlich mal so ein bisschen dazu zu reden, was wir jetzt so in unserer Forschungsgruppe machen. Was ja irgendwie Sinn macht, weil hey, erste Vorlesung und so. Gut. Quark steht für Knowledge Adaption and Reasoning for Content. Und der Grund, warum Professor Kohlhase selber nicht wusste, wofür sein eigenes Akronym steht, ist, weil das Akronym eigentlich wurscht ist. Ich habe das Gerücht gehört, dass er seine Gruppe Quark, genannt hat, weil er, als er in den USA war, festgestellt hat, dass es bei den Amis keinen Quark gibt. Also so Speisequark. Wenn er das hinreichend vermisst hat, dass er dann, als er nach Deutschland kam, seine Gruppe unbedingt Quark nennen musste. Und sich dann halt im Nachhinein irgendwas aus dem Hut gezogen hat, wofür das jetzt stehen könnte. Also offiziell steht es für Knowledge Adaption and Reasoning for Content. Ich bin mir auch gar nicht sicher, was der Satz überhaupt bedeuten soll, so semantisch. Aber naja. Hier jetzt heißt das Ganze ja auch irgendwie Professur für, Wissensrepräsentation und Verarbeitung. Im Englischen ist es angenehmer, das ist einfach Mathematical Knowledge Management. Und das kann man dann abkürzen und dann ist es MKM und dann hat man drei Buchstaben statt drei Sätze mit Subklauseln und ach, keine Ahnung. Ja, also im Großen und Ganzen geht es erstmal darum, wie man irgendwie Wissen in irgendeiner Art und Weise so repräsentieren kann, dass Computer irgendwas damit anfangen können. Da hat man dann halt natürlich irgendwie so ein Spektrum zwischen extrem formal auf der einen Seite, also keine Ahnung, tatsächlich ein Code, den ein Computer ausführen kann und komplett informal auf der anderen Seite, wie halt irgendwie Fließtext von Leuten, die irgendwas schwurbeln. Und damit wollen wir halt irgendwie lustige Sachen abmachen, wie halt zum Beispiel irgendwie intelligentes Verhalten induzieren daraus. Hier ist so ein bisschen eine Liste von Sachen, die man damit macht. Was man machen kann. Content Markup ist relativ interessant für uns. Was im Prinzip einfach nur so viel heißt, wie wir nehmen halt irgendwelche Texte, die da sind und annotieren die auf irgendeine Art und Weise, dass möglichst Computer was damit anfangen können. Unserer Meinung nach ist das der effizientere Weg, als tatsächlich zu versuchen, Kram komplett zu formalisieren. Aus zwei Gründen. Erstens ist es anstrengend. Und der zweite Grund ist, entsprechend kriegt man Leute nicht dazu, es zu tun. Aber Content Markup ist halt für viele Probleme führt das halt auch schon irgendwie zu schönen Lösungen und so. Also ist das eher so unsere Methode. Ja, User Support und Quality Control statt unbedingt Sachen, die jetzt hundertprozentig korrekt sind, was auch immer das genau heißen soll überhaupt. Entsprechend Mathematik ist halt irgendwie so unsere Angriffsstelle Nummer eins. Und das ist halt auch irgendwie so unsere Angriffsstelle Nummer eins. Weil sich Mathematik halt einfach wunderbar für vieles, was wir so machen, als das perfekte Anwendungsgebiet eignet. Es ist halt so wunderbar semi-formal. Man kann es üblicherweise komplett formal ausdrücken, wenn man jetzt alles irgendwie in First oder Logic in ZFC übersetzt oder so ein Kram. Tut man aber halt häufig nicht. Das heißt, den informalen Kram haben wir halt auch. Care more about applications than about philosophy ist, glaube ich, wahr für jeden, der nicht gerade Philosoph ist. Aber, ja. Gut, genau. Unsere Gruppe gibt es eben seit 2004. Entsprechend haben wir halt auch einen Sack von Leuten, die irgendwie mal an uns vorbeigelaufen sind oder promoviert haben irgendwann oder damit assoziiert sind. Und jetzt seit in meinem Fall drei Wochen sitzen wir halt jetzt hier. Da ist noch unsere Homepage. Falls euch das irgendwie interessiert, könnt ihr euch das natürlich gerne anschauen. Wenn es um Applications geht, Bäm! Das ist irgendwie Kram, den wir entweder verursacht haben oder irgendwie miteinander zu tun haben. Falls euch das irgendwie interessiert, wenn es um solche Sachen geht wie Bachelorarbeiten, Projektarbeiten, Masterarbeiten und so weiter und so fort, keine Scheu. Bitte e-mailt mich einfach. Ich habe auch tatsächlich schon E-Mails von zwei Leuten gekriegt, was mich sehr freut. Wir können uns immer entweder irgendwas aus dem Hut ziehen, was ihr irgendwie Lustiges machen könnt, falls euch irgendwas hier interessiert. Und dann ist das einfach so. Also, ja, auch da bitte keine Scheu. Insbesondere wenn es halt um so Sachen geht. Ich bin mir nicht sicher, was E-Math 3.0 ist, deswegen ignoriere ich das mal. Aber Active Documents sind natürlich irgendwie sehr interessant. Wir hatten letztes Jahr in Bremen eine Bachelorarbeit. Der hat dann halt tatsächlich auch irgendwie UE4, also Unreal Engine, ausgepackt und ein Computerspiel gebaut, das im Hintergrund Logik ablaufen hatte. Also für so Sachen sind wir auch gerne offen.)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | results
 That does not seem to be the case, so we'll just start. Remember, last week, we mostly did admin stuff, right? Meaning, you want a grade, we have to have some kind of a way of giving you grades. It's largely irrelevant for the greater cause of AI. And so, we're going to start. And the other things we did was basically try and kind of get an overview of what AI might be. And I've tried to convince you that AI exists, i.e., in the last almost 70 years, we've been achieving something in AI. Many of the things that are now called computer science or engineering were actually born out of AI. And so, we're going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. And I'm going to start. I would like to, since AI is very much in the public discussion, make you aware of a distinction that the next time you have to give an interview, your interviewee, no, interviewer, is probably not going to be aware of. And that's the difference between strong and weak AI. Okay. So, weak AI or narrow AI or instrumental AI, or applied AI, all of those kind of things, they mean one thing, namely, we AI researchers, you, me, all the other ones over there, choose a restricted domain, chess playing, scheduling, question answering, all those kind of things, and then try to be as good as possible, probably better, ideally, than humans. Okay. And that is something that works. We've seen successes. We know that chess and Go and checkers and tic-tac-toe, we've already achieved domination over humans. And we had already, using computer science methods, already become much better at multiplying 20-digit numbers than humans ever were. So, that's what we think, we AI researchers think AI might be. There is another conception of AI, which we call strong AI, or full AI, or abstract general intelligence. And that is really leave out all the domain restrictions, trying to be a strong AI. And that is really leave out all the domain restrictions, trying to be a strong AI. And that is really leave out all the domain restrictions, trying to be as good or better than a human, and do everything a human can do. Meaning, alpha Go, not only has to know how to play Go, but also chess, and poker, and soccer, and love poetry, and international politics, all the things you can do. Right? That's what we call AGI, general or full artificial intelligence. You can imagine that this is a little bit harder. And that's really what Hollywood thinks AI is. If you think back at all the movies about AI that you've seen, right? Those are all these robots that are not only smarter than humans are, but they can run faster, and they can be more efficient, and they can be more beautiful than... at least me. So, and you can imagine that this is hard. And so, a lot of the discussion that is going on in the general public, and that has been fueled by people like Elon Musk or so, that say, oh, the robocalypse is coming, right? And so on. And Stephen Hawking and so on, in his weaker moments, have contributed to this. That's all strong AI. Now, one of the things that's been noticeably absent in my look what we can do set of slides was strong AI. Strong AI is something I believe to be over the horizon and over the next one and so on. So while I believe that you will actually contribute much to my weak AI hall of fame in the future, I do not think that I will live to see general AI realized. And I don't even think that you will see general AI realized. Now, I might be wrong. I hope I am. But that's just my gut feeling. No, that's not what I really wanted. So, it's very important for you to keep those two concepts apart. We may be, as a field, very successful in weak AI. That doesn't mean we can do strong AI. We can do it. But we can do it in a way that is not so much that we can do it in a way that's not so much that we can do it in a way that is not so much that we can stab the weak AI. We can do strong AI. Now, you might say, and many people actually do say, that, well, if we just basically cover the whole landscape of everything with weak AI systems, that should give us strong AI. So it's just a problem of finding enough bright AI master's students and, you know, just letting them uncoordinate what they work on. The problem is that if you want to have general AI, you need some way of what you could think of as a routing algorithm. Right? If it's poetry, give it to her system. And if it's engineering, how about his system and so on. That thing, to build that, what's been called the supervisor, is something we can do. It is something we call AI hard. Namely, it's non-trivial to find out whether you're talking about engineering or poetry. That may be that we actually know it after a while. But the finer distinctions are very, very, very hard. And routing to the right weak AI system, we believe, not proved yet, of course, because we haven't built one yet, but we believe to be AI hard. Now, AI hard, is that something you intuitively understand?)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | results
 Okay. On to the new stuff. So. I would like to tell you a little bit about what this funny animal artificial intelligence might be. And I'll reveal to you that we really, really don't know ourselves. And I'll try to answer these kind of questions. What is AI? What have we achieved? We're going to take a very quick walk through the topics we're going to cover this semester. And of course, with all that talent in the room, I'm going to make a very quick advertisement about this stuff. You can do research about in my group. There must be some advantage of me actually standing up in front of you. Good. So, what is AI? There's a couple of definitions. Wikipedia has one. AI is intelligence exhibited by machines. Big surprise. Now. Philostomies. Philosophically, that's fine. All right. It basically says it's artificial, i.e. exhibited by a machine. Intelligence. Now, if I told you here's the definition, go and build AI. Would you know what to do? No. I wouldn't either. All right. It's a nice definition. But it's not, if you think about it, operational. All right. There are definitions. There are definitions where you know exactly what to do. This one isn't one of those. You can find that beautiful or you can find it annoying. All right. So, there are other definitions. AI is a subfield of computer science that is concerned with automation of intelligent behavior. Now, that has a little bit more information. It basically says, truly or falsely, it's a field of computer science. Right? We're not building AI by teaching anthills to do certain things, which one could think is a good way of arriving at AI. And some people do think that. Right? You may have heard about swarm intelligence and all of those kind of things. That's not what we're doing. We're using computers. Helpful. But then the rest is kind of automation. Right? Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. A definition that I like is due to Elaine Rich, which says AI studies how we can make the computer do things that humans still do better at the moment. It's slightly more operational. It basically tells us what we don't have to do, i.e. what is not AI. Right? There are certain things like regulating the temperature in a room that a thermostat does very well, thank you very much. Right? So that's not AI. That's, I don't know, domestic engineering or whatever. There are a lot of, I've been advertising these seats in the front here without much success. But there is place here and you can actually reach it without climbing. You can reach it without sitting over anybody. Okay? So for some parts of AI, I'm going to adopt Elaine Rich's definition. It's slightly problematic. And that's also something you can like or not. But it describes reality pretty well. AI is... It's somewhat the study of problems that are just too hard to be actually solved. Right? We haven't solved the AI problem after 70 years of trying. The wonderful thing is we've developed loads of very, very useful stuff. Many of the things that we're calling computer science nowadays started out as AI. Right? Including things like functional programming languages. Right? That are just in the age of parallelism are making a great contribution. They were invented because the old imperative languages weren't actually cutting it when you were trying to build systems or programs that would build... Would build... Would build... Would build... Would build... Would build... Intelligent behavior. Intelligent behavior. Parallel programming was actually very much driven forward by AI. And many other things. We're going to see a couple this semester. Constraint programming. Constraint solving is an old AI problem. Planning, which some people think is no longer AI because we are pretty good at it. We're pretty good at planning stuff. You could not actually be successful in the Ukraine War if you didn't have very complex planning algorithms that tells you where to move your trucks and your tanks and all of those kind of things. They do it automatically. Scheduling is something that I still remember being done with... I think it was a computer science thing. I think it was a computer science thing. I think it was a computer science thing. I think it was a computer science thing. They had these wonderful big boards that had all these little loads and loads and loads of little tiny paper pockets in them and you could stick nice and colorful cards in them and then you would have people standing in front of this board for two weeks trying to schedule where which course went. We can do this now by pressing a button. Okay? So, all of those things which are now considered engineering and have been taken over by the engineers are not considered AI anymore. So AI is kind of always stuck in this corner of problems that are too hard to solve. I like that corner. The big problems still. We don't know how to solve them. We have lots of crazy ideas of how this might... And the instant we solve a problem, it automatically becomes computer science. It's like pathology in medicine. The department of therapy resistant cases. I think it's important. Okay. And we can have a lot of fun here. But, I think it's important. Okay. But, we also invent lots of things that later become really, really, really well understood as part of computer science. Right. So, this is a definition of AI. The main problem in this, and you will have noticed, is that the last definition here is the only one. That... I'm laughing right now. This is IT. The last... So if you believe that hemos, the first one was the yo-yo depression, right, ago a long time ago. And this is what boobs means then. To evaluate intelligence class. What Robinson has written about intelligence class. Now, right here. Here is time period that not all psychiatrists can follow. So, all of you can wanna adapt this. Then obviously Share practiced intelligence effectively here. What it should do no less, is to apply зал of intelligence classes... It is not a set list, but is still an integral part of the program and does effectively satisfy its use. We now we've got a final statement that points out what is intelligent. We don't have enough ideas to explain. This has to do, these are the images you see here, exist. You can define intelligence as... knowing what intelligence is, they'll tell you, I know it when I see it, but I cannot define it. Okay, and if you press them really hard about what intelligence is, then they say, well, it's that what an intelligence test measures. Right, you can pull your hair out at this answer. Right, so, but Elaine Rich's definition, and that's why I like it, actually gets by without saying anything about intelligence. So, we can also try and look at artificial intelligence by saying, well, what are the components of artificial intelligence? And I'm going to give you five that we're pretty sure are part of intelligence. Not all of them we thought would be there 50 years ago. So, one of the things that we do consider part of AI, and necessary and important component, is the ability to learn. Right, everything that we would probably call intelligence. Right, we'll see other things. The ability to learn has some kind of an ability to learn. Ambrose Cherlency, who's doing a lot of writing here, he's also on the Library ofction Board. Just some time ago, in the last session in university. I can tell you by looking in the round table at the UE steak, and all that stuff about magic and most of these details don't get in. One thing I remember from reading over work until now, even something like the meme 그 I learned in Poland, that isn gruenbos bora, is that if you put out more of those words as your report, right. So learning seems to be important. Inference. The ability to process knowledge and to come up with things we consider to be true or valid from other things that we consider true or valid is an important thing in AI. Humans do it.)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | results
 Ja. Gut, genau, hier Überblick, was wir dieses Semester so machen. Und was nächstes Semester vielleicht, wahrscheinlich, möglicherweise eher so dann gemacht werden würde. Ha, genau. Das ist neu. Ja, Professor Kohlhase wollte das Thema so ein bisschen vermeiden. Ich wollte das nicht, weil, ja. Es gibt diese Unterscheidung zwischen strong AI und narrow AI, mit jeweils noch einer Liste von Synonymen hinten dran gepackt. Narrow AI ist das, was man üblicherweise erwartet, dass Informatiker sich so ein bisschen damit auseinandersetzen. Ja, ich habe irgendwie so ein konkretes Ziel, wie, keine Ahnung, ich will Schach spielen oder ich will Musik automatisch komponiert haben oder was auch immer. Also schreibe ich mir irgendwie so ein pseudo-intelligentes Programm, das dann irgendwie das Problem für mich löst. Das ist narrow AI. Das ist das, womit wir uns hauptsächlich beschäftigen werden. Auf der anderen Seite ist das, was Hollywood üblicherweise denkt, was künstliche Intelligenz ist, nennt sich dann strong AI oder full AI oder AGI für Artificial General Intelligence. Ja. Also Artificial General Intelligence. Ich bin mir nicht ganz sicher, warum sie das G unbedingt in die Mitte packen mussten, aber, ja, okay. Ja, also weak AI ist das, was irgendwie momentan noch irgendwie feasible ist. Strong AI ist das, wo dann auch irgendwie Futuristen und so sich darüber auslassen, was passieren könnte irgendwann in den nächsten, je nachdem, wen man fragt, 10.000 bis 10.000 Jahren. Ja. Und ein paar Worte dazu. Also die Leute, die sich ernstzunehmend mit AGI auseinandersetzen und es gibt diese Leute tatsächlich. Was die konzeptuell oder mathematisch prinzipiell machen, ist im Großen und Ganzen, zumindest vom Framework her, dasselbe wie narrow AI. Also wenn ihr euch irgendwie für AGI interessiert, seid ihr hier trotzdem im richtigen Kurs. Auch wenn ich das jetzt mit zwei Slides abhandeln werde und danach nie wieder erwähnen. Plus, was diese Leute halt üblicherweise noch irgendwie machen, ist dann irgendwie Decision Theory und Game Theory und so. Ich weiß nicht, das werden wir hier dann eher nicht machen. Gibt aber bestimmt auch irgendwie Kurse dazu. Das Hauptproblem ist, glaube ich, mit AGI, dass so ein bisschen fragwürdig ist, je nachdem, mit wem man redet und wessen Arbeit man sich gerade anschaut. Ja. Ja. Und wie man anschaut, wie viel Sinn das eigentlich überhaupt macht oder wie respektabel das ist oder wie viel esoterischer Blödsinn da mit drin steckt. Ich sag ja, es gibt Leute, die machen das ernsthaft.)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | results
 I would like to, since AI is very much in the public discussion, make you aware of a distinction that the next time you have to give an interview, your interviewee, no, interviewer, is probably not going to be aware of. And that's the difference between strong and weak AI. Okay. So, weak AI or narrow AI or instrumental AI, or applied AI, all of those kind of things, they mean one thing, namely, we AI researchers, you, me, all the other ones over there, choose a restricted domain, chess playing, scheduling, question answering, all those kind of things, and then try to be as good as possible, probably better, ideally, than humans. Okay. And that is something that works. We've seen successes. We know that chess and Go and checkers and tic-tac-toe, we've already achieved domination over humans. And we had already, using computer science methods, already become much better at multiplying 20-digit numbers than humans ever were. So, that's what we think, we AI researchers think AI might be. There is another conception of AI, which we call strong AI, or full AI, or abstract general intelligence. And that is really leave out all the domain restrictions, trying to be a strong AI. And that is really leave out all the domain restrictions, trying to be a strong AI. And that is really leave out all the domain restrictions, trying to be as good or better than a human, and do everything a human can do. Meaning, alpha Go, not only has to know how to play Go, but also chess, and poker, and soccer, and love poetry, and international politics, all the things you can do. Right? That's what we call AGI, general or full artificial intelligence. You can imagine that this is a little bit harder. And that's really what Hollywood thinks AI is. If you think back at all the movies about AI that you've seen, right? Those are all these robots that are not only smarter than humans are, but they can run faster, and they can be more efficient, and they can be more beautiful than... at least me. So, and you can imagine that this is hard. And so, a lot of the discussion that is going on in the general public, and that has been fueled by people like Elon Musk or so, that say, oh, the robocalypse is coming, right? And so on. And Stephen Hawking and so on, in his weaker moments, have contributed to this. That's all strong AI. Now, one of the things that's been noticeably absent in my look what we can do set of slides was strong AI. Strong AI is something I believe to be over the horizon and over the next one and so on. So while I believe that you will actually contribute much to my weak AI hall of fame in the future, I do not think that I will live to see general AI realized. And I don't even think that you will see general AI realized. Now, I might be wrong. I hope I am. But that's just my gut feeling.)
2025-10-19 22:56:24 | INFO | retrieval.faiss_segments | results
 Three or four a month in one of these companies. And they're shipped worldwide. And that means that every machine is slightly different because they're made to order, and that they all need manuals. Operation manuals. Operation manuals in typically something like 25 to 40 languages, for any of these little companies. Well, they're not little, they're actually quite big by now. And so you have in these companies the problem of maintaining something like 100 to 200 different variants of machine manuals in 25 languages. And they all have to be extremely high-quality, extremely high-precision, because if you have an error in your manual and that leads to actually destroying the machine, which is very easy, guess who pays? So it's a very important task for the companies to have very good manuals with hundreds and thousands of variants of that same manual. They share a lot, but they have crucial differences. Now, this is something, because every one of these machines has something like a thousand or so interesting parts, you get by with a couple of thousand concepts, all of which have to be somehow dealt with. Right? And that's exactly what symbolic techniques are good at. These companies actually, in industrial practice, use symbolic AI techniques to deal with this problem. You just don't hear about it because they don't want to give their competitive advantage away. Chances are quite good that you're not going to be hired by Google for Google Translate. Chances are very good that you have a good shot at getting a job at one of these companies out there in the hills and do things like manuals with what you learn about AI. Google Translate also exists as something where you can work on. Wonderful. Or looking at trying to understand whale songs or whatever people are doing. But I just want to alert you to the fact that only because you hear about the consumer tasks most, because you're all consumers, doesn't mean that there's not a very interesting realm of interesting, interesting problems here. And by and large, for these kind of narrow, means producer of something that we have under very tight control, tasks, where you need very high precision.)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | retrieval 14)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 Dieser Audiobeitrag wird von der Universität Erlangen-Nürnberg präsentiert. Guten Tag allerseits. Vielleicht sollte ich wieder auf die Slides zurückschalten. Wir haben letzte Woche einen wahrscheinlich letzten großen Teil der Vorlesung angefangen. Wir haben angefangen, uns über maschinelles Lernen Gedanken zu machen. Das ist ein großes Gebiet. Genau wie... Genau wie bei allen anderen Gebieten werden wir nur kleine Teile davon behandeln können. So die Grundlagen hier in dieser Vorlesung. Es gibt ganze Gebiete, Konferenzen und Spezialvorlesungen über dieses Thema. Selbst hier in Erlangen, auch wenn die meisten Vorlesungen, die es in dieser Richtung hier gibt, unter Mustererkennung laufen. Aber das ist nichts anderes als im Wesentlichen angewandtes Machine Learning. Im Wesentlichen dieselben Geschichten. Und ich will hier nur so eine relativ allgemeine, wie man sagen kann, KI-orientierte Einführung geben. Ähm... Machine Learning ist eine so der neuen Trends in ganz, ganz vielen Gebieten der Informatik. Das kommt im Wesentlichen daher, dass man einerseits auf der Hardware-Seite große Fortschritte gemacht hat. Dass man statistische Modelle sehr gut trainieren kann. Dadurch, dass man sie auf GPU-Farmen laufen lässt. Ähm... Das ist das eine. Und natürlich, dass es gewisse Firmen gibt, die sehr viele GPUs haben. Ja. Wo man dann auch mal, wenn man die richtigen Connections hat, einfach mal ein paar zehntausend GPUs einfach mal einen Monat rechnen lassen kann. Und für viele der Sachen, wo jetzt die großen Erfolge gefeiert werden, die liegen genau an sowas. An Hardware-Zeugs. Wie bei den Physikern. Wenn man halt Zugang zu dem großen, ähm... Teilchenbeschleuniger hat, dann kann man irgendwie, ähm... irgendwelche Quarks oder sowas sehen. Und sonst eben nicht. Ähm... Und, ähm... Deswegen gibt es so ein bisschen in der... KI, aber auch in angrenzenden Gebieten so die Tendenz, ähm... zu sagen, okay, dann nehmen wir doch mal Deep Learning und wenden das, ähm... ohne groß nachzudenken. Ähm... Ähm... Auf mein Problem an und hoffentlich passiert dann was Schönes. Ähm... Und meistens passiert erstmal nix, dann ändert man das Modell ein bisschen, ähm... Und dann passiert vielleicht doch noch ein bisschen mehr. Ähm... Das Problem, was ich daran sehe, ist, das ist zwar alles wunderschön, aber diese ganzen Sachen geben uns sehr wenig Erklärungen. Ja, das ist, äh... Sehr häufig nicht, warum etwas funktioniert. Ja, es lernt halt von sich selber und, ähm... gibt selber keine Erklärungen ab, das System. Und dann... Ähm... Dann funktionieren gewisse Sachen, aber man weiß auch noch nicht so richtig, warum. Das ist, äh... Das ist ein bisschen, ähm... im Gegensatz zu diesen symbolischen oder inferenzbasierten Verfahren. Natürlich kann man auch... ...au. ...au. ...aufsagen, ähm... die inferenzbasierten Verfahren können zwar erklären, aber wenn sie keine, ähm... Aber vor allen Dingen deswegen, weil sie keine Resultate rauskriegen und dann auch nix zu erklären haben. Ja, das ist natürlich auch, äh... eine legitime, äh... Kritik. Ich denke, und das sollte man sich, ähm... Sie sollten sich vielleicht so ein bisschen im Hinterkopf behalten, ähm... Auf die Dauer wird man letztlich, ähm... eine Mischung brauchen aus solchen, ähm... eher datengetriebenen Verfahren und eher symbolischen Top-Down-Verfahren. Ähm... Da ist die Forschung allerdings noch nicht sehr weit. Ja, also da... Es gibt zwar Ansätze, aber ich muss gestehen, die, die... äh... äh... reißen mich noch nicht so vom Hocker. Ja, das ist so, da hat man noch nicht so richtig die Idee, was man gerne möchte. Man hätte gerne, dass das vielleicht man symbolische Sachen lernen könnte und dann symbolisch weiterrechnen könnte und dann irgendwo das Ganze wieder, ähm... die Inferenz steuern könnte mit, mit... gelernten Verfahren und so weiter. Gut. Ähm, aber bevor wir dazu kommen, ähm... wollen wir uns ein bisschen eher die Grundlagen angucken. Einerseits möchte ich, haben wir angefangen damit, ähm... die... diese ganze Sache, ähm... zurück zu, zu binden in unsere Agentensicht, mit den Lernagenten. Und ich möchte heute so ein bisschen, ähm... in, sozusagen allgemein über Lernen sprechen. Ähm... Dann eine sehr einfache Äh... Form des Lernens, äh... nämlich Entscheidungsbaumlernen. Ähm... mir genauer angucken, weil man da schon relativ viel dran sehen kann. Und dann so ein bisschen über Lernperformance. Ähm... Wie gut ist denn ein Lernalgorithmus? Was, was interessiert uns da? Ähm... Sprechen. Genau. Ähm... Warum lernen? Im Wesentlichen deswegen, weil... ähm... Lernen praktisch ist. Ja? Aus zwei Gründen. Einmal für das System selber, weil sich die Umgebung ändert. Weil man deswegen nicht irgendwelche, ähm... fixen, ähm... Wahrscheinlichkeiten in diese, zum Beispiel, Bayesian-Modelle einbauen kann. Weil die sich ja jederzeit ändern können. Die Welt ändert sich. Man muss sich irgendwie anpassen. Ähm... Und irgendwoher müssen diese neuen, neuen Werte oder so etwas brauchen. Ähm... kommen. Ähm... Ja. Andererseits wissen wir viele Dinge nicht. Es ist viel besser, wenn die Systeme das selber lernen können. Ähm... Und, ähm... Es ist natürlich sehr praktisch, wenn ein System lernen kann. Dann braucht man nicht alles zu implementieren. Als... KI-Entwickler. Ja. Viel besser man implementiert die wesentlichen Basisroutinen und dann kann man das System in die Welt entlassen und studieren lassen oder in eine Grundschule gehen lassen oder so etwas. Und hoffentlich irgendwann mal ein System, was ausgelernt hat und das kann, was es soll. Genau. Die Idee an der ganzen Lernerei aus Agentensicht ist, dass man im Wesentlichen den Agenten hat wie bisher, nur dass man eine ganz neue, ich würde mal sagen, Säule von... ähm... ähm... Komponenten dazu macht, die das jeweilige Performance-Element, also das, was bisher die Arbeit getan hat, ja, was auf die Umwelt reagiert hat, was geplant hat, ja, und solche Sachen. Was das erweitert, um Lernfunktionalität. Und die Lernfunktionalität ist typischerweise, dass man irgendwo ein Lernelement hat, etwas, was... ähm... ähm... ... die jeweiligen Modelle, die Regelmengen oder so etwas, verbessert. Und damit wir überhaupt von einer Verbesserung sprechen können, muss es einen irgendwie gearteten, externen... ähm... ...Standard, einen Evaluationsstandard geben. Ja? Lernen ist immer irgendwie Optimierung. Wir passen uns besser an eine Umgebung an. Und der Agent wird in irgendeiner Form... ...erfolgreicher. Und damit man überhaupt davon sprechen kann, muss man irgendwie einen externen Performance-Standard haben. Ja? Was nicht sein kann, bei all diesem hier, ist, dass wir einfach unsere Aufgaben umdefinieren. Ja? Sowas wie beim Studium Notenskala... ähm... ...Notenskala verändern und dann werden... ...und dann kriegen alle Studenten eine Eins. Das ist nicht Lernen. Ja? Schade eigentlich. Sonst wäre das alles so einfach. Aber... ...bei all diesem hier, und deswegen ist es hier auch rot und extern, ja? Der Agent kann diesen Performance-Standard nicht verändern. Wenn man sich vorstellt, sowas wie Evolution oder sowas, Survival of the fittest, ja? Da kann ich zwar unter Umständen meine... ...meine... ...Umgebung verändern, als Organismus. Ja? Zum Beispiel, als die Grünalgen aufgekommen sind, haben die von einer reduzierenden... ...Atmosphäre letztlich das... ...die Atmosphäre... ...mit Sauerstoff angereichert. Und sozusagen alle ihre... ...alle ihre Konkurrenten sind draufgegangen, ja? Weil die irgendwie eine reduzierende Atmosphäre brauchten. Ja, man kann die... ...Umgebung kann man ändern. Ja? Durch Aktionen. Aber man kann nicht den Performance-Standard, nämlich... ...die einen sterben, die anderen leben. Ja? Diesen Performance-Standard der Evolution, den kann man zum Beispiel nicht ändern. Das muss man sich... ...das muss man... ...das ist sozusagen wichtig, sich vor Augen zu halten. Und... ...das Lernelement... ...ist genau dazu da, in diesem Performance-Standard, bezüglich dieses Performance-Standards, zu evaluieren. Und es gibt hier sozusagen, so vorgesehen in gewisser Weise von der Architektur her, sind noch, sagen wir mal, irgendwelche Kritikelemente, also Elemente, die irgendwie sagen, naja, du hast, du bist jetzt gestorben, weil du nicht schnell genug... ...dies und jenes gemacht hast, oder so etwas, oder... ...du bist jetzt gestorben, weil du... ...die Klippe runtergesprungen bist, lass das lieber in Zukunft. Und so was, also dass man... ...das als eine Beobachtung des Performance-Standards hat. Und dann gibt es noch diese Idee, dass man einen Problemgenerator hat, wenn man fürs Lernen proaktiv selber Experimente macht.)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 Und das war so weit, wie wir das letzte Mal gekommen sind. Und wegen dieser Probleme war es so, dass diese statistische Approximation oder Maschinenlernung, je nachdem, ob man es sozusagen vor der KI betrachtet oder nach der Gründung der KI, war im Wesentlichen, dass man vor der KI bzw. in der Frühzeit der KI, dass man im Wesentlichen so kleine Lernprobleme sich anguckt, wo man irgendwie 50.000 bis 5.000 Beispiele hatte. Am Anfang des letzten Jahrhunderts, wo solche Sachen, wir werden heute lineare Regressionen sehen und so etwas, wo sowas noch von Hand gerechnet wurde, dann kann man sich vorstellen, dass man das natürlich nicht irgendwie auf Millionen von Beispielen machen will. Da hat man irgendwie sowas, was man Small-Scale-Learning nennt. Und da kommen die Fehler im Wesentlichen davon, dass man sehr eingeschränkte Hypothesenräume hat. Typischerweise, wenn man lineare Regressionen macht, einfach lineare Funktionen, mit denen kann man leicht rechnen. Da kann man zum Teil sogar, das werden wir sehen, zum Teil sogar geschlossene Lösungen finden. Und dann hat man natürlich sowas wie Fehler, die davon kommen, im Wesentlichen, dass man zu wenig Beispiele hat. Wenn man sich komplexe Funktionen angucken will, dann braucht man schon eine ganze Menge Beispiele. Was wir in den letzten Jahren sehen, ist Lernen aus großen Beispielmengen. Man kann sich vorstellen, dadurch, dass die Computer sehr viel, also mit langer Zeit exponentiell stärker geworden sind, dass man jetzt sehr viel mehr Beispiele lernen kann. Auch natürlich größere und interessantere Hypothesenräume. Ja, und im Wesentlichen ist es so, dass wir heutzutage, dass das Lernen heutzutage bestimmt ist, dadurch, wie viel wir lernen, wie viel Rechenpower wir haben. In den letzten 10 Jahren gab es enorme Fortschritte im maschinellen Lernen, was im Wesentlichen dadurch kam, dass so Firmen wie Google oder sowas einfach praktisch unbeschränkt Rechenpower haben. Das ist auch in der Forschung ein echtes Problem. Es gibt gewisse Forscher, zum Beispiel die, die bei Google arbeiten, die können dann einfach mal, wenn sie irgendwas rechnen wollen, einen gesamten Datencenter eine Weile lang haben. Oder aber ganze Farmen von GPUs, also von so Grafikprozessoren. Grafikprozessoren machen sehr häufig die lineare Algebra sehr schnell, haben Spezialchips für solche lineare Algebra. Operationen, wie wir sie auch hier sehen werden. Und da kann man sehr viel rechnen eben auf solche Grafikchips, auslagern. Und wenn man weiß, dass man sowas gerne machen möchte, dann baut man eben Maschinen, die eigentlich im Wesentlichen nur aus Grafikchips bestehen. Und kriegt dadurch enorme, für diese sehr eingeschränkten Operationen, die genau sind, die man für solche Dinge hier braucht, dass man solche GPU-Superrechner benutzen kann, auf denen man solche Dinge dann rechnen kann. Und dadurch werden dann natürlich, große Fortschritte erreicht. Einfach, weil man sehr viel mehr Rechenpower auf die Sachen draufsetzen kann.)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 jetzt wollen wir, evaluieren. Wie gut sind wir denn? Was wir wollen, beim Lernen, ich würde es noch so ein bisschen durchziehen, ist, dass wir, ähm, Daten aus der Vergangenheit angucken, stellen sich die Beispiele als so eine Art Zeitreihe vor, hm, die Daimler-Aktien, letzte Woche Dienstag, letzte Woche Mittwoch, letzte Woche Donnerstag, und dann machen wir darauf Machine Learning, und dann wollen wir voraussagen, was tun die Aktien morgen, oder am Montag, oder am Dienstag, und so was. Das ist das Typische, richtig? Und dann wollen wir etwas machen, was ja wohl ziemlich ambitioniert ist, ja, wir wollen nämlich, dass unsere Hypothese ist, unsere Hypothesen sind dann gut, wenn sie die zukünftigen Daten, über die wir gar nichts wissen, am besten voraussagen. Okay? Das ist das ambitionierte Problem von Machine Learning. Das heißt, wir wollen über die zukünftigen Daten die Daten, zukünftigen Daten, die beste Hypothese haben. Und, was uns jetzt interessiert ist, können wir das irgendwie evaluieren? Und die Antwort ist nein, können wir nicht. Warum nicht? Weil die Zukunft unbekannt ist. Ja? Nun stimmt das nicht ganz. Ja? Die Zukunft, man kann ja annehmen, dass die Zukunft im Wesentlichen, wie die Vergangenheit ist. Zumindest auf probabilistischer Ebene. Wenn ich irgendwann mal mit einem Würfel gelernt habe, was so passiert, nämlich die 2 kommt in einem Sechstel aller Fälle, ja, und der Würfel bleibt gleich, dann wird das auch in Zukunft stimmen. Ich weiß zwar immer noch nicht, ob beim nächsten Würfel ein 2 kommt oder nicht. Ja? Aber ich weiß immerhin, ja, wahrscheinlich in einem Sechstel aller Fälle. Ja? Wenn jetzt jemand irgendwie hinter meinem Rücken mit der Bohrmaschine kommt und irgendwas an einem Würfel macht, dann habe ich eigentlich gar keine Chance mehr, irgendetwas voraus zu sagen. Deswegen werden wir immer, wenn wir anfangen zu evaluieren, werden wir sagen, so, wir müssen annehmen, dass die Zukunft so sich verhält, wie die Vergangenheit, zumindest von der Wahrscheinlichkeitsverteilung her. Ja? Das ist sozusagen eine der Grundannahmen, die sich jetzt so ein bisschen durchziehen wird. Und die, denke ich, sollten wir sozusagen explizit besprechen, ja. Das heißt, das erste, glaube ich, was man verstehen muss, ist, dass, was haben eigentlich diese Beispiele, die wir da sehen, irgendwie mit Wahrscheinlichkeit zu tun? Ja? Das ist doch irgendwie Quatsch. Es stellt sich heraus, ja, wenn man, man kann einfach sich überlegen, dass man für alle zukünftigen Beispiele, über die wissen wir ja, es gibt Beispiele, die haben wir gesehen, die kennen wir schon, und das nächste Beispiel, über das wissen wir noch nichts, das ist ja zufällig. Und genau das können wir, darüber können wir reden. Und über dessen Verteilung, Zukunftsverteilung, Zufallsverteilung, das ist das richtige Maß, über das wir Annahmen treffen können. Und hier ist es so, dass wir einfach uns die Beispiele als Beobachtungen vorkommen. Beispiele sind immer Input, Output. Ein Input und ein Output für meine Hypothese, ja, und wenn man sich dann die Wahrscheinlichkeiten, die gemeinsamen Wahrscheinlichkeiten über diese Ereignisse, über diese zukünftigen Ereignisse, die können wir als eine Zufallsvariable darstellen. Und wir nehmen über die an, zwei Dinge, einmal, dass sie unabhängig sind, wie bei Würfen, die alten Beispiele beeinflussen nicht die neuen. Und die A priori Wahrscheinlichkeit ist immer gleich. Die Beispiele verhalten sich im Wesentlichen wie Würfe.)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 als, noch vor meiner Promotion habe ich noch an einem, ja, Kollege hieß das, teilgenommen. Es kann auch für sich vielleicht interessant werden, ich muss mal einen Flyer raussuchen. Das interdisziplinäre Kollege, der geht zu Kognitionswissenschaften, wo auch, wo sehr viel um KI geht oder um alles, was man mit kognitiven Fähigkeiten verbinden kann. Und da waren noch Kollegen oder Kompetenten von der Uni Kaiserlautern da und damals war das zweibeinige Laufen noch nicht gelöst. Es gab damals noch keine zweibeinig laufenden Roboter. Es ging einfach nicht. Also hat man nicht hinbekommen. Und wenn Sie jetzt sehen, was diese Boston Dynamics Roboter können, das ist schon mehr als nur zweibeiniges Laufen. Also es hat in den letzten zehn Jahren wahnsinnige Fortschritte gemacht. Und zu den Fortschritten kommen wir jetzt gleich mal, nämlich einen Überblick. Ich versuche, diesen Überblick hier in dieser Vorlesungsstunde durchzukriegen, damit wir nächste Woche einsteigen können, inhaltlich. Deswegen tut es mir leid, wenn ich nicht auf alles so genau eingehe. Sie können gerne Fragen stellen, wenn es Sie mehr interessiert. Aber das ist auch schon eine sehr, sehr kondensierte Zusammenfassung. Also einmal, das haben die aus GML schon gesehen, also Grundlagen des Maschinenlernens heißt die Vorlesung GML, dass KI selbst ein großes Gebiet ist, was viele Teilgebiete umfasst. Sie haben die ganzen Stichworte vorhin schon gesehen. Sie wollen Wissen repräsentieren. Also Wissensrepräsentation ist ein eigenes Gebiet. Automatisches Schließen ist ein Gebiet. Planen, Problemlösen. Das Maschinenlernen ist ein sehr großes, sehr sichtbares Gebiet. Computervision, jetzt wegen autonomem Fahren in aller Munde. Und natürlich auch für Sprachassistenten die Verarbeitung Sprache oder Automatische Besetzen. Hier nochmal, wie in der anderen Vorlesung, die Disclaimer. Für die meisten Begriffe gibt es englische Fachworte. Die deutschen klingen entweder komisch oder beschreiben das nicht ganz genau, was eigentlich gemeint ist. Deswegen, ich versuche konsistent zu bleiben in Deutsch-Englisch. Aber bitte verzeihen Sie mir, wenn ich dann oft so deutsch-englische Mischtexte habe, einfach weil der englische Begriff auch prägnanter ist und das Thema besser erfasst und Sie unter dem Begriff auch meistens die Literatur finden. KI hat natürlich Überlappungen mit anderen Fächern, mit Big Data, Data Science, Data Mining. Also ich bin auch überrascht, wie viele andere Vorlesungen hier schon Data Mining machen, was sich dann sehr stark mit Machine Learning überdeckt. Nicht ganz das Gleiche ist, aber große Beschneidung hat. Robotik natürlich, wo Sie jetzt natürlich Intelligenz verhalten wollen, wenn Sie autonomes Fahren oder autonome Roboter denken. Ja, sehen Sie jetzt gerade, es ist nicht Curiosity, Perseverance auf dem Mars gelandet und das Ding muss ja teilweise autonom agieren können. Deswegen haben Sie da auch immer KI. Und Sie haben auch die andere Richtung, die Kognitionswissenschaften. Gibt auch teilweise das eigene Studiengang. Das ist eine Mischung aus allem, was halt mit Denken, mit Kognition zu tun hat. Linguistik, Neurowissenschaften, KI, Psychologie. Also da geht es um die Frage, wenn wir hier Denken erforschen, auf eine sehr mathematische Art und Weise, können wir davon Rückschlüsse ziehen, die wiederum in die Psychologie, Pädagogik zurückgehen und natürlich vieles mehr. Also es gibt wahrscheinlich mittlerweile kaum ein Fach, wo es keine Überlappungen gibt. Und jetzt kommt die kurze Geschichte der KI. Einfach, damit Sie mal sehen, wie sich die KI)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 Das sollten Sie jetzt wieder sehen und damit möchte ich jetzt noch mit dem zweiten Thema anfangen für heute. Ich möchte Ihnen einen kurzen Einblick ins maschinelle Lernen geben und zwar spezifisch für den Bereich der Computer Vision. Warum mache ich das? Damit Sie dann einfach bessere Grundlagen haben, um die gefalteten neuronalen Netze später auch besser zu verstehen. Ich möchte jetzt auch nicht den ganzen Machine Learning Kurs wie beim Kollegen Landes hier wiederholen, sondern möchte einfach auf spezifische Sachen eingehen. Und zwar möchte ich mich mit Ihnen in dem Fall jetzt auf überwachtes Lernen konzentrieren, also auf Supervised Machine Learning und mit Ihnen einfach noch mal kurz wiederholen, wie das im Prinzip funktioniert. Also bei solchen Aufgaben, bei visuellen Aufgaben, zum Beispiel bei Klassifikationsaufgaben, wo man fragt, geben ein Bild, was wird darauf eigentlich gezeigt? Würde man typischerweise ein so folgendes Vorgehen haben, man würde Bilder sammeln und zu diesen Bildern sogenannte Grundwahrheit oder in dem Fall Labels generieren. Zu sagen zum Beispiel, das ist jetzt ein Flugzeug oder das ist ein Auto oder das ist ein Vogel. Und dann würde man mithilfe dieser Daten einen sogenannten Klassifizierer trainieren. In anderen Bereichen Regressionsgraden oder Regressionsgleichungen herausfinden, um zum Beispiel kontinuierliche Werte vorherzusagen, aber die sind jetzt hier im diskreten Fall. Und dann gegeben ein Bilddatensatz, den dieser Klassifizierer vorher noch nicht gesehen hat, die Güte dieses Klassifizierers bestimmt. Und wie macht man das typischerweise? Jetzt einfach mal hier in Python dargestellt, gegeben ein Bildsatz, einen sogenannten Trainingssatz und ein paar Grundwahrheiten oder Labels, sagt man, mach mal, trainier das mal und gib uns dann ein Modell wieder. Wie das trainieren aussieht, das kommt dann tatsächlich darauf an. Ich werde Ihnen heute mal ein Trivialbeispiel zeigen. Wenn man dieses Modell trainiert hat, dann kann man einen neuen Testdatensatz reingeben und sagen, naja, gegeben dem Modell und Bildern, die du vorher noch nicht gesehen hast oder Daten, die du vorher noch nicht gesehen hast, sag mal, worum es sich handelt. Gib mir mal deine Labels zurück. Das ist der sogenannte Prediktschritt. So kann man ganz viele Machine Learning Algorithmen einfach zusammenfassen. Die unterscheiden sich dann natürlich darin, was hier drinnen stattfindet. Jeweils in dem Trainings- und in diesem Prädiktionsschritt. Oder anders gesagt, jetzt bei einem sehr einfachen super oder überwachten Machine Learning Algorithmus, kann man es ganz trivial machen. Da braucht man eigentlich gar nichts trainieren. Da sagt man einfach nur, erinnere dich an alle Daten, an alle Bilder oder Bildfeatures, die wir gerade hatten und die Labels und dann suche das Label des Bild, was am ähnlichsten ist. Oder anders ausgedrückt, gegeben sagen wir einen Datensatz, den wir jetzt)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 Nein, ich bin mir ziemlich sicher, dass es das nicht gäbe. Das würden Sie in den Nachrichten größer sehen. Aber das ist das, was Sie eigentlich immer in der Science Fiction sehen, die starke KI. Deswegen ist auch das vielleicht das, was immer so präsent ist. Also ich bin auch groß geworden mit Knight Rider und ich fand die Idee total toll. Entsprechendes Auto, kann alles möglich machen, hat eine Persönlichkeit. Das hat mich als Kind sehr geprägt. Da habe ich schon mein Interesse an KI entwickelt. Sie kennen es dann vielleicht als nächstes auch. Woran man oft denkt, wenn man an KI denkt, ist Terminator oder in dem Fall Terminator 2. Die Maschinen werden intelligent und unterjochen oder löschen die Menschheit aus. Es ist oft die Angst, wo man sagt, sollten wir wirklich so weit forschen? Was ist, wenn uns die KI irgendwann überflügelt und uns loswerden will? Ist ja sehr, sehr, sehr häufig das Thema in Filmen, also Science Fiction. Aber auch schon viel früher, in einem Film von 1968. Also Sie kennen den Film vermutlich 2001 und ich sehe im Weltraum. Ich will jetzt nicht spoilern, falls Sie den Film schon gesehen haben, aber es geht auch um KI. Ja, genau. Leben in einer Matrix. Auch sehr philosophisch, hat aber erstmal nichts mit KI zu tun. Genau, also Sie sehen, es ist in Science Fiction, es ist sehr weit präsent und wenn es Ihnen so ein bisschen geht wie mir, dann sind Sie dadurch schon beeinflusst. Boston Dynamics, für die, die es nicht kennen, die stellen diese Roboter her und das ist schon, ich sage gerne mal creepy, was die können. Vielleicht als kurzen Datenpunkt dazu. 2009 habe ich an einem, noch als, noch vor meiner Promotion habe ich noch an einem, ja, Kollege hieß das, teilgenommen. Es kann auch für sich vielleicht interessant werden, ich muss mal einen Flyer raussuchen. Das interdisziplinäre Kollege, der geht zu Kognitionswissenschaften, wo auch, wo sehr viel um KI geht oder um alles, was man mit kognitiven Fähigkeiten verbinden kann. Und da waren noch Kollegen oder Kompetenten von der Uni Kaiserlautern da und damals war das zweibeinige Laufen noch nicht gelöst. Es gab damals noch keine zweibeinig laufenden Roboter. Es ging einfach nicht. Also hat man nicht hinbekommen. Und wenn Sie jetzt sehen, was diese Boston Dynamics Roboter können, das ist schon mehr als nur zweibeiniges Laufen. Also es hat in den letzten zehn Jahren wahnsinnige Fortschritte gemacht. Und zu den Fortschritten kommen wir jetzt gleich mal, nämlich einen Überblick. Ich versuche, diesen Überblick hier in dieser Vorlesungsstunde durchzukriegen, damit wir nächste Woche einsteigen können, inhaltlich. Deswegen tut es mir leid, wenn ich nicht auf alles so genau eingehe. Sie können gerne Fragen stellen, wenn es Sie mehr interessiert. Aber das ist auch schon eine sehr, sehr kondensierte Zusammenfassung. Also einmal, das haben die aus GML schon gesehen, also Grundlagen des Maschinenlernens heißt die Vorlesung GML, dass KI selbst ein großes Gebiet ist, was viele Teilgebiete umfasst. Sie haben die ganzen Stichworte vorhin schon gesehen. Sie wollen Wissen repräsentieren. Also Wissensrepräsentation ist ein eigenes Gebiet. Automatisches Schließen ist ein Gebiet. Planen, Problemlösen. Das Maschinenlernen ist ein sehr großes, sehr sichtbares Gebiet. Computervision, jetzt wegen autonomem Fahren in aller Munde. Und natürlich auch für Sprachassistenten die Verarbeitung Sprache oder Automatische Besetzen. Hier nochmal, wie in der anderen Vorlesung, die Disclaimer. Für die meisten Begriffe gibt es englische Fachworte. Die deutschen klingen entweder komisch oder beschreiben das nicht ganz genau, was eigentlich gemeint ist. Deswegen, ich versuche konsistent zu bleiben in Deutsch-Englisch. Aber bitte verzeihen Sie mir, wenn ich dann oft so deutsch-englische Mischtexte habe, einfach weil der englische Begriff auch prägnanter ist und das Thema besser erfasst und Sie unter dem Begriff auch meistens die Literatur finden. KI hat natürlich Überlappungen mit anderen Fächern, mit Big Data, Data Science, Data Mining. Also ich bin auch überrascht, wie viele andere Vorlesungen hier schon Data Mining machen, was sich dann sehr stark mit Machine Learning überdeckt. Nicht ganz das Gleiche ist, aber große Beschneidung hat. Robotik natürlich, wo Sie jetzt natürlich Intelligenz verhalten wollen, wenn Sie autonomes Fahren oder autonome Roboter denken. Ja, sehen Sie jetzt gerade, es ist nicht Curiosity, Perseverance auf dem Mars gelandet und das Ding muss ja teilweise autonom agieren können. Deswegen haben Sie da auch immer KI. Und Sie haben auch die andere Richtung, die Kognitionswissenschaften. Gibt auch teilweise das eigene Studiengang. Das ist eine Mischung aus allem, was halt mit Denken, mit Kognition zu tun hat. Linguistik, Neurowissenschaften, KI, Psychologie. Also da geht es um die Frage, wenn wir hier Denken erforschen, auf eine sehr mathematische Art und Weise, können wir davon Rückschlüsse ziehen, die wiederum in die Psychologie, Pädagogik zurückgehen und natürlich vieles mehr. Also es gibt wahrscheinlich mittlerweile kaum ein Fach, wo es keine Überlappungen gibt. Und jetzt kommt die kurze Geschichte der KI. Einfach, damit Sie mal sehen, wie sich die KI entwickelt hat. Was ich sehr spannend finde, weil es demnach herkommt. Viele Dinge wusste ich halt natürlich auch. Habe ich auch erst in der Uni gelernt. Und es ist sehr interessant, dass man auch mal sieht, was alles schon sehr früh ging und was noch nicht so lange geht. Sie haben schon 1912 den ersten Schachcomputer. Und der wurde entwickelt von Leonardo Torres y Quevedo. Und das ist ein elektromechanischer Roboter. Also es gab damals noch keine Computer in diesem Sinne, wie heute. Der kann das sogenannte K.R.K. Endspiel spielen. Also K.R.K. spielt für König Rook. Rook ist der Turm. Und der gewinnt in maximal 50 Zügen. Und das war für die damalige Zeit schon krass. Stellen Sie sich vor, das ist vor über 100 Jahren, würden Sie mal sagen, ich habe eine Maschine, die kann Schach spielen. Oder einen sehr kleinen Teil von Schach. Dann passierte, sagen wir mal, lange nichts. Was auch vielleicht an diversen Weltkriegen liegen könnte. Aber wie es immer so ist, Kriege haben die Forschung immer beflügelt, weil viel Geld reingeflossen ist. Und 1943 hat jetzt keinen Bezug zum Weltkrieg gehabt. Aber da haben die Warren McCulloch und Walter Pitts das künstliche Neuron, das Konzept entwickelt. Und das kombiniert verschiedene Erkenntnisse. Also Sie müssen sich vorstellen, auch damals, auch über das Gehirn war noch nicht so viel bekannt. Und das hat verschiedene Erkenntnisse kombiniert. Nämlich einmal, dass man das Gehirn als Netzwerk von Neuronen betrachten kann, zur Informationsverarbeitung. Und dass man Aussagenlogik, die es ja schon viel länger gibt als Computer, mit Binärwerten in Digitalrechnern abbilden kann. Und außerdem hat Alan Turing auch wieder mit seiner Turing-Maschine ein hypothetisches Berechnungsmodell entwickelt und gezeigt, dass alle erdenklichen mathematischen Berechnungen durch die Turing-Maschine durchgeführt werden können. Sie kennen vielleicht den Begriff Turing-Mächtig. Wenn nicht, werden Sie den wahrscheinlich noch im Studium hören. Aus diesen drei Erkenntnissen haben die kombiniert, dass jede erdenkliche berechenbare Funktion durch ein Netzwerk künstlicher Neuronen berechnet werden kann. Und außerdem schlugen die beiden vor, dass man solches Netzwerk auch durch Anwendungen geeigneter Regeln trainieren kann und dass es lernen kann. Das war damals schon, also das war der Vorschlag. Und sechs Jahre später hat dann Donald Hebb eine einfache Lernregel gezeigt. Ich hätte es genannt Hebb'sche Lernregel, die einfach sagt, wenn zwei Neuronen, also Neuronen sind Zellen, die verbunden sind, das ist die einfache Fassung, wenn zwei verbundene Neuronen gleichzeitig aktiv sind, dann wird die Verbindung zwischen beiden gestärkt. Das ist die Hebb'sche Lernregel. Und damit kann man schon ein paar tolle Dinge zeigen. Wie vorhin schon gesagt, 1950 hat dann Alan Turing den Turing-Test vorgeschlagen. Der hat jetzt ja kein neues Felder KI geöffnet oder hat eine neue Lösung präsentiert. Aber er hat eine sehr schöne Messlatte gesetzt, die bis heute nicht erreicht wurde, wie man eventuell Intelligenz abtesten kann. Und 1951 haben Marvin Winsky und Dean Edmonds SNARK gebaut. Das ist der Stochastic Neural Analog Reinforcement Calculator. Das war der erste Neural Network Computer. Der bestand noch aus Röhren. Und der simuliert ein Netzwerk aus 40 Neuronen. Wahnsinn. Also für die damalige Zeit war das ein Novum natürlich. Heute wird man müde über Lachen. Und 1955 haben Alan Newell und Herbert A. Simon den Logic Theorist programmiert. Der konnte zum Beispiel, also das war natürlich sehr rein logisch, hatte jetzt nichts mit Neuronen zu tun. Aber der konnte schon 38 von 52 Theoremen aus einem Buch namens Prinzipia Mathematica beweisen, was für die damalige Zeit auch schon sehr beeindruckend war. Er hat wohl sogar für einige Theoremen einen eleganteren oder kürzeren Beweis gefunden. 1956 wird im Allgemeinen oder von vielen als das Jahr als die Geburt der KI betrachtet. Dann hat John McCarthy die Datenaufkonferenz in Hanover, New Hampshire, also nicht das deutsche Hannover, initiiert und hat da Leute eingeladen, denen er noch viel zugetraut hat im Bereich KI, oder die Namen hatten. Unter anderem Marvin Minsky, Claude Shannon, Alan Newell, Herbert A. Simon. Viele von den Namen haben es bestimmt schon mal gehört, oder Sie werden sie noch öfter hören. Und es standen folgende wichtige Aussagen als Ergebnis dieser Konferenz. Nämlich, dass sämtliche Eigenschaften der Intelligenz in Form abstrakter Modelle präzise beschreiben lassen. Das ist ja erst mal eine umstrittene These. Also keine klare These, und sie könnte umstritten sein. Also auch heute, wenn es auch Leute gibt, die sagen, Intelligenz kann man nicht nur durch reine Mathematik abbilden. Vielleicht auch einige von Ihnen. Es ist eine offene Frage. Ich bin der Meinung, man kann, aber das war damals schon ein revolutionärer Gedanke. Und auch die Idee, dass Denkprozesse nicht ausschließlich dem menschlichen Gehirn vorbehalten sind. Und dass Computer das beste bekannte außer-menschliches Instrument für diese Denkprozesse sind. Und die Konferenz selbst hat jetzt keine Durchbrüche in der Forschung als Ergebnis gehabt, aber die Leute kannten sich jetzt halt erst mal, konnten zusammen forschen. Also die Big Players damals und haben für viele Jahre das Gebiet der KI dominiert. 1952 bis 1969 wird im Allgemeinen als die Ära des Aufbruchs und Begeisterung bezeichnet. Computer waren neu und man dachte, die können gut rechnen und das war es. Sie kennen vielleicht noch diesen einen Spruch. Ich glaube, das war der Chef von IBM, der gesagt hat, er glaubt nicht, dass mehr als fünf Computer weltweit notwendig sind. Und das war natürlich eine ganz andere Vorstellung von Computern damals als heute. Mein Herd kann ich auf Werkseinstellung zurücksetzen. Also der hat wahrscheinlich mehr Intelligenz als viele Computer aus den 50ern oder 60ern. Und eine häufige Erwartung war damals auf jeden Fall noch, eine Maschine wird niemals X können. Ja, also kann nicht. Maschine wird niemals Schach spielen können. Maschine wird niemals was übersetzen können. Maschine wird niemals Bilder erkennen, autonom fahren, was auch immer. Es gab immer jemanden, der gesagt hat, also das werden Computer nicht können. Mit dem Ergebnis, dass meistens KI-Forscher dann danach eine Maschine gebaut haben, die genau das konnten. Und das wird gerne als die Look-Ma-No-Hands, also guck mal Mama ohne Hände, wäre beschrieben. Weil einfach immer wieder Dinge, wo man sagte, das ist unheimlich schwierig, das geht nicht, gezeigt wurde, ja, hier, wir haben es mal gelöst. Unter anderem, also Sie müssen das nicht alles auswendig kennen, aber Schrödeleau von Terry Reinograd. Die Sprache Lisp, also Lisp Processing von John McCarthy. Das Perzeptron, das werden wir uns vielleicht noch ein paar Mal begegnen von Frank Rosenblatt. Eliza, das sagt Ihnen vielleicht was von Joseph Walzenbaum. Also Eliza war ein, kommt das noch? Nein. Eliza war ein Dialogsystem, also wir konnten damit chatten und es hat Antworten geliefert. Allerdings, es konnte, glaube ich, nur 50 bis 100 verschiedene Antworten und trotzdem hätte man im ersten Moment meinen können, man redet mit einem Menschen, weil es auf sehr, sehr einfachen Regeln basiert hat. Aber heutzutage könnte damit niemand mehr hier das Licht füllen können. Und der General Problem Solver von Alan Newell und Herbert A. Simon, also der sollte wirklich allgemeine Probleme lösen, jedes Problem lösen können. Und naja, danach kam die Ernüchterung. Also die Erwartungen waren halt sehr, sehr groß. Mit so Aussagen wie von 1958, in zehn Jahren werden Digitalcomputer den Weltmeister in den Schach schlagen und in zehn Jahren werden Computer neue mathematische Beweise entdecken und beweisen. Das war 1958, also 1968 wollte man das eigentlich schon geschafft haben. Wir sind jetzt so weit, aber das ist also eher 50 Jahre später als zehn Jahre später. Und Maschinen werden in der Lage sein, innerhalb von 20 Jahren, da war man schon etwas vorsichtiger, jede Arbeit zu machen, die ein Mensch tun kann. Innerhalb einer Generation, also Sie merken schon, man wird immer ein bisschen vorsichtiger, werden wir das Problem oder die Herausforderung, eine KI zu erschaffen, im Prinzip gelöst haben, hat Marvin Minsky gesagt, 1967. Und 1970 noch, also in drei bis acht Jahren, haben wir eine Maschine mit einer generellen Intelligenz ungefähr wie der Durchschnittsmensch, auch von Marvin Minsky. Ja, ich glaube, Spoiler Alert, es hat nicht funktioniert. Aber dieser Running Gag, dass es immer zehn Jahre weit entfernt ist, der hat der KI lange nach, hing ihr lange nach. Und noch ein schönes Beispiel ist die Übersetzung. Man dachte halt damals, also das Übersetzen durch Reihen ist eine taktische Umstellung und die Übersetzung einzelner Wörter ihr Ziel erreichen können. Ich weiß nicht, wenn Sie mal eine andere Sprache gelernt haben oder lernen, also ich nutze teilweise Duolingo einfach, um ein bisschen meine Sprachen oder mein Vokabular zu halten. Und wenn Sie da in die Foren schauen, haben Sie ganz viele Menschen, die wirklich sagen, aber das Wort heißt doch das, warum kann ich es nicht so übersetzen? Ja, die schlagen dann einfach ein Wort nach und sind der Meinung, ja, okay, dann muss ich doch Wörter übersetzen können. Und Sprache ist eben nicht so einfach. Und da gibt es dieses schöne Beispiel, der Satz, the spirit is willing, but the flesh is weak, wurde von dem Programm ins Russische übersetzt und vom Russischen wieder zurück übersetzt. Und das Ergebnis war, the vodka is good, but the meat is rotten. Also, das habe ich oft gelesen. Ich hoffe einfach mal, dass es keine Urban Legend ist, aber das liegt es hier an, dass natürlich die Worte keine eindeutige Bedeutung haben. Also der Geist, Sie kennen, wenn Sie hier von Himbeergeist reden, dann ist es ein Schnaps. Ja, aber der Geist kann genauso gut, der ist Spukgespenst sein oder der Geist, den Sie im Kopf haben, also Bachergeist, der Zeitgeist, also dasselbe Wort hat viele verschiedene Bedeutungen. Und welche hier genau gemeint ist, hängt im Kontext ab. Und das ist viel, viel schwieriger, als man damals dachte. Und Kontext und Hintergrundwissen waren viel wichtiger als gedacht. Und da wurde dann auch die Finanzierung eingestellt 1966, da man einfach keine Erfolge mehr vorzuweisen hatte oder zu erwarten war. 1969 hat dann lustigerweise genau Marvin Minsky einen Sargnagel damals in den neuronalen Netze reingehauen. Der hat nämlich bewiesen, dass das Perzeptron die XOR-Funktion, also exklusives oder, nicht abbilden kann. Vorher hat man doch gemeint, man kann ja alles lernen damit. Und das führt zu rapide Schwindelinteresse an neuronalen Netzen. Er hatte recht, er hat es bewiesen. Aber das Perzeptron, müssen Sie sich vorstellen, das ist ein neuronales Netz, was aus einem Neuron besteht, einem einzigen. Und das XOR sehr wohllösbar ist mit zwei Schichten, ich glaube es reichen, ich glaube drei Neurone reichen aus, ansonsten sind es fünf. Das ist also lösbar, aber es hat damals dazu geführt, dass man dachte, oh neuronaler Netz könnte doch gar nicht so viel und das Interesse ist stark gesunken. Was ansonsten in der Zeit dann stattdessen hoch kam, waren die wissensbasierten Systeme oder auch Expertensysteme genannt. Gibt es auch heute noch. Also man hat einfach jetzt gesagt, also wir haben ja Experten und die haben Wissen und wir müssen dieses Wissen extrahieren und daraus Regeln ableiten, also Heuristiken. Und deswegen gab es damit auch sehr verstärkte Forschung an Wissensrepräsentationen. Also wenn Sie jetzt, was nehmen wir denn mal, sagen wir mal, Sie haben jetzt jemanden in der Versicherungswirtschaft oder Automobilbau, da kenne ich mich ein bisschen mit aus. Sie haben jemanden in Automobilbau und jetzt haben Sie einen Experten und der hat schon 30 Jahre Erfahrung und der sagt dann, nee, also hier brauchen Sie gar nicht mit Aluminium zu kommen, das ist viel zu, keine Ahnung, das geht nicht, da brauchen Sie schon Stahl. Oder nee, hier dürfen Sie gar keinen Kunststoff nehmen, das schwilzt. Und dann fragen Sie ja, was heißt denn hier und dann sagt, naja, wenn die Temperatur über so und so Grad ist, dann brauchen Sie dieses Material. Und solche Regeln kommen dann da langsam, kommen da vielleicht raus. Die hat man gesammelt und das müssen Sie ja irgendwie repräsentieren. Also der Satz, wir haben eben schon gemerkt, Sätze zu analysieren ist nicht so einfach wegen Kontext, deswegen mussten wir das formalisieren. Das heißt, es war sehr verstärkte Forschung daran, wie man Wissen wirklich auch für Computer verarbeitbar darstellt. Und da gab es auch Systeme wie Dendril oder Mycin. Mycin war ein Expertensystem, lassen Sie mich nicht lügen, der Name sagt ja schon, dass es da um Pilze geht und also in der Medizin wurden die teilweise eingesetzt. Mycin war ein Expertensystem von 1972 zur Erkennung, genau, zu Infektionskrankheiten also nicht nur Pilze. Und Sie müssen sich vorstellen, da geben Sie ein paar Ergebnisse von Analysen rein und dann sagt der, oh, es könnte das sein, testen Sie mal das. Und so hat man sich nach und nach dann zur Krankheit vorgearbeitet. Und das war recht erfolgreich. Außerdem hatten Sie dann noch Prolog, eine logische Programmiersprache, haben Sie vielleicht auch schon mal gehört. Also logische Programmiersprachen waren damals sehr in und wir werden ein paar davon auch eventuell alles mal anschauen. Also einfach, dass Sie es mal gesehen haben, auch wenn das heute keine Relevanz mehr hat. Aber Sie kennen vielleicht, es kommt irgendwie mal vor, dass Sie irgendwo so News lesen, dass man irgendwelche alten Informatiker aus der Pension oder aus dem Ruhestand holt, weil sie die einzelnen Programmiersprachen noch können und die Systeme verwalten können, weil es heute einfach nicht mehr beigebracht wird. Das war alles, also wir waren ja vorhin bei 1969 bis 1974, also das sind alles ungefähre Zeitangaben.)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 Direkt danach folgte der sogenannte erste KI-Winter. Also ich habe in meinem Studium noch sehr viel über KI-Winter gehört, wenn ich es danach, als ich danach recherchiert hatte, finden Sie verschiedene Darstellungen oder auch nicht so prominent die Bezeichnung KI-Winter, aber ich fand das sehr einprägsam. Das waren Anlehnungen an den nuklearen Winter, also wo danach nichts, nach dem Atomkrieg nichts mehr wächst, weil alles zugeschneit ist und keine Sonne mehr auf die Erde kommt. Im Prinzip hat man durch die vielen Versprechungen und die nicht eingehaltenen Versprechungen das Interesse und die Investitionen so geschädigt, dass da erstmal nichts mehr gewachsen ist an KI oder nicht viel. Damals wurde so viel Geld draufgeworfen auf die KI und hat man irgendwann gesagt, also da kommt ja nichts zurück, also wir streichen jetzt alle Forschungsgelder für undirected explanatory research. Also hat gesagt, so hier hast du ein paar Millionen Dollar und forsch mal bitte. Und Sie kennen, heute ist es ja so, heute brauchen Sie immer auch heute noch ein sehr genaues Forschungsziel. Einfach sagen, ich forsche an KI, damit werden Sie wahrscheinlich kein Geld kriegen. Die Probleme damals waren halt auch, dass Sie dann noch eine sehr beschränkte Rechenkraft hatten. Also wir reden hier von den 70ern. Das ist wirklich alles nicht zu vergleichen zu dem, was wir heute an Rechenfrauen haben, allein schon, was wahrscheinlich jeder zu Hause stehen hat. Die Bewegungserkältung der Netzhaut hat man, kann man schätzen, mit circa 1000 Millionen, also eine Milliarden Instruktionen pro Sekunde. Also allein, was die Nervenzellen in Ihrer Netzhaut, nicht mehr hinten im Gehirn, sondern in der Netzhaut leisten, betrifft das um Vielfaches, was die schnellsten Suchcomputer damals konnten. Die hatten nämlich maximal 100 Millionen, also Million Instruktionen pro Sekunde. Und viele Dinge waren dann auch aufgrund der Rechenkraft nicht lösbar. Und das Problem ist auch, wenn Sie sich viele Probleme anschauen, also die von Ihnen, die jetzt schon Algorithmen und Datenstrukturen gehört haben, also Informatiker von Ihnen kennen das, die VZler kennen, wenn sie das nächste Semester hören, vermute ich auch bei mir übrigens, da haben Sie bei ganz vielen Problemen eine kombinatorische Explosion. Also Sie haben ganz schnell auch im echten Leben, gibt es so viele Dinge zu beachten, so viele Variablen, dass Sie so viele Möglichkeiten haben, dass Sie unheimliche Rechenpower brauchen, um das zu lösen. Zum Beispiel Sprachverständnis, wenn Sie versuchen würden, alle möglichen Sätze, die es gibt, auch zu listen. Naja, das wären sehr viele, wenn nicht sogar unendlich viele. Das hat 1980, wurde das oder bildet sich das sogenannte Bora-Wegsche-Paradox, nämlich, dass es vergleichsweise einfach ist, einen Computer dazu zu bringen, Leistungen auf Erwachsenenniveau bei Intelligenztests oder beim Damenspielen zu erbringen. Also Schachcomputer waren damals schon möglich, aber es ist schwierig oder unmöglich, in die Fähigkeit eines Einjährigen in Bezug auf Wahrnehmung und Mobilität zu vermitteln. Also wir denken daran, Schachspielen konnten Computer schon lange, aber Laufen auf zwei Beinen nicht so. Und das ist ja schon seltsam, dass man sagt, man konnte einfach die Sachen, die nur auf Logik basieren, viel einfacher nachbilden, als die Sachen, die andere Dinge als Logik benötigen. Und Hans Moraweg hat das so formuliert, im Allgemeinen sind wir uns am wenigsten bewusst, was unser Verstand am besten kann. Wir sind uns einfacher Prozesse, die nicht gut funktionieren, mehr bewusst als komplexe Prozesse, die fehlerfrei funktionieren. Also wenn ich Sie jetzt fragen würde, also ich gebe Ihnen einen Ball zu, und Sie sollen mir erklären, wie Sie den jetzt fangen, also woher Sie wissen, dass Sie da die Hand hin tun sollen, Sie können es wahrscheinlich auch nicht erklären. Ich könnte es Ihnen auch nicht erklären. Aber wenn ich Ihnen jetzt erkläre, wie Sie, oder wenn Sie mir erklären sollen, wie man eine Ableitung herstellt, mathematische Ableitung, oder wie man den größten gemeinsamen Teil erfindet, das ist relativ einfach zu erklären, aber das ist halt rein logisch. Und das wurde hier als Moraweg-Schutzparadox bezeichnet. In den 80ern gab es dann wieder die ersten kommerziellen Erfolge in der KI. Also Expertensysteme haben sich dann doch ein bisschen durchgesetzt. Es gab die verschiedensten Anwendungen, also R1, später ist es X-Con zur Konfiguration von Macs, das waren auch wieder Rechner. Und das war so, also das hat auch Geld verdient. Das war der erste Beweis, dass KI echt nützlich sein kann. Also auf einmal haben die Firmen da auch was wieder investiert, weil es nicht einfach nur ein Geldgrab war, sondern auch was damit verdienen konnte. Und das hat dazu geführt, dass auch wieder KI im größeren Stil gefördert wurde und viele Firmen eine KI-Abteilung hatten. Dann kam der zweite KI-Winter, das hat sich nämlich herausgestellt, dass sie, wenn sie so ein Expertensystem haben, also wir haben ja gesagt, ein Expertensystem, das basiert auf vielen Regeln von Experten. Und Sie können sich vorstellen, da kommt immer mehr Wissen hinzu. Aber das neue Wissen beeinflusst das alte Wissen. Die Regeln interagieren und deswegen wurde die Wartung immer teurer. Irgendwann haben sie mehr Aufwand gehabt, so ein System zu warten, als sie Zeit hatte. Und da sind die so ein bisschen an ihr Ende gestoßen. Und Desktop-Computer, IBM und Apple wurden schneller als teure Lisp-Computer. Also wir hatten ja vorhin Lisp, also diese Sprache, Lisp-Processing, das war damals quasi das, womit man KI gemacht hat. Während meiner Doktorandenzeit, als ich auch eine Vorlesung KI betreute, hat mein Doktorvater die ersten vier Übungsblätter nur in Lisp machen lassen. Und ich sage Ihnen, das ist kein Spaß. Das artet meistens daran aus, dass Sie die fehlende Klammer suchen, weil Sie haben mehr Klammern als sonst was in dieser Sprache. Wir werden uns das mal anschauen, einfach mal, einfach damit Sie sehen, wie gut Sie es jetzt haben, dass Sie andere Sprachen nutzen können. Das war damals aber das, was man genutzt hat. Und da gab es Firmen, die haben spezielle Computer hergestellt oder programmiert, die nur das konnten. Und dieser Markt ist dann auch eingebrochen. Und es gab in Japan ein großes KI-Projekt, Fifth Generation, hat auch die Erwartung nicht erfüllt, also wieder mal zu große Versprechungen. Und dann ist das Interesse wieder zurückgegangen. 1986 gab es dann auch die Rückkehr der neuronalen Metze. Wie gesagt, hatte Minsky der ganzen Sache so ein bisschen einen Sargnagel, den letzten Sargnagel verpasst und das Interesse ging zurück. Dann hat man aber die sogenannte Backpropagation-Lernung wiederentdeckt. Das wurde schon vorher 1969 von Bryson und Ho entwickelt. Da geht es also darum, wie Sie in einem tiefschichtigen neuronalen Netzwerk oder einem mehrschichtigen neuronalen Netzwerk die Gewichtung, die Verbindung zwischen Neuronen anpassen können. Und also das wurde schon mal entdeckt, aber was hat man da jetzt wiederentdeckt? Und das führte auch zu der Wiederentdeckung oder dem Aufkommen des Konnektionismus als Gegensatz zu symbolischen Ansätzen. Das werde ich später vielleicht noch mal kurz erwähnen, aber um es hier mal zu sagen, wenn Sie, nehmen wir das Beispiel nochmal mit Formelnbeweisen oder solchen Sachen, ableiten, Logik einfach. Sie haben Symbole. Sie haben sowas wie f von x gleich x Quadrat, steht auf Symbolen. Die Symbole sind einfach verarbeitbar. Sie können einfache Regeln anwenden. Es sind wenig Symbole vor allem, wenn Sie aber jetzt eine Bilderkennung haben zum Beispiel und Sie haben eine Kamera, die jetzt nur Voll-HD-Auflösung hat. Dann haben Sie ja Millionen von Pixeln, Millionen von Werten und Sie können nicht jeden einzelnen Wert eine Bedeutung und Symbol zu messen. Und das ist der Konnektionismus, der, wo man gerne unterteilt zwischen symbolischer und sub-symbolischer KI. Symbolisch heißt, Sie haben einzelne Einheiten. Ein Wort ist ein Symbol. Ein Zeichen ist ein Symbol. Und Sie machen Symbolmanipulation. Und beim sub-symbolischen Ansatz, wie in normalen Netzen, haben Sie sehr, sehr viele Zahlen, die in sich keine Bedeutung haben, aber im Zusammenspiel auf einmal intelligentes Verhalten zeigen. Was man ja bei normalen Netzen, vor allem am Deep Learning stark sehen kann, dass dieser Konnektionismus einfach ein sehr guter Ansatz ist. Und normalen Netzen wurden dann wieder mächtiger. Man konnte viel mehr Probleme auf einmal damit lösen. Außerdem wurde die KI empirisch. Die KI war lange rebellisch über der Statistik. Also, wenn Sie so sind wie ich im Studium, dann haben Sie nicht viel Interesse an Statistik oder verstehen es nicht oder mögen es nicht. Und wahrscheinlich ging es den Leuten damals auch so. Und Statistik war ihnen damals zu stringent. Und man hat gesagt, nein, wir machen einfach mal. Wir machen das alles anders. Und die haben sich damit auch ein bisschen davon losgelöst und wollten sich loslösen. Und dadurch wurde KI auch rebellisch mehr, aber isoliert, weil man mit denen nicht gesprochen hat. Man wollte ja alles anders machen. Und nach und nach hat man sich wieder angenähert, weil man gemerkt hat, dass diese klassischen Methoden in der Mathematik, die sind ja alle seit Jahrzehnten, Jahrhunderten teilweise bewiesen. Sie haben sehr, sehr fundierte Grundlagen, auf denen Sie aufbauen können, wo Sie Dinge beweisen können, wo Sie Dinge einfach mal mathematisch herleiten können. Und durch diese Annäherung wurde das Ganze ein bisschen erwachsener. Also empirisch in dem Fall jetzt. Beispiele sind zum Beispiel Hidden Markov Models oder Bayesian Methoden, mit denen Sie auch sehr genau quantifizieren können, wie gut ist Ihre Lösung, wie sicher sind Sie sich Ihrer Lösung. Und das hat der KI nochmal eine neue Richtung verpasst. Ich weiß nicht, was Ihr Jahrgang ist, aber ich habe es noch nicht bekommen. Live damals am 11. Mai 1997 hat der Computer Deep Blue erstmals den Schachgrossmeister, Weltmeister Gary Kasper aufgeschlagen. Und das war damals ein Meilenstein. Wir erinnern uns, ich gehe mal kurz zurück, wir erinnern uns, das hat, haben wir es hier, ja, 1958 hat man gedacht, dass man innerhalb von zehn Jahren den Schachweltmeister besiegt. Hat ein bisschen länger gedauert, sagen wir mal 30 Jahre statt zehn Jahre, aber es hat funktioniert. Und Sie werden es vielleicht wissen, auch damals haben, kann sein. Übrigens auch ein beliebtes Thema, also ein Kommentar ist, dass er nicht gut gespielt hat. Ein Thema ist, oder ein Argument ist, dass die Leute denken, ja, ich spiele Computer so gut, kann ja nicht sein. Und dann spielen sie nicht so gut, wie sie könnten, weil sie den Computer unterschätzen. Ist auch ein Faktor. Ich glaube, in Wahrheit er hat auch dreieinhalb zu zweieinhalb gewonnen. Also es gab sehr viele Unentschieden. Und Gary Kasper hat, glaube ich, sogar vermutet, dass es nicht so war, Dinge nicht mit rechten Dingen zu gehen, dass da vielleicht Menschen geholfen haben. Und trotzdem, das war, also es war schon ein Meilenstein, also es war schon ein Moment in der Geschichte, wo man sagt, oh, jetzt hat ein Computer was geschafft, was man sonst nur nur Menschen, oder wo Menschen besser waren. So ist dann auch passiert, dass nach und nach Computer immer besser wurden, in denen Menschen bisher einfach die Führung hatten. Dazu kommt, dass sie ab den 2000ern die Verfügbarkeit von sehr großen Datensätzen auf einmal haben. Also wir reden jetzt hier nicht von Big Data, aber man hat früher sich auf Algorithmen fokussiert. Ja, wir wollen den Algorithmus verbessern. Man hat dann aber auch gemerkt, dass man mit besseren Daten auch was reißen kann. Und zum Beispiel, also das eine Beispiel, was ich herausgepickt habe, ist das Wort Bank. Bank kann Sitzgelegenheit bedeuten oder Kreditinstitut. Auf der Bank können Sie sitzen oder Sie bringen Ihr Geld auf die Bank. Und jetzt nehmen Sie mal eine Handvoll Sätze und sollen jetzt unterscheiden, also ein Programm schreiben, was entscheidet, welches, was gerade gemeint ist in diesem Satz. Und die Idee war, die Unterscheidung nur anhand von Wortdefinitionen zu machen, also ungelabelten Beispielsätzen und, also nee, anhand von Wortdefinitionen und ungelabelten Beispielsätzen. Also ich gebe Ihnen quasi jetzt die Duden-Definition von Bank und hunderttausende Millionen von Beispielsätzen, wo das Wort drin vorkommt. Und ein mittelmäßiger Algorithmus mit 100 Millionen Wörtern als Trainingsdaten ist besser als der beste Algorithmus mit nur einer Million Wörter Trainingsdaten. Also allein durch die schiere Masse an Trainingsdaten konnten wir das Problem lösen oder erschlagen, was übrigens auch jetzt beim Deep Learning oft vorkommt. Wenn ich lese, was, also wenn Sie mal googlen, was ist Deep Learning, finden Sie auch sehr viele Definitionen, die, sag ich mal, aus Bereichen kommen, die nicht Informatiker sind, wo dann oft gesagt wird, Deep Learning braucht sehr, sehr viele Daten. Das stimmt. Das ist nicht das, aber nicht das, wobei ich Deep Learning definieren würde. Aber hier ist es auch so. Sie haben, wenn Sie die Regelmäßigkeiten erkennen wollen, brauchen Sie viele Daten. Und hier hat sich gezeigt, dass, wenn Sie die Daten besser auswählen und viel mehr Daten haben, Sie auch Probleme teilweise besser lösen können, als wenn Sie einfach nur den Algorithmus verbessern. Und da war auch die Erkenntnis, dass manche Probleme sich besser durch Lernen lösen lassen, als durch handgemachte wissensbasierte Systeme. Das sind auch die beiden Welten. Wissensbasierte Systeme oder viele Algorithmen der KI sind handgemacht, wenn Sie so wollen, Intelligent Design. Sie haben eine Idee und sie programmieren das intelligente Verhalten. Und da ist nichts mehr dem, sag ich mal, dem Zufall überlassen. Das ist alles vorgegeben. Und beim Lernen, auch beim machine learning Lernen, haben sie ein paar Grundregeln definiert, den Rest lernt das System von alleine. Und Umfragen in den 2000ern haben aber ergeben, dass KI immer noch schlecht angesehen war. Da gibt es ein paar schöne Zitate im Economist von Juni 2007. Da hat ein Investor gesagt, also sie wurden von dem Begriff Spracherkennung ein bisschen abgeschreckt, weil es wie das Wort künstliche Intelligenz mit Systemen verbunden wurde, die sehr oft einfach nicht das eingehalten haben, was sie versprochen haben. Patty Tascarella in der Pittsburgh Business Times hat gesagt, manche glauben, dass das Wort Robotik mittlerweile genauso ein Stigma trägt wie KI und die Finanzierung von Firmen sogar schädigt. Stellen Sie sich vor, Sie nennen etwas Blablabla Robotics und Sie wissen ja, dass noch die, die Sachen nicht können. Dann würden Sie auch weniger Geld reingeben. Das ist im Prinzip das Gegenteil davon, was Sie heute teilweise haben, dass Firmen einfach nur irgendwo Bitcoin oder Cryptocurrency in ihren Namen stecken und auf einmal Geld erhalten. Also die Worte waren ein bisschen verbrannt. Und das war sogar so, dass auch jemand gesagt hat in den New York Times, also im Tiefpunkt haben Computerwissenschaftler, also Computer Scientist und Software Engineer den Begriff KI einfach komplett vermieden, einfach weil man Angst hatte, dass man das einfach nur als hingespinzt oder als, naja, als klappt ja eh nicht erkennt oder sieht. Und das hat auch dazu geführt, dass sich dann diese auch viele Teilgebiete der KI ergeben haben, die sich nicht mehr KI genannt haben. Zum Beispiel maschinelles Lernen, kognitive Systeme, wissensbasierte Systeme. Also in den 2000ern, also ich habe ja von 2003 bis 2008 studiert, da war es wirklich noch so, dass ich damals oft dachte, ach, das ist doch eher KI, aber man hat es nicht KI genannt. Wissensbasierte Systeme, Mustererkennung, also Pattern Recognition, einfach weil der Name KI verbrannt war. Und jetzt ist die Frage, was ist der Stand heute? Der KI-Effekt ist, dass mittlerweile sehr viele KI-Anwendungen, also KI-Methoden in die Anwendung geschafft haben und ohne, dass man die KI nennt. Sie haben es gerade eben gehört, weil man KI nicht so toll fand, den Begriff, oder weil er negativ konnotiert war. Und das führt dazu, dass KI jetzt überall ist und man es nicht als solcher erkennt, weil man es auch nicht so nennt. Das Umgekehrte ist auch der Fall. Ich rede, da kommen KI-Chips in Handys und da werden KI-Chips gebaut und eigentlich sind es nur, sage ich mal, in GPUs, also Schleuder-Prozessoren. Aber man nennt es jetzt wieder KI. Aber 2006 hatten sie noch sehr viele KI-Systeme, die man einfach nicht so genannt hat und das hat dazu geführt, dass das nicht so ankam. Also man hat die Erfolge nicht als KI erkannt. Und da hat Marvin Minsky, der lebt leider nicht mehr, das war 2016, ist er gestorben, aber der hat es nochmal zu Wort gewählt, 2011, gesagt, das Paradoxe an der Situation ist, dass jedes Mal, wenn ein KI-Projekt einen Erfolg hatte, eine neue Entdeckung gemacht hat, dass man das schnell, dass es ein Produkt gab, was eine neue Art von, was man als neue Spezialität bei einem Spin-off, neue Methode, neue Richtung erkannt hat oder genannt hat, mit einem eigenen Namen und das man dann nicht mehr mit KI assoziiert hat. Und dann Fragen außenstehende, ja, aber warum macht KI keine Fortschritte? Weil die Fortschritte in lauter Teilgebieten der KI entstanden sind, die manche nicht mit KI assoziiert haben. Und sehr schön ist auch, das gilt auch heute noch von 1970, das Zitat, Intelligenz ist, was auch immer Maschinen noch nicht gemacht haben. Als das erste Mal erklärt wurde oder bekannt wurde, wie die Blue funktioniert, also der Schachcomputer, dass er nämlich einfach, grob gesagt, alle Kombinationen, alle möglichen Züge bis einer gewissen Tiefe durchprobiert, hat man gesagt, das ist ja keine Intelligenz, der probiert ja nur durch. Und so ist es auch jedes Mal, wenn Sie jetzt eine KI programmieren, die irgendwas löst, eine Wegfindung, hier Routenplanung, sonst irgendwas, da heißt es dann, wenn jemand versteht, wie es geht und merkt, das ist ja eigentlich ganz viel Rechnen und ganz viel Mathematik, dann heißt es oft, das ist ja keine Intelligenz. Da sind wir wieder bei diesem Vergleich, kann ein U-Boot schwimmen? Das ist, wenn wir sagen, ja, das ist ja kein Schwimmen in dem Sinne. Und da sagt man, ja, es ist ja kein Denken in dem Sinne. Wieder bei dem Punkt, Intelligentes Handeln und Intelligentes Denken. Intelligentes Denken wird in Programmen einfach auch abgesprochen, aber Intelligent Handeln, naja, soweit sind wir mittlerweile schon. Ich habe diese Folie nochmal, also Verzeihung an die Informatiker, die es schon gesehen haben, die Folie kennen Sie. Ich habe 2015 einen Vortrag gehalten und habe damals diese Folie gemacht, Stand der KI heute, also das ist jetzt schon sechs Jahre alt, einfach um Ihnen auch nochmal den Vergleich zu geben, was hat sich seitdem getan. Das autonom fahrende Auto von Google hat 2015 elf Unfälle auf 1,5 Millionen autonom gefahrenen Kilometern verursacht und an keinem oder war beteiligt gehabt und an keinem davon war das Google Auto selbst schuld. Mittlerweile gibt es ein paar mehr Fälle, wo selbstfahrende Autos schuld waren, aber das war, also dieser Treppenblitz, dass es immer zehn Jahre entfernt ist, kommt langsam zum Ende, weil die KI nun doch schon nah dran ist. Genauso die Spracherkennung. Ich habe es gestern auch schon erzählt. Ich kann mich an Spracherkennung erinnern, dass es nicht funktioniert hat. Trepperquoten von 90, 95 Prozent, also hier ist das zwanzigste Wort falsch und das hat mir damals, war für mich nicht anwendbar. Vor allem auch, weil ich schnell spreche, war für mich die Spracherkennung nie richtig gut. Aber wenn ich jetzt sehe, was mein Handy oder was Amazon Alexa alles erkennt, ist schon sehr beeindruckend. Also auch was für einen Akzente, Genuschel, Dialekte, verschiedene Sprachen, ist schon krass, was es kann und wir sehen sie ja auch in der FAZ von 2014 war auch der Kommentar Spracherkennung. Das war auch die Technik, die nicht perfekt funktioniert hat, oder? Und die Leute waren überrascht, weil sie es auch noch kennen als so klappt es ja auch nicht. Und so wie man von KI-Wintern redet, redet man auch oft vom KI-Frühling, also das ist nach dem Winter kommt der Frühling, dass durch Deep Learning jetzt wieder sehr viele KI-Anwendungen, also sehr viel KI in den Fokus gerückt ist. Es gibt wieder richtigen KI-Hype. Alles ist Deep Learning. Überall heißt es, wir wollen nicht Deep Learning machen. Und das wird auch erfolgreich eingesetzt, wie gesagt, bei Amazon Alexa, Google Sprachassistent, Apple Siri, was sie alles haben. Sie haben Spiele-KIs, die mittlerweile Menschen schlagen. AlphaGo Master hat neue Strategien entwickelt. AlphaGo Zero im selben Jahr entwickelt hat, also beim Go-Spiel, hat sogar erfolgreiche Beispiele gelernt, indem es nur gegen sich selbst gespielt hat und dadurch die Regeln gelernt hat. Und nach nur 40 Tagen, aber immensen Hardware und wahrscheinlich auch Stromkosten, war es besser als alle seine vorherigen Versionen. Und 2019 hat AlphaStar in StarCraft II Großmeisterrang erreicht. Und das ist hier nochmal was anderes, weil das in Echtzeit Strategiespiel ist und nicht rundenbasiert wie Schach oder Go. Also die Frage kam gestern, rundenbasiert heißt ja in dem Fall, sie haben fast beliebig viel Zeit. Sie haben eine gewisse Zeit, ihre Entscheidung, ihren nächsten Zug zu überlegen und dann lässt der Gegner seinen Zug. Und in Echtzeit, während sie überlegen, entwickelt sich die Welt weiter. Das ist der große Unterschied und deswegen ist es nochmal schwieriger, weil sie schnell Entscheidungen treffen müssen und auch während sie Entscheidungen treffen, vielleicht neue Informationen in ihre Entscheidungen einfließen lassen müssen. Und Deep Learning hat viele Durchbrüche verursacht. Also ich habe auch gesehen, ein paar von ihnen haben letztes Semester das Seminar Machine Learning bei Thomas Wieland belegt. Also ein paar von ihnen haben das hier schon mal gesehen vermutlich. Sogenannte Convolutional Neural Networks erkennen Ziffern besser als Menschen, schon seit einigen Jahren, auch Verkehrsschilder glaube ich. Also sie machen weniger Fehler. Es gibt Neural Style Transfer, der den Stil von Gemäden auf Bilder übertragen kann. Das ist auch Deep Learning. Super Sampling erzeugt hochauflösende Bilder aus kleinen Bildern. Sie können also eine kleine Auflösung auf eine hohe Auflösung hochrendern, sagen wir mal voller DO4K. Deep Learning, NVIDIA nennt es DLSS, also vermutlich Deep Learning Super Sampling, aber ich glaube, ich habe einen TM vergessen, der Begriff gehört denen. Deep Fake, wo sie Gesichter auf andere Personen draufsetzen können. Und GANs, also Generative Adversarial Networks, die echt aussehende Fotos erzeugen können und auch ganz viele andere Dinge erzeugen können. Also es gibt die Website This Person Doesn't Exist oder This Cat Doesn't Exist. Und das ist einfach krass, was diese Netzwerke können. Und das selbstfahrende Auto ist jetzt wirklich nur noch wenige Jahre entfernt. Diesmal wirklich.)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | results
 Aber das ist auch schon eine sehr, sehr kondensierte Zusammenfassung. Also einmal, das haben die aus GML schon gesehen, also Grundlagen des Maschinenlernens heißt die Vorlesung GML, dass KI selbst ein großes Gebiet ist, was viele Teilgebiete umfasst. Sie haben die ganzen Stichworte vorhin schon gesehen. Sie wollen Wissen repräsentieren. Also Wissensrepräsentation ist ein eigenes Gebiet. Automatisches Schließen ist ein Gebiet. Planen, Problemlösen. Das Maschinenlernen ist ein sehr großes, sehr sichtbares Gebiet. Computervision, jetzt wegen autonomem Fahren in aller Munde. Und natürlich auch für Sprachassistenten die Verarbeitung Sprache oder Automatische Besetzen. Hier nochmal, wie in der anderen Vorlesung, die Disclaimer. Für die meisten Begriffe gibt es englische Fachworte. Die deutschen klingen entweder komisch oder beschreiben das nicht ganz genau, was eigentlich gemeint ist. Deswegen, ich versuche konsistent zu bleiben in Deutsch-Englisch. Aber bitte verzeihen Sie mir, wenn ich dann oft so deutsch-englische Mischtexte habe, einfach weil der englische Begriff auch prägnanter ist und das Thema besser erfasst und Sie unter dem Begriff auch meistens die Literatur finden. KI hat natürlich Überlappungen mit anderen Fächern, mit Big Data, Data Science, Data Mining. Also ich bin auch überrascht, wie viele andere Vorlesungen hier schon Data Mining machen, was sich dann sehr stark mit Machine Learning überdeckt. Nicht ganz das Gleiche ist, aber große Beschneidung hat. Robotik natürlich, wo Sie jetzt natürlich Intelligenz verhalten wollen, wenn Sie autonomes Fahren oder autonome Roboter denken. Ja, sehen Sie jetzt gerade, es ist nicht Curiosity, Perseverance auf dem Mars gelandet und das Ding muss ja teilweise autonom agieren können. Deswegen haben Sie da auch immer KI. Und Sie haben auch die andere Richtung, die Kognitionswissenschaften. Gibt auch teilweise das eigene Studiengang. Das ist eine Mischung aus allem, was halt mit Denken, mit Kognition zu tun hat. Linguistik, Neurowissenschaften, KI, Psychologie. Also da geht es um die Frage, wenn wir hier Denken erforschen, auf eine sehr mathematische Art und Weise, können wir davon Rückschlüsse ziehen, die wiederum in die Psychologie, Pädagogik zurückgehen und natürlich vieles mehr. Also es gibt wahrscheinlich mittlerweile kaum ein Fach, wo es keine Überlappungen gibt. Und jetzt kommt die kurze Geschichte der KI. Einfach, damit Sie mal sehen, wie sich die KI entwickelt hat. Was ich sehr spannend finde, weil es demnach herkommt. Viele Dinge wusste ich halt natürlich auch. Habe ich auch erst in der Uni gelernt. Und es ist sehr interessant, dass man auch mal sieht, was alles schon sehr früh ging und was noch nicht so lange geht. Sie haben schon 1912 den ersten Schachcomputer. Und der wurde entwickelt von Leonardo Torres y Quevedo. Und das ist ein elektromechanischer Roboter. Also es gab damals noch keine Computer in diesem Sinne, wie heute.)
2025-10-19 22:56:25 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | retrieval 14)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | results
 Jetzt. Aber das ist so der Hauptgrund, warum das mit so bekannt wurde und so gehalten wurde. Das sind so ein paar Anwendungsgebiete. Und jetzt sagt ihr vielleicht, ja Marcel, das ist ja ganz cool, das sieht ja auch cool aus, aber braucht man denn sowas überhaupt in der Realität? Was macht man denn damit, wenn man so viele Bilder einfärben kann? Das bringt doch nichts. Tja. Und deswegen habe ich mal den Ausschnitt mitgebracht. Das sind momentan laufende Competitions. Ja, da ist kein Zahlendreher. Also das sind 1,5 Millionen für den Gewinner. Wo man natürlich nicht unbedingt Deep Learning benutzen muss, aber es liegt nahe, dass man es benutzt. Leider kann man das nicht so gut lesen, aber im Grunde geht es darum, so Passenger Screening, also man kriegt irgendwie so ein paar Bilder von... Ich weiß es nicht hundertprozentig, aber ich denke mal von so X-Ray-Aufnahmen, also so Flugzeughafen, wo man durch diese Schranken gehen muss und vielleicht kriegt man noch ein paar Signale, wo es gepiept hat, keine Ahnung. Und dann soll man sagen, okay, ist das eine Waffe oder ist das was Gefährliches oder hat er einfach bloß ein Piercing oder was weiß ich. Das ist so das zweite. Value Prediction, also wie viel ist ein Haus in 10 Jahren an diesem Standort und so weiter wert. Da wird auch ziemlich viel Geld reingebuttert, wie man sieht. Das ist so ein Bild von UNICEF oder so, oder UNESCO, keine Ahnung. Aber gibt es auch. Und halt, was man ziemlich oft sieht, was die Unternehmen auch am meisten, also wenn sie jetzt nicht gerade so viel Geld ausgeben wollen, am meisten sehen, ist diese Market-Analyse. Also wenn ich einen Kunden habe, der jetzt dieses Buch gekauft hat und das hier und das hier und das hier, was wird er dann als nächstes kaufen? Und tatsächlich benutzt man da auch Deep Learning oder probiert es zumindest. Und da kommen auch coole Sachen bei raus. Also ihr seht auf jeden Fall, es wird gefragt. Also die laufen aktuell noch, man sieht hier noch, fünf Monate to go, das habe ich vor einer Woche oder so gemacht. Also wer Lust hat, kann da mal mitmachen. Ich habe da auch ein paar Mal mitgemacht. Das war sehr lehrreich, weil ich herausgefunden habe, dass ich ungefähr miserabel bin. Ist aber auch kein Wunder, wenn es da um 1,5 Millionen Dollar Preisgeld geht, also da macht halt wirklich die Spitze aller mit. Und da hast du natürlich so alleine, kannst schon mal machen, aber du solltest nicht so wie ich so blauäugig rangehen und sagen, Top 100 geht locker. Ich glaube, ich war irgendwie 400 von 500 insgesamt oder so. Auf jeden Fall, man kann es mal machen. Das ist cool, man lernt viel. Also ich habe viel gelernt, die Leute tauschen sich auch aus. Das ist echt cool. Und wenn mal jemand das mitmachen will, ist cackle.com. Es gibt auch noch andere Seiten, aber das ist so das Größte, was ich kenne. Und das ist auch ganz lustig. Soweit so gut. Gehen wir jetzt mal zu den interessanten Sachen oder zu den bisschen formaleren Sachen. Und schauen uns mal den Familienstammbaum der Neuronalen Netzwerke an. Weil neulich hat mir so jemand gesagt, ja, ich kenne da schon die Artificial Neural Networks, aber, nein, andersrum. Der hat gesagt, ich kenne da die Feed Forward Neural Networks, aber Artificial Neural Networks sagt mir gar nichts. Und ich meine so, ja, im Grunde ist das bloß der Überbegriff. Ach so. Also deswegen dachte ich so, ganz kurz mal den Tree durchgehen. Im Grunde Artificial Neural Networks ist so alles, was man sich vorstellen kann, wo irgendwelche Neuronen beteiligt sind, und die sich beeinflussen. Dann gibt es da Feed Forward, das heißt einfach nur von links nach rechts durch, von oben nach unten, je nachdem. Recht viel genauer ist das noch nicht definiert. Dann kann man es noch unterteilen in Recurrent, also es geht einmal durch, und dann beeinflusst es den alten Stand wieder. Haben wir uns dieses Semester nicht wirklich angeschaut, und lohnt sich auch für die Aufgaben, die wir machen, nicht wirklich. Allgemein werden Recurrent, also rückgekoppelte Neuronalen Netze, ziemlich verdrängt, weil sie zu trainieren sind, und da man ziemlich oft in Probleme läuft. Und dann gibt es noch die SOMs, die Self Organizing Maps, ich glaube, da kann sich ungefähr keiner was darunter vorstellen. Die sind aber auch noch unwichtiger geworden als die Recurrent. Und unter den Feed Forward gibt es die Convolutional, ist das nicht so wichtig, was genau, weiß jemand schon, wie Convolutional aussieht? Convolutional Neural Networks? Zumindest grob? Oh, ich sehe ein paar Nicken, ein paar... Okay, das ist gut. Darunter gibt es dann ein R-CNN, manchmal auch nur RCNN genannt, das ist ziemlich lustig, weil man kann das ziemlich einfach verwechseln mit dem RCNN, der Strich macht es, und oft genug liest man aber im Internet nur so RCNN, Object Detection, und dann denkst du dir so, okay, ist das links oder rechts? Meistens ist es das linke. Aber wollte ich nur mit aufnehmen, ist jetzt nicht direkt so eine fette Gruppe, aber ist so... ein Modename, sage ich mal. Und Recurrency in Enz. Das ist so überblicksmäßig. Jetzt möchte ich mal einen Tipp von euch hören. Ich habe schon ein paar Andeutungen gemacht, aber wo haben wir uns hauptsächlich aufgehalten dieses Semester? Sucht euch einen Punkt aus, außer den obersten, der ist ein bisschen... Wer ist... Fangen wir mal mit der nächsten Hierarchiestufe an. Wer ist dafür, dass wir uns dafür hauptsächlich... Jo. Und damit? Und das daneben? Also genau, das trifft's. Wir haben irgendwie bloß das linke angeschaut. Die zwei, die in der Mitte und rechts, die sind auch schon interessant, aber wie gesagt, haben viele Nachteile, deswegen werden sie immer weniger benutzt. Okay, das nur so zum Überblick. Und ich will es auch gar nicht weiter vertiefen, das reicht schon vollkommen, für was die Dinger stehen, wenn es euch interessiert, googelt's. Ansonsten... googelt's nicht. Und... Das ist halt... Die drei da unten sind das Hauptgebiet von Deep Learning. Die anderen kümmert man sich fast gar nicht drum. Beziehungsweise indirekt schon, weil das ja die Eltern sind, aber nicht alles, was möglich ist. So. Dann schauen wir uns mal an, was ist Deep Learning eigentlich? Und die Grundidee ist einfach nur, dass man ganz viele Neuronen hintereinander schaltet, ganz viele Layer hintereinander schaltet und darauf hofft... Ja, auf was hofft man eigentlich, wenn man ganz viele Neuronen hintereinander schaltet oder ganz viele Schichten? Hat jemand einen Vorschlag? Eine Idee?)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | results
 auf einmal haben. Also wir reden jetzt hier nicht von Big Data, aber man hat früher sich auf Algorithmen fokussiert. Ja, wir wollen den Algorithmus verbessern. Man hat dann aber auch gemerkt, dass man mit besseren Daten auch was reißen kann. Und zum Beispiel, also das eine Beispiel, was ich herausgepickt habe, ist das Wort Bank. Bank kann Sitzgelegenheit bedeuten oder Kreditinstitut. Auf der Bank können Sie sitzen oder Sie bringen Ihr Geld auf die Bank. Und jetzt nehmen Sie mal eine Handvoll Sätze und sollen jetzt unterscheiden, also ein Programm schreiben, was entscheidet, welches, was gerade gemeint ist in diesem Satz. Und die Idee war, die Unterscheidung nur anhand von Wortdefinitionen zu machen, also ungelabelten Beispielsätzen und, also nee, anhand von Wortdefinitionen und ungelabelten Beispielsätzen. Also ich gebe Ihnen quasi jetzt die Duden-Definition von Bank und hunderttausende Millionen von Beispielsätzen, wo das Wort drin vorkommt. Und ein mittelmäßiger Algorithmus mit 100 Millionen Wörtern als Trainingsdaten ist besser als der beste Algorithmus mit nur einer Million Wörter Trainingsdaten. Also allein durch die schiere Masse an Trainingsdaten konnten wir das Problem lösen oder erschlagen, was übrigens auch jetzt beim Deep Learning oft vorkommt. Wenn ich lese, was, also wenn Sie mal googlen, was ist Deep Learning, finden Sie auch sehr viele Definitionen, die, sag ich mal, aus Bereichen kommen, die nicht Informatiker sind, wo dann oft gesagt wird, Deep Learning braucht sehr, sehr viele Daten. Das stimmt. Das ist nicht das, aber nicht das, wobei ich Deep Learning definieren würde. Aber hier ist es auch so. Sie haben, wenn Sie die Regelmäßigkeiten erkennen wollen, brauchen Sie viele Daten. Und hier hat sich gezeigt, dass, wenn Sie die Daten besser auswählen und viel mehr Daten haben, Sie auch Probleme teilweise besser lösen können, als wenn Sie einfach nur den Algorithmus verbessern. Und da war auch die Erkenntnis, dass manche Probleme sich besser durch Lernen lösen lassen, als durch handgemachte wissensbasierte Systeme. Das sind auch die beiden Welten. Wissensbasierte Systeme oder viele Algorithmen der KI sind handgemacht, wenn Sie so wollen, Intelligent Design. Sie haben eine Idee und sie programmieren das intelligente Verhalten. Und da ist nichts mehr dem, sag ich mal, dem Zufall überlassen. Das ist alles vorgegeben. Und beim Lernen, auch beim machine learning Lernen, haben sie ein paar Grundregeln definiert, den Rest lernt das System von alleine. Und Umfragen in den 2000ern haben aber ergeben, dass KI immer noch)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | results
 ... Ja. Genau das ist es halt. Also Deep Learning ist wirklich datenhungrig. Je mehr Bilder, desto besser. Ich weiß nicht, ob schon mal jemand das ImageNet angeschaut hat, aber das sind 14 Millionen Bilder zum Trainieren. Das ist schon eine Hausnummer. Und das ist halt auch wirklich die Idee. Man holt sich so viele Daten wie möglich. Bevor man irgendwas macht, holt man sich mehr Daten. Das ist immer der beste Weg. Und manchmal ist das aber natürlich nicht möglich. Also keine Ahnung, so im Healthcare-Bereich oder so, ist echt schlecht, da groß Daten zu holen. Und deswegen kann man natürlich auch einen anderen Weg fahren. Man kann sagen, Data Augmentation, okay, ich multipliziere meine Daten, indem ich sie spiegle, rotiere, blurge, also verwischen, raus-reinzoomen, wie auch immer. Als Beispiel. Links Original, dann gespiegelt, darker, dunkler, man kann es auch heller machen, zoomed in, man kann es kombinieren und so weiter. Und dann lässt sich das schon beliebig multiplizieren. Das sieht jetzt aus, als wäre es irgendwie so eine kleine Änderung, so bringt doch eh nichts, du bist gespiegelt, super und jetzt? Es ist eine kleine Änderung, aber erstaunlicherweise funktioniert das super. Also es verbessert die Fehlerrate um einiges und auch die Erkennungsrate. Das ist also echt eine super Möglichkeit, wenn man nicht an mehr Daten kommt, das einfach zu spiegeln. Oder, also spiegeln ist das einfachste, aber man kann natürlich auch noch andere Sachen drauf machen. Also super Idee. Und wenn das aber auch nicht reicht, wenn man sagt, okay, ich habe jetzt alles ausgeschöpft und irgendwie ist es immer noch nicht geil, dann kann man an den Layern rumschrauben. Und jetzt kommen wir auch so zu dem ersten Treiber, der Deep Learning wirklich vorangebracht hat. Und das war die Dropout Layer. Prinzip ist einfach, die konkrete Umsetzung auch, aber man muss wie bei allem aufpassen, dass man sich nicht verzettelt. Und die Idee ist relativ easy. Also ihr erinnert euch an das Netz, was wir vorhin hatten, überall waren da etliche Neuronen. Und alles was wir jetzt machen, wir trainieren das Netz einfach mit weniger Neuronen. Wir schneiden einfach ein paar Neuronen raus, mit den Gewichten logischerweise, trainieren das und dann im nächsten, beim nächsten Trainings Trainingsexample sagen wir, okay, jetzt schneide ich irgendwelche anderen Neuronen raus. Mache ich immer zufällig und ganz am Ende, wenn ich oft genug zufällig rausgeschnitten habe oder genug trainiert habe, packe ich das alles einfach wieder in ein Netz und lasse es dann damit prädikten, was es wirklich, was ich wirklich prädikten wollte. Klingt komisch. Vor allem, was ich finde, was echt komisch klingt, ist, dass die sich dann nicht widersprechen. Also irgendwie hat man das Gefühl, okay, wenn ich da jetzt welche rausschmeiße und die nicht mittrainier, und dann später wieder rein tue und dann andere rausschmeiße, dann sollten die sich irgendwie widersprechen. Ich muss zugeben, ich weiß nicht, ob es dazu vielleicht sogar irgendwelche Paper gibt, die sagen, ja, eigentlich ist das scheiße. Ich weiß es nicht. Also in der Realität funktioniert das tatsächlich ziemlich gut. Vielleicht ist es in der Theorie gar nicht möglich, aber das ist halt wie mit der Hummel. Der Hummel hat auch noch keiner gesagt, dass sie eigentlich nicht fliegen kann. Und sie tut es trotzdem. Es funktioniert. Es ist wirklich eine gute Möglichkeit. Und die Grundidee ist einfach genau das, dass wir mehr oder weniger Layer nutzen, beziehungsweise weniger Neuronen und immer ganz viele wenige und ganz viele schwache Klassifizierer, beziehungsweise neuronale Netze trainieren und die am Ende dann zu einem starken zusammenmerchen. Und da fällt mir auch noch eine kleine andere Sache ein, die ich jetzt nicht mit auf der Folie habe. Man kann natürlich auch das Ganze ein bisschen anders machen und kann sagen, okay, ich mache hier nur zwei Layer, ohne Dropout, weil ich kann das nicht implementieren, will ich nicht, keine Ahnung. Und dann sage ich einfach, okay, ich mache nicht ein neuronales Netz, sondern zehn. Und dann alles was die mir rausgeben, nehme ich den Durchschnitt davon und das ist dann mein Endergebnis. Das macht man auch. Also meistens macht man das nur mit zwei oder drei neuronalen Netzen, weil irgendwie die Computional, die Berechnungszeit ziemlich in die Höhe schießt dann. Aber man macht es. Und man macht das mittlerweile auch, indem man verschiedenste Sachen kombiniert. Also wir haben ja in der Vorlesung so ganz kurz angeschnitten gehabt beim Dennis SVMs und Decision Trees haben wir auch reichlich gemacht. Und tatsächlich macht man das mittlerweile auch. Man nimmt so ein neuronales Netz, oder zwei, und ein Decision Tree und dann nimmt man noch eine SVM und keine Ahnung, wenn einem noch irgendwas fancy einfällt, packen wir es mit dazu und nimmt dann von allem den Durchschnitt und das ist dann unser Endergebnis. Das ist ein cooler Ansatz, kann man machen, aber damit steigt halt auch die Berechnungszeit. Dafür hat man die Vorteile bzw. Nachteile von allen Modellen auf einmal. Ja, aber Dropout Layer, wichtigste Idee. Ich will gar nicht so tief in die Theorie von dem Ansteigen. Wer das machen möchte, für Dropout Layer gibt es sogar noch, aber wer das machen möchte, da gibt es unendlich Bücher und Webseiten und was weiß ich. Und ich möchte einfach nur euch so zeigen, okay, das hier gibt es, das hier könnt ihr googlen, das schaut logisch aus und so funktioniert das. Also ich möchte euch jetzt nicht mit 10.000 Gradienten totballern und ich glaube, das macht eh keinen Spaß. Deswegen nur grobes Prinzip, Grundidee, Implementierung geht bei dem sogar relativ einfach. Ich meine, wenn man sich das vorstellt, man schmeißt beim Vorwärts-Trainieren ein paar raus, beim Rückwärts-Trainieren tut man die halt nicht mit reinrechnen, fertig, ist jetzt nicht so komplex. Und gibt da noch eine Kleinigkeit, die man beachten sollte, dass man hauptsächlich bei den späteren Layern rausschmeißt. Also man, bei den ersten, bei dem allerersten Layer schmeißt man nie raus, weil da sind ja Pixelwerte oder was auch immer drin und da könnte halt jeder Pixelwert könnte da wichtig sein. Jeder kleine Unterschied könnte da wirklich die, die Ausschlag, den Ausschlag geben. Aber je weiter hinter man ist, erwartet man, dass man das irgendwie redundant hat. Also so, dass dreimal ungefähr dasselbe Gesicht erkannt wird und dann ist es egal, wenn ich da einen rausschmeiße, dann erkennen die zwei anderen immer noch ungefähr dasselbe Gesicht. Ist eine, ist die Herangehensweise und ist die Idee dahinter. Und so im Durchschnitt entfernt man 10 bis 50 Prozent der Neuronen pro Schicht. Also nicht für jede, aber halt für die, wo man es raushaben will. So wie für die letzten zwei, drei. Klingt viel, ist auch viel. Manchmal machen sie es, macht man sogar mit 75 Prozent, aber das Problem ist halt, dass der Gradient dadurch ziemlich, ziemlich explodieren kann oder die sich wirklich zu arg widersprechen können. Also es kann schon passieren, wenn man zu viel rauslöscht, dass sie sich wirklich zu arg widersprechen. Aber für den Durchschnittsfall kann man so 10 bis 50 Prozent rausschmeißen und da klappt es dann auch eigentlich so gut wie immer noch. Relativ gut. Das ist die, das sind Dropout-Layer. Und jetzt zur Trainingszeit ganz kurz. Ich glaube, jeder weiß, dass man da auch noch ein paar Sachen hat, die man nicht weiß, wie das ist. Du hast leider meine Frage, die ich eigentlich stellen würde, schon vorweggenommen. Ich wollte so sagen, was schätzt ihr so durchschnittsleer? Aber so durchschnittlich 50 bis 30. Und es gibt aber auch, also das größte, das ist vielleicht übertrieben, aber das größte sinnvoll funktionierende war 1000 layer tief. Und alles, was halt drüber hinaus ging, hat schon auch funktioniert vom algorithmischen her, aber die Ergebnisse waren schlechter, als wenn man ein kleineres genommen hat. Und das kommt halt vor allem erstens vom Overfitting und zweitens von diesen ganzen anderen Sachen, die wir vorhin noch hatten mit diesen earlier layers, depend on deeper, nein, andersrum. Und so Zeug. Und genau. Also was macht man da? Das könnt ihr mir jetzt glauben oder nicht, dass es ein paar Stunden, Tage, manchmal sogar Wochen, Monate dauert. Ich habe aber später noch eine kleine Grafik, die zeigt euch das im Vergleich zu, also CPU-Vergleich, GPU-Vergleich, Titan X oder so. Also man merkt schon, das ist eine Grafik von Nvidia, aber sie zeigt so, wie so die Größenordnung ist. Also, statt CPU nehmen wir natürlich eine GPU. Und was ich euch sagen muss, ich bin jetzt nicht so Nvidia-Fanboy und nehme deswegen überall Nvidia-Produkte. Das Problem ist, okay, bisher, bis vor einem Jahr oder so, lief Deep Learning eigentlich nur auf Nvidia-Grafikkarten sinnvoll. Weil halt die ganzen Deep Learning Frameworks haben CUDA benutzt. Und CUDA lief halt nur auf Nvidia. Mittlerweile ist AMD aber auch dabei, die Frameworks auf OpenCL zu porten. Und es gibt sogar einen neuen Compiler, der angeblich CUDA kompilieren kann oder so, nennt sich HIP. Irgend so was hat mir neulich ein Kollege erzählt. Ich trau dem noch nicht so ganz. Also, man kommt wahrscheinlich leider echt nicht um Nvidia drum rum, wenn man anfangen will, zumindest nicht, wenn man einfach nur auf Nvidia anfangen will und man fertige Frameworks benutzt. Das ist natürlich die Voraussetzung. Aber Training on GPU ist sinnvoller als CPU. Ne Frage? Was schätzt ihr? Wie lange dauert trotzdem noch so so ne durchschnittliche, sagen wir mal so durchschnittliche Größe, okay, das kann jetzt alles sein, aber schätzt mal, wie so die Größenordnung ist fürs Trainieren. Wir haben da so Stunden, Tage, Monate und so weiter gelesen, aber für einen Großteil der Projekte, was schätzt ihr, wo so stundenmäßig oder tagemäßig die Grenze liegt oder der Durchschnitt liegt? Wir nehmen einfach mal wild Durchschnitte. Was sagst du? Keine Ahnung? Heißt? Schätzt irgendwas? Keiner hat ne Ahnung, glaub ich. Erhoffe ich. Okay, eher Stunden oder eher Tage? Im Durchschnitt. Okay. Sagen wir mal ein Tag, einfach so. Spontan. Was sagst du? 20 Stunden. Und du? 10?)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | results
 Für gewisse Dinge wollen wir nachvollziehbare, ähm, Erklärungen haben. Zum Beispiel, ähm, wenn Sie zum Doktor gehen, ja, und er sagt, ähm, ja, dagegen müssen Sie dreimal am Tag Kopfstand machen und einen Zehen wackeln. Ja, und dann, ähm, dann ist das, ähm, dann ist das, ähm, dann ist das, ähm, dann ist das, ähm, dann ist das, ähm, dann ist das, ähm, dann ist das, ähm, dann ist das, ähm, dann ist das, ähm, nine, zehn, ja, wenn man den Doktor dann sagt, ja, weiß ich auch nicht, ja, ich glaub, das stimmt, ja, dann ist doch irgendwie Mist. Also Sie werden erwarten, dass er sagt, ja, ja, dann setzen sich die Wirbel richtig gegeneinander, ja, ja, dann setzen sich die Wirbel richtig gegeneinander, und, ähm, es entlastet die Lunge oder was weiß ich. Irgendwie sowas würden Sie von Ihrem Doktor erwarten. Das können diese neuronalen Netzwerke nicht, neuronalen Netzwerke nicht. Oder wir wissen noch nicht, wie es geht. Es ist zumindest nicht irgendwie offensichtlich, dass man einfach irgendwie in dem Decision Tree runterläuft und sagt, ah, da ist es ungefähr. Und das ist einer der großen Schwachpunkte. Das heißt, wir werden auch nicht, trotz aller dieser wunderbaren Deep Learning-Geschichten, ja, Deep Learning, dies hier ist nicht so weit weg von Deep Learning, und verhält sich sehr ähnlich. Deep Learning heißt einfach, wir machen ganz viel dazwischen, ganz viel Hidden Layers und noch ein bisschen klügere Algorithmen, aber viel mehr und ganz, ganz viel Rechenpower. Viel mehr ist da auch nicht hinter. Da hat man natürlich noch gewisse Netzwerkarchitekturen, dass man irgendwelche Netzwerke mit einem dünnen Bauch hat oder mit einem dicken Bauch und dass die irgendwo sparse sind und so weiter und so fort. Aber man hat das gleiche Problem. Man hat keine Erklärungskomponente bisher. Das heißt, für viele Anwendungen sind sie nicht anwendbar. Zum Beispiel kann man Lernalgorithmen nur sehr, sehr schwer in Medizinprodukten verwenden. Alles, was ein hohes Haftungsrisiko hat, da muss man nachvollziehbare Entscheidungen machen können und das ist das, was man macht. Das ist das, was man macht. Das ist das, was man macht. Das ist das, was man macht. Das ist das, was man macht. Das ist das, was man macht. Das ist das, was man macht. Das ist das, was man macht. Das ist relativ schwierig. Zumindest bei der jetzigen Rechtslage ist es so, dass man das für viele Situationen, man Erklärungen braucht. Vielleicht ändert sich die Rechtslage, das kann sein. Das gibt es gerade bei den selbstfahrenden Autos. Gibt es Tendenzen, wo man sagt, Schuld, da ist ja immer die Frage, was passiert, wenn der Bus jetzt irgendwie so und so viele Kinder platzt. Kinderplatt fährt. Und naja, da gibt es Tendenzen tatsächlich in den Diskussionen, die sagen, ja, alles, was wir versichern können, ist schuldirrelevant. Müssen wir als Gesellschaft uns überlegen, ob das das Richtige ist. Vielleicht, wenn wir als Gesellschaft sagen, wir müssen immer nachvollziehbare Entscheidungen haben, vielleicht müssen wir dann so lange, bis die Theorenbeweise Auto fahren können. Und sozusagen in jeder Situation sagen können, warum sie nun jetzt gegen den Baum fahren und nicht gegen den Baum. Und ob das dann auch so richtig gut funktioniert, wie ein neuronales Netz oder was auch immer, da jetzt im Moment an Methoden verwendet wird, das ist die Frage. Aber man hat hier so eine Abwägung. Und das ist ein echtes Problem, um zu sagen, so attraktiv, wie richtig diese ganzen Lernalgorithmen sind. Man will in manchen Situationen auch Erklärungen haben. Und das zieht sich durch. Es gibt fast keine Lernverfahren, die wirklich Entscheidungen unterstützen. Eine Ausnahme sind das, was wir, nein, nicht wir, sondern Sie, ich bin nächste Woche weg, ich bin in den nächsten beiden Wochen weg, in der nächsten Woche machen werden, da geht es darum, wie kann man lernen, wenn man schon was weiß. Was wir ja jetzt gemacht hatten, ist ja so ein Tabula rasa Lernen. Wir wissen noch gar nichts. Und dann sehen wir irgendwas und dann lernen wir vor uns hin und hinterher haben wir was gelernt, wissen wir was. Das ist für die meisten Situationen absolut unrealistisch. Gucken Sie sich selber an. Sie lernen gerade was. Aber nicht dadurch, dass ich irgendwelche Beispiele gebe und Sie plötzlich erstmal, wenn Sie hier in diese Vorlesung mit einer Amnesie kommen, sprich alles vergessen haben, was Sie vorher wussten, dann haben Sie ein Problem. Und, in der nächsten Woche wird Dennis Müller hier Ihnen erzählen, wie man mit sowas umgeht. Das wird sehr viel wiederum logische Methoden verwenden. Ganz anderer Satz von Methoden. Es gibt noch nicht sehr viele gute Verfahren, die beides können. Wissen und Wissen und Lernen und dann auch noch statistisch oder so etwas. Das ist eines der großen Probleme. Denn diese logikbasierten Verfahren sind ja letztlich in gewisser Weise erklärungsbasiert. Und man weiß noch nicht so richtig, wie man die gut miteinander verbinden soll. Das empfinde ich so als den heiligen Graal der KI. Und deswegen finde ich es ganz gut, wenn Sie beides lernen. Und in der Woche drauf sind sowohl Dennis Müller als auch ich weg und da machen wir die Neuronets Challenge. Also da ist die Idee, dass Sie sich mal die Hände schmutzig machen und den Algorithmus, den ich Ihnen heute leider nicht zeigen konnte, mal from scratch implementieren. Und dann auf verschiedenen Datensätzen Ihre Implementationen gegeneinander anlaufen lassen. Das organisiert Marcel Rupprecht, der hinten sitzt da. Der hat einen Satz von Java-Klassen entwickelt, die es uns erlauben, das Ganze gegeneinander anlaufen zu lassen. Und so genau wie bei dem KALA-Klassik, die wir jetzt auch noch mal in der Kategorie haben, die wir jetzt auch noch mal in der Kategorie haben, die wir jetzt auch noch mal in der Kategorie haben, die Probleme hoffe ich abzuhalten. die Probleme hoffe ich abzuhalten. Genau, das ist der Plan. Und in der letzten Woche des Semesters, wir haben danach noch eine Woche, will ich Ihnen ein bisschen Bayesches Netzwerken lernen, beibringen, um die Sachen wieder zusammenzubinden. Wie lernt man solche Modelle? Wie lernt man solche Modelle? Wie lernt man statistische Modelle aus Beispielen? Wie lernt man statistische Modelle aus Beispielen? Sie wissen alle, Klausur ist 1. August, 18 Uhr, Hörsaal 7. Gut. Dann sehe ich Sie in zweieinhalb Wochen. reduces vet)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | results
 Direkt danach folgte der sogenannte erste KI-Winter. Also ich habe in meinem Studium noch sehr viel über KI-Winter gehört, wenn ich es danach, als ich danach recherchiert hatte, finden Sie verschiedene Darstellungen oder auch nicht so prominent die Bezeichnung KI-Winter, aber ich fand das sehr einprägsam. Das waren Anlehnungen an den nuklearen Winter, also wo danach nichts, nach dem Atomkrieg nichts mehr wächst, weil alles zugeschneit ist und keine Sonne mehr auf die Erde kommt. Im Prinzip hat man durch die vielen Versprechungen und die nicht eingehaltenen Versprechungen das Interesse und die Investitionen so geschädigt, dass da erstmal nichts mehr gewachsen ist an KI oder nicht viel. Damals wurde so viel Geld draufgeworfen auf die KI und hat man irgendwann gesagt, also da kommt ja nichts zurück, also wir streichen jetzt alle Forschungsgelder für undirected explanatory research. Also hat gesagt, so hier hast du ein paar Millionen Dollar und forsch mal bitte. Und Sie kennen, heute ist es ja so, heute brauchen Sie immer auch heute noch ein sehr genaues Forschungsziel. Einfach sagen, ich forsche an KI, damit werden Sie wahrscheinlich kein Geld kriegen. Die Probleme damals waren halt auch, dass Sie dann noch eine sehr beschränkte Rechenkraft hatten. Also wir reden hier von den 70ern. Das ist wirklich alles nicht zu vergleichen zu dem, was wir heute an Rechenfrauen haben, allein schon, was wahrscheinlich jeder zu Hause stehen hat. Die Bewegungserkältung der Netzhaut hat man, kann man schätzen, mit circa 1000 Millionen, also eine Milliarden Instruktionen pro Sekunde. Also allein, was die Nervenzellen in Ihrer Netzhaut, nicht mehr hinten im Gehirn, sondern in der Netzhaut leisten, betrifft das um Vielfaches, was die schnellsten Suchcomputer damals konnten. Die hatten nämlich maximal 100 Millionen, also Million Instruktionen pro Sekunde. Und viele Dinge waren dann auch aufgrund der Rechenkraft nicht lösbar. Und das Problem ist auch, wenn Sie sich viele Probleme anschauen, also die von Ihnen, die jetzt schon Algorithmen und Datenstrukturen gehört haben, also Informatiker von Ihnen kennen das, die VZler kennen, wenn sie das nächste Semester hören, vermute ich auch bei mir übrigens, da haben Sie bei ganz vielen Problemen eine kombinatorische Explosion. Also Sie haben ganz schnell auch im echten Leben, gibt es so viele Dinge zu beachten, so viele Variablen, dass Sie so viele Möglichkeiten haben, dass Sie unheimliche Rechenpower brauchen, um das zu lösen. Zum Beispiel Sprachverständnis, wenn Sie versuchen würden, alle möglichen Sätze, die es gibt, auch zu listen. Naja, das wären sehr viele, wenn nicht sogar unendlich viele. Das hat 1980, wurde das oder bildet sich das sogenannte Bora-Wegsche-Paradox, nämlich, dass es vergleichsweise einfach ist, einen Computer dazu zu bringen, Leistungen auf Erwachsenenniveau bei Intelligenztests oder beim Damenspielen zu erbringen. Also Schachcomputer waren damals schon möglich, aber es ist schwierig oder unmöglich, in die Fähigkeit eines Einjährigen in Bezug auf Wahrnehmung und Mobilität zu vermitteln. Also wir denken daran, Schachspielen konnten Computer schon lange, aber Laufen auf zwei Beinen nicht so. Und das ist ja schon seltsam, dass man sagt, man konnte einfach die Sachen, die nur auf Logik basieren, viel einfacher nachbilden, als die Sachen, die andere Dinge als Logik benötigen. Und Hans Moraweg hat das so formuliert, im Allgemeinen sind wir uns am wenigsten bewusst, was unser Verstand am besten kann. Wir sind uns einfacher Prozesse, die nicht gut funktionieren, mehr bewusst als komplexe Prozesse, die fehlerfrei funktionieren. Also wenn ich Sie jetzt fragen würde, also ich gebe Ihnen einen Ball zu, und Sie sollen mir erklären, wie Sie den jetzt fangen, also woher Sie wissen, dass Sie da die Hand hin tun sollen, Sie können es wahrscheinlich auch nicht erklären. Ich könnte es Ihnen auch nicht erklären. Aber wenn ich Ihnen jetzt erkläre, wie Sie, oder wenn Sie mir erklären sollen, wie man eine Ableitung herstellt, mathematische Ableitung, oder wie man den größten gemeinsamen Teil erfindet, das ist relativ einfach zu erklären, aber das ist halt rein logisch. Und das wurde hier als Moraweg-Schutzparadox bezeichnet. In den 80ern gab es dann wieder die ersten kommerziellen Erfolge in der KI. Also Expertensysteme haben sich dann doch ein bisschen durchgesetzt. Es gab die verschiedensten Anwendungen, also R1, später ist es X-Con zur Konfiguration von Macs, das waren auch wieder Rechner. Und das war so, also das hat auch Geld verdient. Das war der erste Beweis, dass KI echt nützlich sein kann. Also auf einmal haben die Firmen da auch was wieder investiert, weil es nicht einfach nur ein Geldgrab war, sondern auch was damit verdienen konnte. Und das hat dazu geführt, dass auch wieder KI im größeren Stil gefördert wurde und viele Firmen eine KI-Abteilung hatten. Dann kam der zweite KI-Winter, das hat sich nämlich herausgestellt, dass sie, wenn sie so ein Expertensystem haben, also wir haben ja gesagt, ein Expertensystem, das basiert auf vielen Regeln von Experten. Und Sie können sich vorstellen, da kommt immer mehr Wissen hinzu. Aber das neue Wissen beeinflusst das alte Wissen. Die Regeln interagieren und deswegen wurde die Wartung immer teurer. Irgendwann haben sie mehr Aufwand gehabt, so ein System zu warten, als sie Zeit hatte. Und da sind die so ein bisschen an ihr Ende gestoßen. Und Desktop-Computer, IBM und Apple wurden schneller als teure Lisp-Computer. Also wir hatten ja vorhin Lisp, also diese Sprache, Lisp-Processing, das war damals quasi das, womit man KI gemacht hat. Während meiner Doktorandenzeit, als ich auch eine Vorlesung KI betreute, hat mein Doktorvater die ersten vier Übungsblätter nur in Lisp machen lassen. Und ich sage Ihnen, das ist kein Spaß. Das artet meistens daran aus, dass Sie die fehlende Klammer suchen, weil Sie haben mehr Klammern als sonst was in dieser Sprache. Wir werden uns das mal anschauen, einfach mal, einfach damit Sie sehen, wie gut Sie es jetzt haben, dass Sie andere Sprachen nutzen können. Das war damals aber das, was man genutzt hat. Und da gab es Firmen, die haben spezielle Computer hergestellt oder programmiert, die nur das konnten. Und dieser Markt ist dann auch eingebrochen. Und es gab in Japan ein großes KI-Projekt, Fifth Generation, hat auch die Erwartung nicht erfüllt, also wieder mal zu große Versprechungen. Und dann ist das Interesse wieder zurückgegangen. 1986 gab es dann auch die Rückkehr der neuronalen Metze. Wie gesagt, hatte Minsky der ganzen Sache so ein bisschen einen Sargnagel, den letzten Sargnagel verpasst und das Interesse ging zurück. Dann hat man aber die sogenannte Backpropagation-Lernung wiederentdeckt. Das wurde schon vorher 1969 von Bryson und Ho entwickelt. Da geht es also darum, wie Sie in einem tiefschichtigen neuronalen Netzwerk oder einem mehrschichtigen neuronalen Netzwerk die Gewichtung, die Verbindung zwischen Neuronen anpassen können. Und also das wurde schon mal entdeckt, aber was hat man da jetzt wiederentdeckt? Und das führte auch zu der Wiederentdeckung oder dem Aufkommen des Konnektionismus als Gegensatz zu symbolischen Ansätzen. Das werde ich später vielleicht noch mal kurz erwähnen, aber um es hier mal zu sagen, wenn Sie, nehmen wir das Beispiel nochmal mit Formelnbeweisen oder solchen Sachen, ableiten, Logik einfach. Sie haben Symbole. Sie haben sowas wie f von x gleich x Quadrat, steht auf Symbolen. Die Symbole sind einfach verarbeitbar. Sie können einfache Regeln anwenden. Es sind wenig Symbole vor allem, wenn Sie aber jetzt eine Bilderkennung haben zum Beispiel und Sie haben eine Kamera, die jetzt nur Voll-HD-Auflösung hat. Dann haben Sie ja Millionen von Pixeln, Millionen von Werten und Sie können nicht jeden einzelnen Wert eine Bedeutung und Symbol zu messen. Und das ist der Konnektionismus, der, wo man gerne unterteilt zwischen symbolischer und sub-symbolischer KI. Symbolisch heißt, Sie haben einzelne Einheiten. Ein Wort ist ein Symbol. Ein Zeichen ist ein Symbol. Und Sie machen Symbolmanipulation. Und beim sub-symbolischen Ansatz, wie in normalen Netzen, haben Sie sehr, sehr viele Zahlen, die in sich keine Bedeutung haben, aber im Zusammenspiel auf einmal intelligentes Verhalten zeigen. Was man ja bei normalen Netzen, vor allem am Deep Learning stark sehen kann, dass dieser Konnektionismus einfach ein sehr guter Ansatz ist. Und normalen Netzen wurden dann wieder mächtiger. Man konnte viel mehr Probleme auf einmal damit lösen. Außerdem wurde die KI empirisch. Die KI war lange rebellisch über der Statistik. Also, wenn Sie so sind wie ich im Studium, dann haben Sie nicht viel Interesse an Statistik oder verstehen es nicht oder mögen es nicht. Und wahrscheinlich ging es den Leuten damals auch so. Und Statistik war ihnen damals zu stringent. Und man hat gesagt, nein, wir machen einfach mal. Wir machen das alles anders. Und die haben sich damit auch ein bisschen davon losgelöst und wollten sich loslösen. Und dadurch wurde KI auch rebellisch mehr, aber isoliert, weil man mit denen nicht gesprochen hat. Man wollte ja alles anders machen. Und nach und nach hat man sich wieder angenähert, weil man gemerkt hat, dass diese klassischen Methoden in der Mathematik, die sind ja alle seit Jahrzehnten, Jahrhunderten teilweise bewiesen. Sie haben sehr, sehr fundierte Grundlagen, auf denen Sie aufbauen können, wo Sie Dinge beweisen können, wo Sie Dinge einfach mal mathematisch herleiten können. Und durch diese Annäherung wurde das Ganze ein bisschen erwachsener. Also empirisch in dem Fall jetzt. Beispiele sind zum Beispiel Hidden Markov Models oder Bayesian Methoden, mit denen Sie auch sehr genau quantifizieren können, wie gut ist Ihre Lösung, wie sicher sind Sie sich Ihrer Lösung. Und das hat der KI nochmal eine neue Richtung verpasst. Ich weiß nicht, was Ihr Jahrgang ist, aber ich habe es noch nicht bekommen. Live damals am 11. Mai 1997 hat der Computer Deep Blue erstmals den Schachgrossmeister, Weltmeister Gary Kasper aufgeschlagen. Und das war damals ein Meilenstein. Wir erinnern uns, ich gehe mal kurz zurück, wir erinnern uns, das hat, haben wir es hier, ja, 1958 hat man gedacht, dass man innerhalb von zehn Jahren den Schachweltmeister besiegt. Hat ein bisschen länger gedauert, sagen wir mal 30 Jahre statt zehn Jahre, aber es hat funktioniert. Und Sie werden es vielleicht wissen, auch damals haben, kann sein. Übrigens auch ein beliebtes Thema, also ein Kommentar ist, dass er nicht gut gespielt hat. Ein Thema ist, oder ein Argument ist, dass die Leute denken, ja, ich spiele Computer so gut, kann ja nicht sein. Und dann spielen sie nicht so gut, wie sie könnten, weil sie den Computer unterschätzen. Ist auch ein Faktor. Ich glaube, in Wahrheit er hat auch dreieinhalb zu zweieinhalb gewonnen. Also es gab sehr viele Unentschieden. Und Gary Kasper hat, glaube ich, sogar vermutet, dass es nicht so war, Dinge nicht mit rechten Dingen zu gehen, dass da vielleicht Menschen geholfen haben. Und trotzdem, das war, also es war schon ein Meilenstein, also es war schon ein Moment in der Geschichte, wo man sagt, oh, jetzt hat ein Computer was geschafft, was man sonst nur nur Menschen, oder wo Menschen besser waren. So ist dann auch passiert, dass nach und nach Computer immer besser wurden, in denen Menschen bisher einfach die Führung hatten. Dazu kommt, dass sie ab den 2000ern die Verfügbarkeit von sehr großen Datensätzen auf einmal haben. Also wir reden jetzt hier nicht von Big Data, aber man hat früher sich auf Algorithmen fokussiert. Ja, wir wollen den Algorithmus verbessern. Man hat dann aber auch gemerkt, dass man mit besseren Daten auch was reißen kann. Und zum Beispiel, also das eine Beispiel, was ich herausgepickt habe, ist das Wort Bank. Bank kann Sitzgelegenheit bedeuten oder Kreditinstitut. Auf der Bank können Sie sitzen oder Sie bringen Ihr Geld auf die Bank. Und jetzt nehmen Sie mal eine Handvoll Sätze und sollen jetzt unterscheiden, also ein Programm schreiben, was entscheidet, welches, was gerade gemeint ist in diesem Satz. Und die Idee war, die Unterscheidung nur anhand von Wortdefinitionen zu machen, also ungelabelten Beispielsätzen und, also nee, anhand von Wortdefinitionen und ungelabelten Beispielsätzen. Also ich gebe Ihnen quasi jetzt die Duden-Definition von Bank und hunderttausende Millionen von Beispielsätzen, wo das Wort drin vorkommt. Und ein mittelmäßiger Algorithmus mit 100 Millionen Wörtern als Trainingsdaten ist besser als der beste Algorithmus mit nur einer Million Wörter Trainingsdaten. Also allein durch die schiere Masse an Trainingsdaten konnten wir das Problem lösen oder erschlagen, was übrigens auch jetzt beim Deep Learning oft vorkommt. Wenn ich lese, was, also wenn Sie mal googlen, was ist Deep Learning, finden Sie auch sehr viele Definitionen, die, sag ich mal, aus Bereichen kommen, die nicht Informatiker sind, wo dann oft gesagt wird, Deep Learning braucht sehr, sehr viele Daten. Das stimmt. Das ist nicht das, aber nicht das, wobei ich Deep Learning definieren würde. Aber hier ist es auch so. Sie haben, wenn Sie die Regelmäßigkeiten erkennen wollen, brauchen Sie viele Daten. Und hier hat sich gezeigt, dass, wenn Sie die Daten besser auswählen und viel mehr Daten haben, Sie auch Probleme teilweise besser lösen können, als wenn Sie einfach nur den Algorithmus verbessern. Und da war auch die Erkenntnis, dass manche Probleme sich besser durch Lernen lösen lassen, als durch handgemachte wissensbasierte Systeme. Das sind auch die beiden Welten. Wissensbasierte Systeme oder viele Algorithmen der KI sind handgemacht, wenn Sie so wollen, Intelligent Design. Sie haben eine Idee und sie programmieren das intelligente Verhalten. Und da ist nichts mehr dem, sag ich mal, dem Zufall überlassen. Das ist alles vorgegeben. Und beim Lernen, auch beim machine learning Lernen, haben sie ein paar Grundregeln definiert, den Rest lernt das System von alleine. Und Umfragen in den 2000ern haben aber ergeben, dass KI immer noch schlecht angesehen war. Da gibt es ein paar schöne Zitate im Economist von Juni 2007. Da hat ein Investor gesagt, also sie wurden von dem Begriff Spracherkennung ein bisschen abgeschreckt, weil es wie das Wort künstliche Intelligenz mit Systemen verbunden wurde, die sehr oft einfach nicht das eingehalten haben, was sie versprochen haben. Patty Tascarella in der Pittsburgh Business Times hat gesagt, manche glauben, dass das Wort Robotik mittlerweile genauso ein Stigma trägt wie KI und die Finanzierung von Firmen sogar schädigt. Stellen Sie sich vor, Sie nennen etwas Blablabla Robotics und Sie wissen ja, dass noch die, die Sachen nicht können. Dann würden Sie auch weniger Geld reingeben. Das ist im Prinzip das Gegenteil davon, was Sie heute teilweise haben, dass Firmen einfach nur irgendwo Bitcoin oder Cryptocurrency in ihren Namen stecken und auf einmal Geld erhalten. Also die Worte waren ein bisschen verbrannt. Und das war sogar so, dass auch jemand gesagt hat in den New York Times, also im Tiefpunkt haben Computerwissenschaftler, also Computer Scientist und Software Engineer den Begriff KI einfach komplett vermieden, einfach weil man Angst hatte, dass man das einfach nur als hingespinzt oder als, naja, als klappt ja eh nicht erkennt oder sieht. Und das hat auch dazu geführt, dass sich dann diese auch viele Teilgebiete der KI ergeben haben, die sich nicht mehr KI genannt haben. Zum Beispiel maschinelles Lernen, kognitive Systeme, wissensbasierte Systeme. Also in den 2000ern, also ich habe ja von 2003 bis 2008 studiert, da war es wirklich noch so, dass ich damals oft dachte, ach, das ist doch eher KI, aber man hat es nicht KI genannt. Wissensbasierte Systeme, Mustererkennung, also Pattern Recognition, einfach weil der Name KI verbrannt war. Und jetzt ist die Frage, was ist der Stand heute? Der KI-Effekt ist, dass mittlerweile sehr viele KI-Anwendungen, also KI-Methoden in die Anwendung geschafft haben und ohne, dass man die KI nennt. Sie haben es gerade eben gehört, weil man KI nicht so toll fand, den Begriff, oder weil er negativ konnotiert war. Und das führt dazu, dass KI jetzt überall ist und man es nicht als solcher erkennt, weil man es auch nicht so nennt. Das Umgekehrte ist auch der Fall. Ich rede, da kommen KI-Chips in Handys und da werden KI-Chips gebaut und eigentlich sind es nur, sage ich mal, in GPUs, also Schleuder-Prozessoren. Aber man nennt es jetzt wieder KI. Aber 2006 hatten sie noch sehr viele KI-Systeme, die man einfach nicht so genannt hat und das hat dazu geführt, dass das nicht so ankam. Also man hat die Erfolge nicht als KI erkannt. Und da hat Marvin Minsky, der lebt leider nicht mehr, das war 2016, ist er gestorben, aber der hat es nochmal zu Wort gewählt, 2011, gesagt, das Paradoxe an der Situation ist, dass jedes Mal, wenn ein KI-Projekt einen Erfolg hatte, eine neue Entdeckung gemacht hat, dass man das schnell, dass es ein Produkt gab, was eine neue Art von, was man als neue Spezialität bei einem Spin-off, neue Methode, neue Richtung erkannt hat oder genannt hat, mit einem eigenen Namen und das man dann nicht mehr mit KI assoziiert hat. Und dann Fragen außenstehende, ja, aber warum macht KI keine Fortschritte? Weil die Fortschritte in lauter Teilgebieten der KI entstanden sind, die manche nicht mit KI assoziiert haben. Und sehr schön ist auch, das gilt auch heute noch von 1970, das Zitat, Intelligenz ist, was auch immer Maschinen noch nicht gemacht haben. Als das erste Mal erklärt wurde oder bekannt wurde, wie die Blue funktioniert, also der Schachcomputer, dass er nämlich einfach, grob gesagt, alle Kombinationen, alle möglichen Züge bis einer gewissen Tiefe durchprobiert, hat man gesagt, das ist ja keine Intelligenz, der probiert ja nur durch. Und so ist es auch jedes Mal, wenn Sie jetzt eine KI programmieren, die irgendwas löst, eine Wegfindung, hier Routenplanung, sonst irgendwas, da heißt es dann, wenn jemand versteht, wie es geht und merkt, das ist ja eigentlich ganz viel Rechnen und ganz viel Mathematik, dann heißt es oft, das ist ja keine Intelligenz. Da sind wir wieder bei diesem Vergleich, kann ein U-Boot schwimmen? Das ist, wenn wir sagen, ja, das ist ja kein Schwimmen in dem Sinne. Und da sagt man, ja, es ist ja kein Denken in dem Sinne. Wieder bei dem Punkt, Intelligentes Handeln und Intelligentes Denken. Intelligentes Denken wird in Programmen einfach auch abgesprochen, aber Intelligent Handeln, naja, soweit sind wir mittlerweile schon. Ich habe diese Folie nochmal, also Verzeihung an die Informatiker, die es schon gesehen haben, die Folie kennen Sie. Ich habe 2015 einen Vortrag gehalten und habe damals diese Folie gemacht, Stand der KI heute, also das ist jetzt schon sechs Jahre alt, einfach um Ihnen auch nochmal den Vergleich zu geben, was hat sich seitdem getan. Das autonom fahrende Auto von Google hat 2015 elf Unfälle auf 1,5 Millionen autonom gefahrenen Kilometern verursacht und an keinem oder war beteiligt gehabt und an keinem davon war das Google Auto selbst schuld. Mittlerweile gibt es ein paar mehr Fälle, wo selbstfahrende Autos schuld waren, aber das war, also dieser Treppenblitz, dass es immer zehn Jahre entfernt ist, kommt langsam zum Ende, weil die KI nun doch schon nah dran ist. Genauso die Spracherkennung. Ich habe es gestern auch schon erzählt. Ich kann mich an Spracherkennung erinnern, dass es nicht funktioniert hat. Trepperquoten von 90, 95 Prozent, also hier ist das zwanzigste Wort falsch und das hat mir damals, war für mich nicht anwendbar. Vor allem auch, weil ich schnell spreche, war für mich die Spracherkennung nie richtig gut. Aber wenn ich jetzt sehe, was mein Handy oder was Amazon Alexa alles erkennt, ist schon sehr beeindruckend. Also auch was für einen Akzente, Genuschel, Dialekte, verschiedene Sprachen, ist schon krass, was es kann und wir sehen sie ja auch in der FAZ von 2014 war auch der Kommentar Spracherkennung. Das war auch die Technik, die nicht perfekt funktioniert hat, oder? Und die Leute waren überrascht, weil sie es auch noch kennen als so klappt es ja auch nicht. Und so wie man von KI-Wintern redet, redet man auch oft vom KI-Frühling, also das ist nach dem Winter kommt der Frühling, dass durch Deep Learning jetzt wieder sehr viele KI-Anwendungen, also sehr viel KI in den Fokus gerückt ist. Es gibt wieder richtigen KI-Hype. Alles ist Deep Learning. Überall heißt es, wir wollen nicht Deep Learning machen. Und das wird auch erfolgreich eingesetzt, wie gesagt, bei Amazon Alexa, Google Sprachassistent, Apple Siri, was sie alles haben. Sie haben Spiele-KIs, die mittlerweile Menschen schlagen. AlphaGo Master hat neue Strategien entwickelt. AlphaGo Zero im selben Jahr entwickelt hat, also beim Go-Spiel, hat sogar erfolgreiche Beispiele gelernt, indem es nur gegen sich selbst gespielt hat und dadurch die Regeln gelernt hat. Und nach nur 40 Tagen, aber immensen Hardware und wahrscheinlich auch Stromkosten, war es besser als alle seine vorherigen Versionen. Und 2019 hat AlphaStar in StarCraft II Großmeisterrang erreicht. Und das ist hier nochmal was anderes, weil das in Echtzeit Strategiespiel ist und nicht rundenbasiert wie Schach oder Go. Also die Frage kam gestern, rundenbasiert heißt ja in dem Fall, sie haben fast beliebig viel Zeit. Sie haben eine gewisse Zeit, ihre Entscheidung, ihren nächsten Zug zu überlegen und dann lässt der Gegner seinen Zug. Und in Echtzeit, während sie überlegen, entwickelt sich die Welt weiter. Das ist der große Unterschied und deswegen ist es nochmal schwieriger, weil sie schnell Entscheidungen treffen müssen und auch während sie Entscheidungen treffen, vielleicht neue Informationen in ihre Entscheidungen einfließen lassen müssen. Und Deep Learning hat viele Durchbrüche verursacht. Also ich habe auch gesehen, ein paar von ihnen haben letztes Semester das Seminar Machine Learning bei Thomas Wieland belegt. Also ein paar von ihnen haben das hier schon mal gesehen vermutlich. Sogenannte Convolutional Neural Networks erkennen Ziffern besser als Menschen, schon seit einigen Jahren, auch Verkehrsschilder glaube ich. Also sie machen weniger Fehler. Es gibt Neural Style Transfer, der den Stil von Gemäden auf Bilder übertragen kann. Das ist auch Deep Learning. Super Sampling erzeugt hochauflösende Bilder aus kleinen Bildern. Sie können also eine kleine Auflösung auf eine hohe Auflösung hochrendern, sagen wir mal voller DO4K. Deep Learning, NVIDIA nennt es DLSS, also vermutlich Deep Learning Super Sampling, aber ich glaube, ich habe einen TM vergessen, der Begriff gehört denen. Deep Fake, wo sie Gesichter auf andere Personen draufsetzen können. Und GANs, also Generative Adversarial Networks, die echt aussehende Fotos erzeugen können und auch ganz viele andere Dinge erzeugen können. Also es gibt die Website This Person Doesn't Exist oder This Cat Doesn't Exist. Und das ist einfach krass, was diese Netzwerke können. Und das selbstfahrende Auto ist jetzt wirklich nur noch wenige Jahre entfernt. Diesmal wirklich.)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | results
 Beziehungsweise indirekt schon, weil das ja die Eltern sind, aber nicht alles, was möglich ist. So. Dann schauen wir uns mal an, was ist Deep Learning eigentlich? Und die Grundidee ist einfach nur, dass man ganz viele Neuronen hintereinander schaltet, ganz viele Layer hintereinander schaltet und darauf hofft... Ja, auf was hofft man eigentlich, wenn man ganz viele Neuronen hintereinander schaltet oder ganz viele Schichten? Hat jemand einen Vorschlag? Eine Idee? Möchte jemand eine Idee äußern? Ich glaube, ihr habt Ideen, aber... Gefühlt möchte keiner, dass ihr äußern. Okay, ist auch nicht so schlimm. Die Grundidee ist, dass in jeder Schicht das abstrakter wird, was das Neuronalnetz lernt. Hier ganz konkret. Wir wollen ein Gesicht erkennen, ganz links. Und in der ersten Schicht, also stellen wir uns vor, das hier ist die Gesichtseingabe, in der ersten Schicht lernt es dann so ein paar Kanten und Linien und Kreise und ist damit schon ganz zufrieden. In der zweiten Schicht lernt es dann auch dazu, okay, aus Kreis und... Sagen wir aus zwei geraden Linien und so einen Halbkreis kann ich eine Nase machen und dann lernt das Neuron halt die Nase und das unten drunter lernt, okay, aus einem Kreis und Augenbrauen kann ich... also aus einem Kreis und einer Halbkreis... kann ich Augen machen und so weiter. Und bis in die letzte Schicht, wo halt dann wirklich konkret über Gesichter entschieden wird. Ziemlich cooles Konzept. Und obwohl, laut Dennis, ich weiß es nicht, ich habe es noch nie gelesen, aber laut Dennis kann man mit drei Schichten von neuronalen Netzen schon alle Funktionen, die es gibt, alle matrischen Funktionen, die es gibt, annähern. Das kann gut sein. Aber was halt das Problem ist, du hast keine hierarchisch abstrakter werdende Pipeline, sage ich mal. Das heißt, du fängst nicht bei Linien an, sondern wenn du jetzt bloß zwei Schichten hast, dann willst du, dass das eine sofort die Nase erkennt und das ist halt ziemlich schwer. Als wenn das so der Reihe nach zusammengebaut wird. Ist jetzt nicht groß... Ich glaube, das kann man sich vorstellen, oder? Also gibt es jemanden, der damit Probleme hat und der sagt, so kann man das überhaupt nicht sagen? Genau. Also das ist... Ja? Ja, das ist so. Also so in der Regel nimmt man fünf bis dreißig. Aber es gibt auch schon, gab auch schon Versuche, da war es bis zu tausend und das hat auch einigermaßen geklappt, aber dann natürlich nicht mehr einfachst zu. Da muss man spezielle Sachen machen. Aber fünf bis dreißig ist so das, was so normalerweise benutzt wird. Genau. Das ist die Grundidee und man hofft halt drauf, dass immer, je weiter man hintergeht, immer besser wird und besser aussieht. Genau. Hier habe ich es nochmal einfach kurz zusammengefasst für diejenigen, die es vielleicht im Nachhinein noch anschauen wollen. Wenn man sich das mal wie Dialoge vorstellt zwischen den Neuronen, dann könnte so die ersten paar Neuronen sagen, yeah, ich habe hier Ecken gefunden und Kanten und ich habe hier eine Linie gefunden und die nächsten Neuronen sagen dann super, das kann ich toll zu einer Nase kombinieren und bis halt dann die letzte Schicht irgendwie so relativ speziell ist, ist keine Katze oder vielleicht sogar hat eine Brille, hat keine Brille, ist ein Mädchen, ist ein Junge und so weiter. Also da kann man echt coole Sachen rausfinden und das wird auch tatsächlich, also wirklich, man kann wirklich mehr oder weniger erkennen, welches Neuron auf was am meisten reagiert. So ist nämlich auch, so langsam, okay, egal. So ist nämlich auch das Bild von vorher entstanden mit diesen Kanten und so. Das hat sich niemand ausgedacht, sondern hat da wirklich geschaut, welches Neuron reagiert auf was als Eingabe am meisten und hat dann gesehen, okay, die ersten haben die Kanten am meisten reagiert, die zweiten haben dann auf Nasen und so weiter. Das ist also ziemlich cool und das kann man sich wirklich genauso vorstellen.)
2025-10-19 22:56:26 | INFO | retrieval.faiss_segments | results
 Aber im Prinzip ist das Vorgehen eben immer, ich muss mit irgendeiner Methode Kandidaten für diese Keypoints finden, ich muss die Keypoints beschreiben und ich muss die Keypoints dann eben entsprechend auch miteinander vergleichen können. Eine aktuelle Tendenz im Bereich der Bildanalyse ist natürlich das Deep Learning. Beim Deep Learning wird ein künstliches neuronales Netzwerk eben genommen, um Objekte in Bildern zu erkennen. Wir haben das hier mal wieder am Beispiel eines solchen Emblems durchgeführt, also einer bestimmten Art von Holzschnitten, also Drucken aus einem Holzblock heraus, die eben in einer bestimmten Epoche in der Literatur verwendet wurden, um damit Deckblätter und sowas zu gestalten. Was beim Deep Learning dann typischerweise passiert, ist, dass wir erst mal eine Transformation machen. Das heißt, wir skalieren das Bild auf irgendein Standardformat. Und dann werden die einzelnen Bildpunkte als Eingabe in verschiedene Ebenen des neuronalen Netzwerkes gelegt und das sind dann eben entsprechende mathematische Formeln, die da passieren. Das sehen wir uns gleich noch ein ganz, ganz klein bisschen genauer an. Und hier oben kommen dann Klassen raus. Und die Parameter dieser Ebenen hier, die werden jetzt optimiert an Trainingsbeispielen, sodass sie möglichst gut für ein Bild rausfinden, welche Klasse, ob das denn ein Hund oder ein Engel oder ein Buch ist. Und das funktioniert dann dadurch, dass man hier unten praktisch diese Pixelwerte aktiviert und dann hier oben einen hohen Wert durchrechnet, durch die verschiedenen Ebenen und für Engel eine hohe Aktivierung bekommt. Die Verfahren heißen Deep Learning, weil sie eben mehrere Ebenen hier verwenden. Und wir kommen auf diese Art und Weise von den sogenannten Low Level Features, also die Farbwerte der einzelnen Bildpunkte, bis zu den High Level Image Features, nämlich ist ein Buch darin abgebildet oder ein Engel oder ein Hund oder noch vieles mehr. So, ich hatte Ihnen versprochen oder Sie vorgewarnt, dass wir uns das noch ein ganz klein bisschen genauer anschauen wollen. Das ist der Aufbau eines typischen Netzes, wie es eben in der Bildanalyse angewendet wird und das sind sogenannte Convolutional Neural Networks. Convolution? Convolution ist die Übersetzung für Faltung. Faltung? Da war doch was. Ja, wir haben Masken kennengelernt und genau das ist jetzt das Charakteristische, dass diese Maskierungen, also das, was wir kennengelernt haben hier in dem Bereich, als wir die Filtermasken kennengelernt haben und als wir das dann angewendet haben, genau das passiert jetzt auch wieder in diesen künstlichen neuronalen Netzen. Das sind die Convolution Layer, die das machen und die genau solche Masken anwenden, deren Parameter allerdings dann gelernt werden in diesem Trainingsprozess auf der Basis von Trainingsdaten. Das heißt, wir haben ein ursprüngliches Bild. Die Bilder werden typischerweise auf eine Standardgröße dafür skaliert und dann haben wir eben immer mehrere Layer und es gibt eigentlich grob gesprochen zwei Arten von Layern. Nämlich die Convolution Layer, danach kommt noch so eine Aktivierungsfunktion. Ein Rectified Linear Unit, ein ReLU Layer kann da verwendet werden. Das soll uns mal überhaupt nicht interessieren. Wichtig ist für uns die Convolution und das Convolution Layer haben wir jetzt hier mal dargestellt und uns mal größer skaliert. Und da bekommen wir als Input eine Matrix. Letztlich in der ersten Stufe ein Bild, in den späteren Stufen dann, was die Zwischenebenen produziert haben. Das, was wir jetzt machen müssen, ist eine Randbetrachtung. Das heißt, wir machen ein Padding noch da dran. Sie sehen hier, dass die ursprüngliche Matrix, die wurde jetzt hier um einen neuen Rand erweitert, der nichts anderes ist, als dass wir diese Werte einfach nach oben auch noch ergänzen. Damit wir nämlich jetzt unsere Körnel auf die Matrixwerte anwenden können. Und das ist genau die Maskenanwendung, die wir schon kennen. Wir wenden also hier in dem Fall eine entsprechende Schärfungsmaske an. Und bekommen dann hier jetzt entsprechend neue ausgerechnete Werte. Diese Werte, die werden dann auch durch diesen ReLU Layer geschickt. Das heißt, der entscheidet dann, wenn die Werte negativ sind, dann werden die gar nicht durchgelassen, dann werden die auf 0 gesetzt. Das muss man in solchen Netzwerken machen, um gewisse mathematische Eigenschaften zu erhalten. Das braucht uns aber hier nicht zu interessieren. Was uns interessiert ist, dass wir nicht nur diese Convolution Layer haben, sondern daneben haben wir auch Pooling Layer. Und was macht das Pooling? Das verkleinert oder vergrößert das Bild. Im Grunde genommen macht das Pooling fast so was, wie wenn wir Bilder skalieren machen. Nur, dass wir hier ja selber festlegen können, wie viel es kleiner und größer wird. Das heißt, wir machen hier nichts mit Pixeln, die zwischen die Stühle fallen oder so, sondern wir rechnen einfach aus jeweils zum Beispiel 4 Pixeln, das könnten auch 9 Pixel sein, wir könnten auch andere Strukturen machen, einen neuen Wert aus. Und eine sehr einfache Form des Pooling ist das Max-Pooling, so dass wir einfach die Information jetzt verdichten. Und das wird eben über sehr viele Ebenen gemacht. Häufig werden dann auch alle Ebenen erhalten. Das heißt, es gibt noch solche Bypasses, wo die Informationen der vorherigen Ebenen weitergeführt werden. Und dann wird das Ganze umgeformt. Die einzelnen Werte hier werden dann umgeformt zu einer linearen Struktur. Und die wird dann wieder verbunden über entsprechende einfache Formeln mit der nächsten Ebene. Und am Ende haben wir wieder einzelne Knoten in unserem neuronalen Netz, die für Fuchs, Engel und Himmel stehen. Diese Layer hier unten, die eben aus Convolution Layern und Pooling bestehen, das sind die Hidden Layers, die im Grunde genommen die Funktion haben, die Features, die Eigenschaften der Bilder, die für diese Klassifikationsaufgabe wichtig sind, herauszurechnen. Und deshalb werden die Parameter dieser Ebenen jetzt gelernt in einem Trainingsprozess, wo wir eben Bilder mit annotierten Füchsen, Engeln, Himmel, Kopf und so weiter in das Netz hineingeben. Und die Parameter über die Ebenen, die Gewichtungen der Ebenen, die werden dann eben gelernt an den Trainingsdaten. Und dann können wir das nachher anwenden auf entsprechende weitere Daten und können damit eben eine Zuordnung machen. Wichtig ist, dass man sieht, dass diese Hidden Layers Features, Eigenschaften letztlich erzeugen, die durchaus vergleichbar sind zu unseren Eigenschaften, die wir hier hatten. Das heißt, im Grunde genommen sind das von Menschen ersonnene und erfundene Features, die eben optimiert waren für bestimmte Aufgaben der Objekterkennung. Und dadurch, dass man das jetzt in einem solchen neuronalen Netzwerk lernen lässt und da auch lernen lässt, welche Eigenschaften und so was das Ganze beeinflussen sollen und wie gewisse Charakteristika dann gewichtet werden oder auch nicht, dadurch bekommt man eben eine Mächtigkeit, die allerdings dann darauf basiert, dass wir Trainingsdaten haben. Und damit lässt sich dann zum Beispiel die Annotation eines großen Bildbestandes machen. Wenn man hinreichend viele Trainingsdaten hat, überträgt man das Wissen. Es gibt da aber auch durchaus kritische Stimmen. Ein Beispiel, um das deutlich zu machen ist, es gibt ein, jetzt muss ich aufpassen, ich kriege das Beispiel nicht mehr ganz genau hin, also nehmen Sie es bitte nicht zu wörtlich, aber es gibt einen großen signifikanten Beispieldatensatz, mit dem Netze vorgelernt wurden. Und darin ist auch das Konzept Philosoph. Und es gibt aber in dem ganzen Datenbestand genau drei Beispielbilder, die Philosophen enthalten. Und das sind alles alte, weiße Männer. Das heißt, in diesem Netz ist sozusagen Diskriminierung eingebaut, weil das Netz lernt, wenn etwas ein Philosoph ist, dann muss es ein alter, weißer Mann sein. Das heißt, das ist das Problem von diesen Netzwerken, dass sie dann auch ein Trainingsbias bekommen. Das heißt, sie lernen eben das, was im Trainingsdatenbestand ist. Dabei versuchen sie schon zu verallgemeinern. Aber wenn eben gewisse Dinge nicht im Trainingsdatenbestand drin sind, fällt ihnen das Verallgemeinern natürlich sehr, sehr schwer. Lassen Sie mich noch ein Beispiel für die Anwendung von solchen Netzen andeuten. Und das ist hier StyleGAN. Da werden Bilder erzeugt. Und zwar in der Form, dass wir ursprünglich, wir geben nur solche Random Pictures in das Netz hinein. Das heißt, es werden wirklich Zufallszahlen erzeugt. Aus diesen erzeugten Zufallszahlen muss dann ein neuronales Netz, das ähnlich diesem hier aufgebaut ist, Bilder erzeugen. Und das tut es. Es erzeugt Fake-Bilder, zum Beispiel dieses hier. Und dann muss ein Diskriminator auch wieder ein neuronales Netz entscheiden. Der hat als Input dann hier entsprechende Bilder und entscheidet nur fake oder nicht fake. Und das heißt also, der hat Beispielbilder, der ist trainiert und bekommt dann jetzt neue Fake-Bilder und entscheidet dann, ist es fake oder nicht fake. Dadurch wird dieses Netz trainiert, relativ gute Bilder zu erzeugen. Wir sehen hier nach einem Trainingsprozess, das iteriert sich dann dran, das produziert immer neue Fake-Bilder und dann muss es entscheiden. Und dann wird nachher gesagt, ja, war fake oder nicht. Und auf die Art und Weise wird das Netz immer besser. Und wir sehen hier, das war am Anfang. Das ist sozusagen das Random-Bild, das reingeschubst wurde. Trainingsdaten waren solche Embleme. Hier sieht man eben ein Beispiel, wie die aussehen. Und das sind die Charakteristika, die man sich dann so vorstellt. Das ist das, was zum Beispiel nach 801 Trainingsschritten erzeugt wurde. Es sieht immer noch nicht so richtig gut aus. Nach gut 3.000 Schritten, nach 6.000 Schritten, nach 8.000 oder 7.700 Schritten und nach 8.406 Iterationen. Und man sieht, da kommt so langsam was raus, was tatsächlich ein Emblem sein könnte und was wirklich schwer zu unterscheiden ist. Und so kann man eben dann Netzwerke, Bilder erzeugen lassen. Und die können dann als Künstler in Anführungsstrichen auftreten. Nun kann man in solche Netzwerke nicht nur Bilder erzeugen, Nun kann man in solche Netzwerke nicht nur Zufallswerte reinschieben, sondern man kann in solche Netzwerke auch schon Bilder reinschieben. Und das kann man zum Beispiel machen, indem man normale Bilder nimmt, wie man sie von der Fotokamera aufgenommen hat. Die schiebt man dann da rein und die werden überführt in entsprechende Embleme. Da muss man jetzt noch einen Rückkanal einbauen, das kann total unähnlich dem ursprünglichen Bild werden. Und dann kann man das machen, was als Style-Transfer heute relativ populär ist. Man kann Bilder in eine andere Bildsprache übersetzen. Man kann aus normalen Fotos Aquarelle machen oder Monet-Bilder oder eben auch solche Strichzeichen. Das heißt, die Möglichkeiten damit dann im Grunde genommen auch Bildbearbeitung zu machen, bestehen, indem ich solche Strukturen eben nicht nur verwende, um Fake-Bilder zu erzeugen, sondern ich kann die auch verwenden, um dann einen Rückbezug zu machen. Wie gut kann ich den Ursprung wieder heraus erzeugen und dann kann ich hier eben nicht Zufallswerte reinschieben, sondern ein entsprechendes Bild. So, das war jetzt die halbe Stunde, die ich mir vorgenommen hatte im Bereich der Bildanalyse, damit Sie eben einen kleinen Eindruck auch davon bekommen, welche Verfahren da zur Anwendung kommen können und welche Möglichkeiten da auch bestehen. Tatsächlich ist es eben so, dass für manche Dinge auch einfacher Verfahren ausreicht. Lokale Features reichen eben für Objekterkennung in vielen Bereichen. Wenn Sie Bildbearbeitung in einem industriellen Produktionsprozess haben und dann eben Ausschuss raussortieren wollen, weil irgendwelche Eigenschaften fehlen oder wenn Sie eine Menge von Objekten haben, die reinkommen und Sie müssen die in fünf Kisten sortieren durch Luftdruck oder sowas, dann mögen SIFT-Verfahren oder ganz einfache Verfahren durchaus ausreichend sein. Deep-Learning-Verfahren haben immer das Problem, dass sie große Trainingsdatenmengen brauchen. Wenn die aber da sind, dann können sie natürlich sehr leistungsfähig eingesetzt werden, wobei man immer beachten muss, dass ein gewisser Bias, eine gewisse Tendenz eben aus den Trainingsdaten dann auch kommt und dass die Fähigkeit davon komplett zu abstrahieren eben letztlich dann doch nicht da ist. Gut, das soll es zum Medientyp Bild gewesen sein.)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | results
 Und jetzt ist die Frage, was ist der Stand heute? Der KI-Effekt ist, dass mittlerweile sehr viele KI-Anwendungen, also KI-Methoden in die Anwendung geschafft haben und ohne, dass man die KI nennt. Sie haben es gerade eben gehört, weil man KI nicht so toll fand, den Begriff, oder weil er negativ konnotiert war. Und das führt dazu, dass KI jetzt überall ist und man es nicht als solcher erkennt, weil man es auch nicht so nennt. Das Umgekehrte ist auch der Fall. Ich rede, da kommen KI-Chips in Handys und da werden KI-Chips gebaut und eigentlich sind es nur, sage ich mal, in GPUs, also Schleuder-Prozessoren. Aber man nennt es jetzt wieder KI. Aber 2006 hatten sie noch sehr viele KI-Systeme, die man einfach nicht so genannt hat und das hat dazu geführt, dass das nicht so ankam. Also man hat die Erfolge nicht als KI erkannt. Und da hat Marvin Minsky, der lebt leider nicht mehr, das war 2016, ist er gestorben, aber der hat es nochmal zu Wort gewählt, 2011, gesagt, das Paradoxe an der Situation ist, dass jedes Mal, wenn ein KI-Projekt einen Erfolg hatte, eine neue Entdeckung gemacht hat, dass man das schnell, dass es ein Produkt gab, was eine neue Art von, was man als neue Spezialität bei einem Spin-off, neue Methode, neue Richtung erkannt hat oder genannt hat, mit einem eigenen Namen und das man dann nicht mehr mit KI assoziiert hat. Und dann Fragen außenstehende, ja, aber warum macht KI keine Fortschritte? Weil die Fortschritte in lauter Teilgebieten der KI entstanden sind, die manche nicht mit KI assoziiert haben. Und sehr schön ist auch, das gilt auch heute noch von 1970, das Zitat, Intelligenz ist, was auch immer Maschinen noch nicht gemacht haben. Als das erste Mal erklärt wurde oder bekannt wurde, wie die Blue funktioniert, also der Schachcomputer, dass er nämlich einfach, grob gesagt, alle Kombinationen, alle möglichen Züge bis einer gewissen Tiefe durchprobiert, hat man gesagt, das ist ja keine Intelligenz, der probiert ja nur durch. Und so ist es auch jedes Mal, wenn Sie jetzt eine KI programmieren, die irgendwas löst, eine Wegfindung, hier Routenplanung, sonst irgendwas, da heißt es dann, wenn jemand versteht, wie es geht und merkt, das ist ja eigentlich ganz viel Rechnen und ganz viel Mathematik, dann heißt es oft, das ist ja keine Intelligenz. Da sind wir wieder bei diesem Vergleich, kann ein U-Boot schwimmen? Das ist, wenn wir sagen, ja, das ist ja kein Schwimmen in dem Sinne. Und da sagt man, ja, es ist ja kein Denken in dem Sinne. Wieder bei dem Punkt, Intelligentes Handeln und Intelligentes Denken. Intelligentes Denken wird in Programmen einfach auch abgesprochen, aber Intelligent Handeln, naja, soweit sind wir mittlerweile schon. Ich habe diese Folie nochmal, also Verzeihung an die Informatiker, die es schon gesehen haben, die Folie kennen Sie. Ich habe 2015 einen Vortrag gehalten und habe damals diese Folie gemacht, Stand der KI heute, also das ist jetzt schon sechs Jahre alt, einfach um Ihnen auch nochmal den Vergleich zu geben, was hat sich seitdem getan. Das autonom fahrende Auto von Google hat 2015 elf Unfälle auf 1,5 Millionen autonom gefahrenen Kilometern verursacht und an keinem oder war beteiligt gehabt und an keinem davon war das Google Auto selbst schuld. Mittlerweile gibt es ein paar mehr Fälle, wo selbstfahrende Autos schuld waren, aber das war, also dieser Treppenblitz, dass es immer zehn Jahre entfernt ist, kommt langsam zum Ende, weil die KI nun doch schon nah dran ist. Genauso die Spracherkennung. Ich habe es gestern auch schon erzählt. Ich kann mich an Spracherkennung erinnern, dass es nicht funktioniert hat. Trepperquoten von 90, 95 Prozent, also hier ist das zwanzigste Wort falsch und das hat mir damals, war für mich nicht anwendbar. Vor allem auch, weil ich schnell spreche, war für mich die Spracherkennung nie richtig gut. Aber wenn ich jetzt sehe, was mein Handy oder was Amazon Alexa alles erkennt, ist schon sehr beeindruckend. Also auch was für einen Akzente, Genuschel, Dialekte, verschiedene Sprachen, ist schon krass, was es kann und wir sehen sie ja auch in der FAZ von 2014 war auch der Kommentar Spracherkennung. Das war auch die Technik, die nicht perfekt funktioniert hat, oder? Und die Leute waren überrascht, weil sie es auch noch kennen als so klappt es ja auch nicht. Und so wie man von KI-Wintern redet, redet man auch oft vom KI-Frühling, also das ist nach dem Winter kommt der Frühling, dass durch Deep Learning jetzt wieder sehr viele KI-Anwendungen, also sehr viel KI in den Fokus gerückt ist. Es gibt wieder richtigen KI-Hype. Alles ist Deep Learning. Überall heißt es, wir wollen nicht Deep Learning machen. Und das wird auch erfolgreich eingesetzt, wie gesagt, bei Amazon Alexa, Google Sprachassistent, Apple Siri, was sie alles haben. Sie haben Spiele-KIs, die mittlerweile Menschen schlagen. AlphaGo Master hat neue Strategien entwickelt. AlphaGo Zero im selben Jahr entwickelt hat, also beim Go-Spiel, hat sogar erfolgreiche Beispiele gelernt, indem es nur gegen sich selbst gespielt hat und dadurch die Regeln gelernt hat. Und nach nur 40 Tagen, aber immensen Hardware und wahrscheinlich auch Stromkosten, war es besser als alle seine vorherigen Versionen. Und 2019 hat AlphaStar in StarCraft II Großmeisterrang erreicht. Und das ist hier nochmal was anderes, weil das in Echtzeit Strategiespiel ist und nicht rundenbasiert wie Schach oder Go. Also die Frage kam gestern, rundenbasiert heißt ja in dem Fall, sie haben fast beliebig viel Zeit. Sie haben eine gewisse Zeit, ihre Entscheidung, ihren nächsten Zug zu überlegen und dann lässt der Gegner seinen Zug. Und in Echtzeit, während sie überlegen, entwickelt sich die Welt weiter. Das ist der große Unterschied und deswegen ist es nochmal schwieriger, weil sie schnell Entscheidungen treffen müssen und auch während sie Entscheidungen treffen, vielleicht neue Informationen in ihre Entscheidungen einfließen lassen müssen. Und Deep Learning hat viele Durchbrüche verursacht. Also ich habe auch gesehen, ein paar von ihnen haben letztes Semester das Seminar Machine Learning bei Thomas Wieland belegt. Also ein paar von ihnen haben das hier schon mal gesehen vermutlich. Sogenannte Convolutional Neural Networks erkennen Ziffern besser als Menschen, schon seit einigen Jahren, auch Verkehrsschilder glaube ich. Also sie machen weniger Fehler. Es gibt Neural Style Transfer, der den Stil von Gemäden auf Bilder übertragen kann. Das ist auch Deep Learning. Super Sampling erzeugt hochauflösende Bilder aus kleinen Bildern. Sie können also eine kleine Auflösung auf eine hohe Auflösung hochrendern, sagen wir mal voller DO4K. Deep Learning, NVIDIA nennt es DLSS, also vermutlich Deep Learning Super Sampling, aber ich glaube, ich habe einen TM vergessen, der Begriff gehört denen. Deep Fake, wo sie Gesichter auf andere Personen draufsetzen können.)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | retrieval 15)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | results
 Was dabei helfen kann, ist Natural Language Processing. Was gehört bei der Sprachverarbeitung dazu? Lemmatisierung, also Grundformreduktion. Laufen, gelaufen, lief wird eben auf Grundform reduziert, weil die Bedeutung doch eigentlich die gleiche ist. Student, Studentin, Studentin wird alles auf einem Lemma reduziert. Dann ein sehr spannender Punkt ist eben der Umgang mit Synonymen, Homonymen, Mähronymen. Also Homonyme, ein Beispiel für Homonyme ist auch Wasserhahn oder sowas, was eben der Wasserhahn sein kann oder der, der auf der Miste kräht. Mähronyme, ganze Teilebeziehungen oder sowas, wo man eben auch sagt, naja, wenn jemand nach einem bestimmten Teil sucht, dann ist vielleicht für ihn auch relevant ein Dokument, das sich um das Ganze kümmert und nicht nur ein Dokument, das das Teil adressiert. Synonymie ist dabei ein Riesenfeld und ein Riesenproblem, weil was auf einem abstrakten, groben Level vielleicht synonym ist, ist es im Detail, in Fachtexten dann nicht. Das ist insbesondere ein Problem von Vertical Search, weil auf der ganz oberen Ebene sagt man vielleicht, naja, Datenbank, Datenbankmanagementsystem und SQL ist irgendwie synonym. Es sei denn, Sie betrachten einen Artikel zum Datenmanagement, dann ist es keineswegs synonym, was sich dahinter verbirgt. Und deshalb ist es auch nicht einfach, diese Sachen dann zu nutzen, weil ich sie immer im jeweiligen Kontext sehen muss und speziell berücksichtigen muss, was wirken die da. Ein anderer sehr spannender Punkt ist Named Entity Recognition. Das einfachste ist Eigennamen, Hans Meyer oder sowas. Und weshalb ist das wichtig? Weil Sie oft lieber wissen, da ist ein Personenname als den konkreten Personennamen. Also Sie wollen einfach gucken, dass da ein Personenname ist oder dass da eine Datumsangabe ist und so. Und das konkrete Datum interessiert Sie eigentlich nicht. Eine andere Geschichte ist, dass Sie natürlich auch möglichst genau identifizieren wollen, gerade wenn Sie an bibliografische Datenbestände denken oder an andere Dinge. Welche Person ist es denn? Deshalb gibt es dafür Normdaten, GND-Ansetzungen, also die gemeinsamen Normdatei und sowas, wo Sie dann wirklich sagen, naja, Goethe oder Schiller, dann ist der oder der gemeint. Weil ich meine, es gibt viele Schillers, aber vielleicht mal einen Speziellen und das muss man dann eben klären. Und ein weiterer Bereich ist dann die Art of Speech Tagging, sodass ich bestimmte Wortformen herausfinde. Aber ein Problem ist zum Beispiel, dass Anfragen nur sehr kurz sind und viele Verfahren des Natural Language Processing setzen eigentlich voraus, dass ich ganz vernünftig strukturierte Sätze habe. Das heißt, auf Anfragen funktioniert das Ganze nur sehr bedingt und Texte in den Dokumenten sind auch sehr unterschiedlich. Das Beispiel Newsartikel versus Twitter-Nachrichten hatten wir ja schon. Sie können ja mal versuchen, eine Standard Natural Language Processing-Pipeline auf Twitter-Texte anzuwenden. Da kommt halt mäßig Gutes daraus. Wenn Sie das auf Newsartikel anwenden, dann klappt das wunderbar im Normalfall. Beispiel, nur damit wir es schon mal erwähnt haben, wir kommen dann später noch dazu, eben eine linguistische Geschichte, so ein Grammatikbrowser, der eben jetzt versucht, einfach den einzelnen Wörtern in einem Satz hier entsprechend die Wortformen zuzuordnen. Und dann bekommen Sie hier eben Möglichkeiten, die Ihnen dann in nachgelagerten Schritten helfen, das Ganze besser zu interpretieren. Und deshalb, Natural Language Processing ist typischerweise auch so eine Pipeline, die eben erstmal mit Tokenizing beginnt. Also, was ist überhaupt ein Wort? Das ist im Deutschen ja auch schwierig, weil wir eben Komposite haben, die zusammengeschrieben werden. Und dann im Englischen habe ich aber wieder das Problem, Phrasen zu identifizieren und herauszufinden, dass das eine Phrase ist. Also, dass ich vielleicht Information und Retrieval nicht als Information und Retrieval abspeichern sollte, sondern als Phrase Information und Retrieval und so weiter. Dazu aber später dann im Kapitel zur Textverarbeitung mehr. Die Evaluation hatten wir schon angesprochen. Hier geht es um experimentelle Verfahren und Maße und die Ergebnisse eines Systems, den Erwartungen eines Nutzers zuzuordnen, damit zu vergleichen. Das Ganze geht zurück, man hat in den 1960er Jahren damit angefangen, stark im Bibliothekskontext. Auch noch Cranfield-Experimente wurden die damals genannt, weil sie eben dort gemacht wurden. Und es geht um IR-Evaluierungsmethoden, die mittlerweile in sehr, sehr vielen Bereichen und sehr exzessiv angewendet werden. Meist werden Testkollektionen immer noch verwendet. Die bestehen aus Dokumenten, Anfragen und Relevanzurteilen. Das heißt also, wir haben als Dokumente beispielsweise einen Korpus von Nachrichtenartikeln, drei Millionen Nachrichtenartikel. Wir haben 50 Beispielanfragen und irgendwelche Experten haben sich überlegt, welche Dokumente relevant sein könnten für diese 50 Beispielanfragen. Am weitesten verbreitet waren lange Zeit die Track-Kollektionen und sie sind immer noch das Vorbild dazu. Und ja, Recall und Precision sind dann gleich zwei Maße für die Effektivität. Fangen wir mit der Track an. Track ist The Text Retrieval Conference und die wird jährlich durchgeführt. Es gibt in Track immer neue Aufgaben, also neue Anfragen. Es gibt auch neue Charakteristika. Mal wurde Mail-Suche gemacht, dann wurde medizinische Suche gemacht, dann wurde Web-Suche gemacht, dann wurde Expert-Search gemacht und vieles andere. Und auf den Webseiten, die beim NIST in Maryland gerostet werden, gibt es dann eben die Daten, die man zum Teil erwerben muss, die nicht alle frei sind und es gibt dann die Tracks, die die einzelnen Aufgabenbeschreibungen beinhalten.)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | results
 symbolisch sprachlich kommunizieren können es ist sogar so dass Menschenaffen denen man irgendwelche Spezialsprachen im wesentlichen Zeichensprachen dass die die ihren Nachkommen beibringen und auch untereinander benutzen und wildfremde Menschen anquatschen die merken das zwar nicht weil die dann Zeichen machen gib mir bitte ein Eis oder so etwas aber Sprache gibt es im Tierreich eingeschränkt Shakespeare bei Delfinen ist noch nicht bekannt geworden aber wie funktioniert das überhaupt wichtiger Teil der künstlichen Intelligenz solche Sachen alle diese Sachen würden in einer KI3 drankommen aber dazu haben wir hier nicht die Ressourcen vor allen Dingen sie nicht es gibt einige Spezialvorlesungen es gibt den Stefan Ewert in der Computerlinguistik der macht im wesentlichen statistische Methoden zur Sprachverarbeitung also so machine learning basierter modernes Zeugs und ich biete im nächsten Semester eine kleine Vorlesung an zur logikbasierten Bedeutung natürlicher Sprache und da geht es darum also ich will jetzt sozusagen unmittelbar in die Werbung fürs nächste Semester eintreten und ich glaube nicht dass ich hinten mit KI1 kommen kann da gibt es eine Vorlesung wo es darum geht Sprache was bedeutet das überhaupt und die Idee ist dass man sprachlich solche Äußerungen so was wie Peter liebt seine Frau übersetzt in überführt in Formate wo man Inferenz machen kann wo man Sachen nachprüfen kann beschreibt das überhaupt was ich sagen wollte und da gibt es ein paar Phänomene wo man tatsächlich mehr braucht als statistische Methoden Statistische Methoden sind wunderbar wenn man rauskriegen will sind zwei Sätze ähnlich was Suchmaschinen Zeugs ich gebe ein Peter liebt seine Frau und dann kriege ich in Google irgendetwas wieder was irgendwie da mit was zu tun hat wobei aber die Trennschärfe die man hat unter Umständen nicht das ist was man will zum Beispiel so was wie Peter liebt seine Frau nicht gibt praktisch dieselbe Begründung wie Peter liebt seine Frau nicht gibt praktisch dieselben Resultate wie Peter liebt seine Frau obwohl das für seine Frau sehr unterschiedlich sehr unterschiedliche Welten sein könnten es geht um mit den statistischen Methoden kriegt man Ähnlichkeiten raus und solche Sachen während man mit Logik basierten Verfahren sehr viel klarere Dinge hat wenn man sie denn kriegt Logik basiert geht normalerweise gut wenn man extrem kleine Welten hat über die man sehr viel weiß dann gehen diese Dinge gut Statistische Verfahren geben einem immer irgendetwas manchmal weiß man nicht so genau was aber es ist total breit anwendbar und je nach Anwendung wird man mit dem einen oder dem anderen glücklich Sachen die wir uns angucken wollen sind sowas von der Bauart sehr häufig sowas wie Ambiguitäten es gibt immer in der Sprache mehrere Lesarten häufig erstaunlich viele Lesarten und dann fragt man sich welche der Lesarten sind denn okay wenn Sie sich sowas angucken wie Peter liebt seine Frau kann man sich vorstellen was das heißt und dann hört man einen elliptischen Satz wie Klaus auch das ist erstmal das Problem was bedeutet das was ist denn die Bedeutung von auch in diesem Fall)
2025-10-19 22:56:27 | INFO | retrieval.faiss_segments | results
 Aber dieses Buch und das muss ich sagen finde ich sehr schön hangelt sich hier an diesen Agentenarchitekturen hoch und bindet auch alles wieder könnte man wahrscheinlich noch an ein paar mehr Stellen machen und ich vermute mal wenn eine neue Edition rauskommt, dass Sie das wahrscheinlich dann noch konsequenter machen. Bindet wieder in diese Agentenarchitekturen zurück und wir hatten uns ein paar angeguckt. Wir hatten uns diese einfachen Reflexagenten angeguckt hatten hatten hatten da gesehen dass die relativ gut mit diesen Suchproblemen in gewisser Weise fertig werden können. Man hat eben diese ganzen Regeln die sowohl heuristisch sein können als auch deterministisch also so zum breiten Suchalgorithmus das ist im Wesentlichen so die Klasse von Dingen die hier drin vorgehen. Dann haben wir dann haben wir zustandsbasierte haben wir zustandsbasierte Agenten also diese lokalen Suchalgorithmen Hillclimbing und so was das ist so ungefähr was in solchen Agenten passiert und auch das ist das Beste was die im Wesentlichen können. Dann wenn man Zustand hat wenn man weiß wo man ist dann kann man systematisch suchen muss sich dann aber natürlich auch den Zustand merken und man hat hierbei auch bei zustandsbasierten Agenten hat man dann auch sozusagen die Unterscheidung einerseits in voll observierbaren voll sichtbaren environments kann man entweder direkt auf den Zustand arbeiten das ist das was wir im letzten Semester gemacht haben was wir heute was wir in diesem Semester gemacht hatten war das wir nochmal dazwischen geschaltet haben das es diesen belief state gibt belief state als was glauben wir von der Welt ja wir haben einen Zustand der mehr oder weniger dass wir von der Welt was wir von der Welt wissen was unvollständig sein kann widerspiegelt und das ist genau das wofür wir die propositionale Inferenz probabilistische Inferenz brauchen das ist der Übergang zu diesen belief states und das müssen wir modellieren dann hatten wir uns als es dann rüber ging in die Entscheidungstheorie gab es zielbasierte Agenten nein stimmt gar nicht es ging rüber in die Planung da hatten wir explizite Ziele die wir verfolgen wollten in der Planung und hatten die Welten die sich auch noch verändern können durch unsere Aktion und da haben wir im wesentlichen Modelle einerseits was wir entweder den Zustandsraum wenn wir den dann sehen können oder den belief state und wir hatten dann plötzlich Modelle die darüber redeten wie sich die Welt verändert durch unsere Aktion im einfachsten Fall sind das Planungen wo wir Sie erinnern sich in diesem Strips Ansatz hatten das war einfach wenn man von A nach B fährt dann war man vorher in A das muss man als Weltzustand wegnehmen und ist hinterher in B ich bin in B muss man zum Zustand dazu nehmen das sind ganz einfache Transitionsmodelle für die Welt wie sich die Welt verändert durch unsere Aktion wir haben noch keine Modelle meistens da drin die sich die irgendwie die Weltveränderung durch andere Leute Aktionen dann kommt man dann in die Mehrspieler Spiele rein wo andere Agenten auch noch agieren können und schließlich sind wir dieses Semester in diese nützlichkeitsbasierten Agenten vorgestoßen wo wir uns aus der Entscheidungstheorie wirklich Nützlichkeiten angeguckt hatten die uns wiederum irgendwie die verbunden sind mit Präferenzen die man tatsächlich sehen kann die Nützlichkeit gibt uns dann die Möglichkeit über rationale Agenten nachzudenken weil wir versuchen können Nützlichkeiten ähm zu maximieren ja und schließlich gibt es zu alledem auch noch lernende Varianten wenn man sich hier angucken kann da kann man lernen was sind die Nützlichkeiten wie verändert sich die Welt kann man lernen was lerne ich überhaupt über die Strukturen der Welt solche Dinge und wenn man lernen kann kann man einerseits sich an verändernde Umgebungen anpassen wenn ich rauskriege dass sich die Verkehrsregeln geändert haben dann sollte ich mein Verhalten anpassen sonst äh kriege ich Probleme und andererseits wenn ich eben nicht sehr viel weiß über die Welt kann ich durch Exploration der Welt irgendwas rauskriegen und alle diese Dinge haben wir gesehen in den etwas komplizierteren ähm Belief State und Transitionsmodell ähm getriebenen Architektur die wir uns in diesem Semester angeguckt haben lernen funktioniert dann wenn man einen einen ähm einen Evaluationskanal hat wo einem irgendwie von außen klar wird wie gut war ich denn jetzt in meiner Welt es gibt so eingebaute Dinge wenn man anfängt Hunger zu kriegen dann weiß man das war wohl nicht so gut ja und wenn man es gibt die Glücksrezeptoren die man natürlich auch immer versucht zu stimulieren und so weiter und das ist so ein von außen gegebener Performancestandard und ähm den versucht man zu optimieren wie viele Nachkommen habe ich oder wie viele Papiere habe ich geschrieben oder wie viel Geld habe ich auf der Bank alle solche Sachen das sind so von außen gegebene Performancestandards wie gut sind meine KI2 Noten solche Dinge und die stoßen dann eben diese Lärmeffekte an das ist übrigens auch die Quelle der positiven und negativen Beispiele ja wenn Sie Hausaufgaben machen und da steht 0 Punkte dran dann ist das ein Gegenbeispiel dann versuchen Sie irgendwas auf dieser Schiene hier zu ändern sodass dann beim nächsten Mal wenigstens ein Punkt oder zwei Punkte dransteht oder so etwas aber Lernen und das ist glaube ich etwas was ganz wichtig ist geht nur dadurch dass man in einem externen einen externen Reiz hat der einen Standard setzt gegen den man sich vergleichen kann oder bezüglich dessen man lernen kann das ist also nicht hier der Sensor ein obwohl das natürlich auch so etwas wie Hunger oder so etwas oder Zeugnis angucken das ist natürlich auch sensorisch aber das hängt nicht so stark von der ähm von der Umgebung ab deswegen haben wir einige dieser oder nimmt man an deswegen haben wir einige dieser externen Performance Standards sowas wie zum Beispiel Hunger oder Glücksgefühle oder sowas sozusagen in der Hardware in unserer biologischen Hardware drin ja und die sind nicht alle kulturellen ähm umgebungsveränderlichen ähm Variablen ähm unter ähm oder erlernt oder einflüssen ja das ist bei Kindern auch so die lernen erst mal optimieren ihre ähm ihre eingebauten Performance Standards ja wenn sie hungrig sind merken sie dass sie brüllen müssen solche Dinge und erst später kommen dann irgendwie solche geplagerten anderen Befriedigungsmethoden dazu ja ähm ähm wir haben in diesem Semester uns relativ stark an diesen rationalen ähm Agenten entlang gehangelt die versuchen die erwartete Nützlichkeit zu optimieren ob mitlernen oder ohne ja und ähm das ist einmal haben wir hier die Nützlichkeit drin sehr wichtig und zum anderen weil wir nur partielle Informationen haben ähm die erwartete Nützlichkeit Rationalität ist nicht das man tatsächlich optimiert ja man weiß meistens nämlich nicht wie das gehe man hat nicht genug Information oder man kann nicht genug rechnen man hat nicht genug Zeit aber wenn irgendwie ein Auto auf einen zukommt dann versucht man sich zwar zu überlegen springe ich nach rechts oder springe ich nach links weg aber wenn man zu lange überlegt dann kann man es auch gleich bleiben lassen da geht die erwartete Nützlichkeit von rechts oder links geht zu irgendeinem Zeitpunkt extrem schnell nach unten und deswegen ist es unter Umständen wichtiger dass man einfach irgendwas macht ähm und das hübsche an diesen rationalen Agenten ist es dass man alle dass man vor dieser Schablone der Nützlichkeitsmaximierung sehr viele Verhaltensweisen die wir so landläufig als intelligent bezeichnen würden ja dass man seine Umgebung exploriert dass man versucht zu lernen über seine Umgebung oder sowas dass sie sich praktisch sofort in ähm in Nützlichkeitsgewinnen niederschlagen und wir können wenn wir gewisse Annahmen treffen das ganze auch sogar quantifizieren ja wenn wir uns jetzt nochmal angucken was haben wir da gemacht jetzt in diesem ähm in diesem Framework da hatten wir uns erstmal dieses Problem Solving angeguckt da waren da hatten wir eben diese im wesentlichen diese Black Box Zustände hatten Übergänge die durch die Aktionen kamen und hatten irgendwelche Heuristiken die irgendwie versuchten irgendwie Wissen und Struktur damit reinzubringen ähm hatten uns dann langsam durchgehangelt bei den Constraint Satisfaction Problemen kamen eben Strukturen in der ähm Zustandsbeschreibung rein die es uns erlaubten bessere Heuristiken zu machen ähm das wurde dann noch stärker bei den stärkeren Sprachen die wir hatten in der Aussagenlogik erst und hinterher sogar in der Logik ähm erster Stufe ähm und dann hinterher hatten wir uns Planungen angeguckt wo es eben nicht nur darum ging ähm die Welt wahrzunehmen und ein etwas über die Welt aussagen zu können ähm sondern tatsächlich auch was zu zu agieren Sequenzen von Aktionen vorzuplanen und dann hinterher auszuführen ähm wir sind dabei im übrigen ähm wieder auf die Aussagenlogik zurückgefallen wie wir das relativ häufig tun weil ähm Logik erster Stufe häufig noch immer zu schwer ist ja genauso übrigens ähm jetzt in dem was wir wir haben im Prinzip nur zwei große Themen gemacht wir haben einerseits die ähm Unsicherheit und partielle Information ähm ähm äh eingeführt in diesem Semester ähm haben dafür sehr viel Statistik äh sehr viel Stochastik gemacht ähm haben uns dann immer weiter vorgehangelt in die ähm komplexeren Umgebung und hatten dann im wesentlichen diese gesamte Lernerei ähm abgehandelt als eine Facette die man so die man so nebenher ähm als zusätzliche Schiene in jedem Agenten machen kann ähm ich hätte gerne ein bisschen mehr Zeit gehabt ähm äh es gibt ganz schön auch in Russell & Norvig beschrieben zum Beispiel wie man ähm solche so einen einfachen Reflex-Agenten lernen kann ja wenn man sich jetzt mal vorstellt dass man irgendwie ähm Lern- oder Optimierungsverfahren hat für für Geisselbakterien oder sowas ja die haben ja auch irgendwelche Reflexe und dann ähm wenn es links zu warm ist dann schwimmen sie nach rechts oder sowas und die müssen das ja irgendwie zumindest imponitorisch gelernt haben wie kann sowas passieren ja und das kann man relativ gut modellieren ähm genau ähm wenn wir uns jetzt nochmal angucken was haben wir tatsächlich gemacht wir haben ein paar Frameworks gesehen ja wir haben das Framework war tatsächlich alles immer die die probabilistische Inferenz und da waren diese ähm abhängigen Wahrscheinlichkeiten aber auch äh abhängige ähm ähm ähm diese ähm abhängigen Unabhängigkeiten ähm waren eine waren ein wichtiges ähm wichtiges Mittel und das Haupt wofür wir das gebraucht haben ist das wir ähm da wir unvollständige Informationen hatten tatsächlich vom State Space auf den Belief Space hoch mussten ja also das ist das konzeptionell was dabei passiert ist und ähm wir mussten unsere Verfahren komplett umschmeißen weil wir unvollständige Informationen haben ja implementiert haben wir das ganze in den Bayeschen Netzwerken und haben die dann hinterher ähm über diese Nützlichkeitsfunktionen ähm zu Entscheidungstheorien gerade im Sinne des äh des rationalen Maximierens der erwarteten Nützlichkeit aufgebohrt ähm hatten das dann hinterher noch um irgendwie eine Zeitkomponente erweitert weil wir ähm mit diesen nur mit Unsicherheit kamen wir tatsächlich immer nur in diesen episodischen ähm in episodischen Umgebungen ähm ähm weiter in denen sich entweder gar nichts ändert oder die Sachen sich die Welt sich so langsam ändert dass wir so tun können als ob sie sich gar nicht ändert ja und ähm wenn man wenn man in Sequenz in speziellen Umgebungen ähm ähm überleben will dann muss man irgendwie mit der Zeit umgehen und dafür braucht man dann so Methoden wie Markov Prozesse und ganz explizit mit reingerechnet die Übergangsmodelle ähm und wenn man das ganze wiederum auf die Entscheidungsebene bringt dann kriegt man diese Markovs Entscheidungsprobleme und ähm partiell sichtbare Markov Entscheidungsprozesse dieser POMDPs ähm also was man das ist aber dasselbe erweiterte das Framework genauso im Prinzip erweitert wie wir das hier oben um Nützlichkeiten und Entscheidungen erweitert haben da haben wir auch schon relativ viel äh gesehen nicht sehr tief insgesamt ist dieses ähm obwohl es 1000 Seiten lang ist das ähm Russell & Norbeck Buch ähm ist äh ist nicht sehr tief ja es ist die KI ist sehr sehr groß mittlerweile ähm und äh da gibt's äh Papierfluten mehr als jemand als man überhaupt je lesen kann ähm aber so so das zeigt einem so ein bisschen wo wo was passiert gibt einem die Basic Framework und in jedem einzelnen wenn man dann sagt ja ähm ich interessier mich aber nicht für sequentielle Welten ich will irgendwie in der Entscheidungstheorie was machen dann sollte man mit dem was ich in diesem Semester hab zeigen können schon mal so eine so eine Einnordung haben und ähm äh wissen was so die Methoden im Prinzip sind in allen diesen Sachen ist natürlich nochmal eine ganz dicke Lage von Engineering ja die Ideen die wir hier in dieser Vorlesung gesehen haben sind so dass man sozusagen erste Systeme bauen könnte und dann muss man noch irgendwie 10 Jahre daran arbeiten um den Faktor 100.000 rauszukriegen in der Effizienz so das ganze irgendwie Spaß macht ähm da weiß man mittlerweile sehr sehr viel wie man solche Sachen steuert wie man wie die Datenstrukturen sein müssen was die Algorithmen sind und so weiter die Algorithmen die ich Ihnen da immer auf einer Slide hab zeigen können ja die sind natürlich herzzerreißend naiv ja aber die zeigen in welche in welche Richtung das ganze gehen soll ja und dann haben wir uns hinterher als letztes eben Machine Learning angeguckt das Framework was wir wo wir uns im wesentlichen ähm ähm drauf spezialisiert hatten war Lernen aus positiven und negativen Beispielen ja das das sogenannte überwachte Lernen ja das das wo man sozusagen in jedem Schritt sagt das hast du gut gemacht das hast du schlecht gemacht ähm und ähm ja und die Idee die dabei rauskommt sozusagen mathematisch ist das man sich einen Hypothesenraum gibt in dem irgendwie die Funktion die man lernen will drin ist oder auch nicht und dann versucht man irgendwie die Passgenauigkeit auf die Beispiele zu optimieren ähm und die Probleme die man da irgendwie in den Griff kriegen muss ist ähm sowas wie ähm Expressivität des Hypothesenraums gegenüber der Größe des Hypothesenraums die einfach in vielen Fällen zu groß wird als das man tatsächlich damit rechnet kann das heißt man muss man muss es auch approximieren ähm und dann hat man natürlich sowas wie Under- und Overfitting mit dem man immer klarkommen muss denn Lernen kann man nur auf alten Daten aber was einem wirklich interessiert ist funktioniert es tatsächlich ähm so weiter ja in der Schule erinnern Sie sich sicher gab es immer diese Aufgaben ich sage Ihnen mal ein paar Zahlen 1, 1, 2, 3, 5, 8 19 wie geht es weiter? das ist natürlich eine Quatschaufgabe es könnte irgendwie weitergehen wir haben überhaupt keine wir wissen nicht wie es weitergeht und dann sagt man sich trotzdem das klingt nach Fibonacci-Zahlen wahrscheinlich ist es eine 13 und dann sagt man ja sehr gut warum? weil der Hypothesenraum in meinem des Lehrers Kopf ist dass ich nehme eine der bekannten Reihen davon gibt es irgendwie 27 Stück das sind die Quadratzahlen das sind die ungeraden Zahlen die geraden Zahlen die Fibonacci-Reihe und so weiter und so fort deswegen kommt es sehr darauf an was der Hypothesenraum ist und natürlich nur im Hypothesenraum findet man dann auch Lösungen und in diesem Framework haben wir uns im wesentlichen bewegt und haben dann über Wissen im Lernen wiederum logikbasierte Methoden uns mal angeguckt wir hatten jetzt gerade heute und am Montag uns diese statistischen Lernverfahren angeguckt die im wesentlichen wieder wunderbar in dieses Framework reinpassen was haben wir ausgelassen? schade eigentlich eigentlich müsste man noch eine KI3 haben aber dazu haben Sie ja keine Zeit ist eigentlich schade es gibt nämlich noch schöne Themen gerade im Lernen gibt es noch so etwas das nennt sich Reinforcement Lernen also unüberwachtes Lernen wo man statt positive und negative Beispiele kriegt, kriegt man irgendwie Feedback positive negative Beispiele wenn wir das mal auf so ein Spiel oder so etwas beziehen stellen Sie sich vor, Sie wollen lernen Backgammon zu spielen da kriegt man nicht nach jedem nach jedem Zug gesagt das war aber ein blöder Zug oder das, oioioi das können Menschen auch gar nicht so gut aber es gibt eine Sache die sagt einem, wie man es sozusagen im Durchschnitt gespielt hat wenn man gewonnen hat, hat man gewonnen und das ist aber schwierig zurückzubinden auf einzelne positive oder negative Beispiele aber das ist aber das ist im Prinzip die einzige Möglichkeit in sehr vielen Problemen überhaupt an das Lernen ranzukommen sonst brauche ich ja immer einen Vortänzer der schon weiß wie es geht wenn wir wüssten in jedem Zug ob das gut ist oder schlecht als Mensch dann könnten wir auch selber Backgammon spielen und gewinnen, aber wir wollen ja Systeme bauen, die das besser können als wir und das ist letztlich das was man im Reinforcement Learning macht und da muss man in gewisser Weise ganz viel rückwärts rechnen und und und das ist etwas, da braucht man auch wieder Spezialtechniken für da das Semester diesmal irgendwie da ich da wir hier Montag und Donnerstag Vorlesungen hatten das heißt sehr häufig nicht hatten sind wir dazu nicht gekommen und natürlich das Hype-Thema schlechthin, das Deep Learning was im Wesentlichen wieder neuronale Netzwerke sind die aber irgendwelche verborgene Layers haben und da gibt es eben dann auch wenn man irrsinnig viel Rechenpower hat gibt es dann Möglichkeiten dass diese dass diese Netzwerke dann letztlich Strukturen selber lernen in allem was wir hier gemacht haben war es ja so, dass wir die Strukturen vorgeben mussten Decision-Trees konnte man machen wenn die Menschen irgendwie sagten naja, die relevanten Attribute sind sitzen da schon Leute drin ist es ein Freitag oder Samstag und dann gibt es ja blöde Attribute die man ja auch sagen könnte ist gerade Vollmond oder nicht hat Trump getwittert heute oder nicht solche Sachen das könnte man auch wahrscheinlich haben die nichts damit zu tun ob ich nun warte oder nicht Trump twittern vielleicht aber auch nur wenn er Präsident ist vor 10 Jahren hat das vielleicht noch nichts damit zu tun gehabt also und da ist jetzt wieder jede Menge menschliche Intelligenz drin und diese Deep Neural Networks, die können wir nicht verändern aber wir können tatsächlich Teile dieser diese Attribute können die tatsächlich in diesen Hidden Layers können die sie selber synthetisieren und haben damit recht gute Erfolge gemacht in letzter Zeit und wenn Sie sich jetzt mal unsere Agenten angucken hier dann waren das ja schon ganz schön theoretische Biester ähm und es gibt eine ganze Strömung in der KI die sehr wichtig ist die sagen Intelligenz zu bauen ohne dass die Agenten in der Welt sind und rumlaufen können und auf die Nase fallen können und sich mit anderen Agenten oder Menschen auseinandersetzen können und so etwas wenn die nicht in der Welt sind dann kann man sowieso keine Intelligenz machen die sagen die bauen dann eben Dinge die bauen dann Roboter und statt das die irgendwie über ein Netzwerk virtuell miteinander kommunizieren, haben die tatsächlich im Mund und machen Schallwellen und die anderen müssen dann durch die Sensorik und dann passieren irgendwelche Dinge das ist die sogenannte Embodied AI wo man sagt tatsächlich Intelligenz ohne Körper ist überhaupt nicht denkbar ... und ganz viele Dinge wie zum Beispiel sowas das Spinnen krabbeln können und all solche Sachen da braucht man nicht viel denken da baut man kein Inferenzsystem auf das irgendwie beweist dass wenn ich mein Bein jetzt nach vorne nach vorne bewege dass ich dann mich glücklicher fühle so krabbeln Spinnen nicht und sehr viele Sachen sind sind auch Dinge die man sonst so für nicht so Intelligenzrelevant hält sind aber doch Spielen eine große Rolle wir sind eben nicht nur geistige Wesen sondern unsere Körper spielen auch eine große Rolle jetzt in dem menschlichen Vorbild stark anzunehmen das ist für Hunde und Delfine und Raben und sowas genauso ist und da gibt es dann so diese ganze Embodied AI die sagt ja aber wir müssen um Intelligenz überhaupt verstehen zu können müssen wir müssen die Biester Körper haben die müssen kommunizieren können die müssen tatsächlich nicht nur als als Metapher sondern die müssen echte Agenten sein und die müssen echt rumlaufen können und bei denen muss auch mal ein Bein abfallen ja und das was lernen sie denn dann oder die Batterie tatsächlich ausfallen was lernen sie denn dann das haben wir gar nicht gemacht also da ist eben Robotik ist sehr wichtig tatsächliche Sinnesorgane ja das so der große der Megatrend ist da diese ist Robocop wo die anfingen damit dass gerade 20 Jahre her stimmt gar nicht 21 aber dass dieser Robocop angefangen hat wo tatsächlich dann Roboter gegeneinander Fußball spielten mittlerweile gibt es da sehr viele verschiedene Ligen da gibt es Robocop Rescue wo irgendwie Roboter in eingestürzte Häuser fahren und Menschen versuchen zu bergen und aber nicht wissen wie es da drin aussieht die haben keine Landkarte vorher die müssen die Landkarte machen indem sie gucken und da sehr viel mit schwierigen Daten zurechtkommen da gibt es die Haushaltsroboter wo ähnliche Probleme sind da weißt du zwar wie die Zimmer aussehen aber du weißt nicht wie es deinen Mitbewohnern geht das musst du selber rauskriegen als Roboter solche Dinge da braucht man dann eben auch wiederum Spezialtechniken die dann aber auch sehr viel in so sagen wir mal Elektrotechnik oder so etwas gehen wenn man einen Roboter bauen will dann muss man mit Motoren rumfummeln und Strippen ziehen solche Sachen das haben wir hier noch gar nicht gemacht Sprache sehr wichtige sehr wichtige Funktion der der künstlichen Intelligenz oder der menschlichen Intelligenz man hat ja lange Zeit geklärt dass man glaubt dass Menschen die einzig sprachbegabten Agenten sind das stimmt nicht wir wissen dass Wale symbolisch kommunizieren können wir wissen dass Imprinaten symbolisch sprachlich kommunizieren können es ist sogar so dass Menschenaffen denen man irgendwelche Spezialsprachen im wesentlichen Zeichensprachen dass die die ihren Nachkommen beibringen und auch untereinander benutzen und wildfremde Menschen anquatschen die merken das zwar nicht weil die dann Zeichen machen gib mir bitte ein Eis oder so etwas aber Sprache gibt es im Tierreich eingeschränkt Shakespeare bei Delfinen ist noch nicht bekannt geworden aber wie funktioniert das überhaupt wichtiger Teil der künstlichen Intelligenz solche Sachen alle diese Sachen würden in einer KI3 drankommen aber dazu haben wir hier nicht die Ressourcen vor allen Dingen sie nicht es gibt einige Spezialvorlesungen es gibt den Stefan Ewert in der Computerlinguistik der macht im wesentlichen statistische Methoden zur Sprachverarbeitung also so machine learning basierter modernes Zeugs und ich biete im nächsten Semester eine kleine Vorlesung an zur logikbasierten Bedeutung natürlicher Sprache und da geht es darum also ich will jetzt sozusagen unmittelbar in die Werbung fürs nächste Semester eintreten und ich glaube nicht dass ich hinten mit KI1 kommen kann da gibt es eine Vorlesung wo es darum geht Sprache was bedeutet das überhaupt und die Idee ist dass man sprachlich solche Äußerungen so was wie Peter liebt seine Frau übersetzt in überführt in Formate wo man Inferenz machen kann wo man Sachen nachprüfen kann beschreibt das überhaupt was ich sagen wollte und da gibt es ein paar Phänomene wo man tatsächlich mehr braucht als statistische Methoden Statistische Methoden sind wunderbar wenn man rauskriegen will sind zwei Sätze ähnlich was Suchmaschinen Zeugs ich gebe ein Peter liebt seine Frau und dann kriege ich in Google irgendetwas wieder was irgendwie da mit was zu tun hat wobei aber die Trennschärfe die man hat unter Umständen nicht das ist was man will zum Beispiel so was wie Peter liebt seine Frau nicht gibt praktisch dieselbe Begründung wie Peter liebt seine Frau nicht gibt praktisch dieselben Resultate wie Peter liebt seine Frau obwohl das für seine Frau sehr unterschiedlich sehr unterschiedliche Welten sein könnten es geht um mit den statistischen Methoden kriegt man Ähnlichkeiten raus und solche Sachen während man mit Logik basierten Verfahren sehr viel klarere Dinge hat wenn man sie denn kriegt Logik basiert geht normalerweise gut wenn man extrem kleine Welten hat über die man sehr viel weiß dann gehen diese Dinge gut Statistische Verfahren geben einem immer irgendetwas manchmal weiß man nicht so genau was aber es ist total breit anwendbar und je nach Anwendung wird man mit dem einen oder dem anderen glücklich Sachen die wir uns angucken wollen sind sowas von der Bauart sehr häufig sowas wie Ambiguitäten es gibt immer in der Sprache mehrere Lesarten häufig erstaunlich viele Lesarten und dann fragt man sich welche der Lesarten sind denn okay wenn Sie sich sowas angucken wie Peter liebt seine Frau kann man sich vorstellen was das heißt und dann hört man einen elliptischen Satz wie Klaus auch das ist erstmal das Problem was bedeutet das was ist denn die Bedeutung von auch in diesem Fall liebt seine Frau das heißt auch ist irgendwie etwas was sagt ja kopier doch mal das relevante Zeugs vom vorherigen Satz runter wie fasst man sowas und wie Sie sehen wenn Sie sich das mal auf die Seite des Kultusminister und sagen wie Sie es sicherlich gesehen haben hier gibt es zwei Bedeutungen einmal die schlampige Bedeutung die sloppy nämlich in dem Klaus Peters Frau liebt und eine andere wo Klaus seine eigene hat und jetzt wie baut man Sachen dass das dass man hier genau die richtigen Bedeutungen kriegt oder solche Dinge wie jedermann liebt eine Frau es gibt zwei zwei Bedeutungen sehen Sie die jedermann es gibt einmal die die Bedeutung dass es für jeden Mann eine Frau gibt die er liebt zum Beispiel seine Mutter oder aber es gibt eine Frau die von allen Männern geliebt wird ja wenn die Welt katholisch wäre könnte man sagen die Jungfrau Maria aber das ist sie ja nicht also es ist etwas schwieriger aber dann hat systematisch bei diesem Satz hat man zwei Bedeutungen identische Satz jedes Auto hat ein Radio hat nur eine Bedeutung ja die Jungfrau Maria hat eine Bedeutung die gibt es nicht warum nicht weil das Radio ein physisches Teil des Autos ist und das kann deswegen nur in einem sein was vielleicht ein bisschen debattierbar ist heutzutage wenn man Softwareradios hat oder sowas naja aber dann muss sich halt das Beispiel ändern oder solche Sachen wie Peter jagt den Gangster im roten Sportwagen wie viel Bedeutung hat das ok welche? Peter jagt den Gangster im roten Sportwagen ich behaupte es gibt noch eine dritte haben Sie die? das ist ein sehr großer Sportwagen und die jagen sich auf dem Rücksitz rum ne Sie sehen schon die Bedeutung interagiert sehr stark und es gibt noch viele Beispiele sowas wie Peter hat einen Sportwagen und er hat einen Sportwagen und er hat einen Sportwagen und Peter mag seinen Hund wie heißt er? Spiff obwohl er ihn manchmal beißt was passiert da? Palast oder als letzte Frage kannst du sicher beantworten wie viele Tiere jeder Art hat Moses mit auf seines Arche genommen wie viele Tiere jeder Art Z collaborations Nämlich Jede Art между오여�hickezähler?retしょ 값 toddardakemyer? ö против centers ca counter affiliate packages and your self? Deskalleinhalt Z 68 till d'accumpliert j doorzer have not beta don't stop at all Je readers are Two? Das gleiche wieền Definitely Der Z неels des allers ist 마음sock um surt포ci technologie lose ins esqueren fand sie in der düsterle better Art Verstöre сначала was wir in diesem hochweg im Umweltschutz am заabl frames und少icht, dass Burger aber sowas sowas macheniva ist. Police-向 setup. Das ist Null. Null? Warum? Weil der Nullgegenstand wie jeweils jeder Nee, das könnte man auch meinen, ja.)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | results
 Nein, ich bin mir ziemlich sicher, dass es das nicht gäbe. Das würden Sie in den Nachrichten größer sehen. Aber das ist das, was Sie eigentlich immer in der Science Fiction sehen, die starke KI. Deswegen ist auch das vielleicht das, was immer so präsent ist. Also ich bin auch groß geworden mit Knight Rider und ich fand die Idee total toll. Entsprechendes Auto, kann alles möglich machen, hat eine Persönlichkeit. Das hat mich als Kind sehr geprägt. Da habe ich schon mein Interesse an KI entwickelt. Sie kennen es dann vielleicht als nächstes auch. Woran man oft denkt, wenn man an KI denkt, ist Terminator oder in dem Fall Terminator 2. Die Maschinen werden intelligent und unterjochen oder löschen die Menschheit aus. Es ist oft die Angst, wo man sagt, sollten wir wirklich so weit forschen? Was ist, wenn uns die KI irgendwann überflügelt und uns loswerden will? Ist ja sehr, sehr, sehr häufig das Thema in Filmen, also Science Fiction. Aber auch schon viel früher, in einem Film von 1968. Also Sie kennen den Film vermutlich 2001 und ich sehe im Weltraum. Ich will jetzt nicht spoilern, falls Sie den Film schon gesehen haben, aber es geht auch um KI. Ja, genau. Leben in einer Matrix. Auch sehr philosophisch, hat aber erstmal nichts mit KI zu tun. Genau, also Sie sehen, es ist in Science Fiction, es ist sehr weit präsent und wenn es Ihnen so ein bisschen geht wie mir, dann sind Sie dadurch schon beeinflusst. Boston Dynamics, für die, die es nicht kennen, die stellen diese Roboter her und das ist schon, ich sage gerne mal creepy, was die können. Vielleicht als kurzen Datenpunkt dazu. 2009 habe ich an einem, noch als, noch vor meiner Promotion habe ich noch an einem, ja, Kollege hieß das, teilgenommen. Es kann auch für sich vielleicht interessant werden, ich muss mal einen Flyer raussuchen. Das interdisziplinäre Kollege, der geht zu Kognitionswissenschaften, wo auch, wo sehr viel um KI geht oder um alles, was man mit kognitiven Fähigkeiten verbinden kann. Und da waren noch Kollegen oder Kompetenten von der Uni Kaiserlautern da und damals war das zweibeinige Laufen noch nicht gelöst. Es gab damals noch keine zweibeinig laufenden Roboter. Es ging einfach nicht. Also hat man nicht hinbekommen. Und wenn Sie jetzt sehen, was diese Boston Dynamics Roboter können, das ist schon mehr als nur zweibeiniges Laufen. Also es hat in den letzten zehn Jahren wahnsinnige Fortschritte gemacht. Und zu den Fortschritten kommen wir jetzt gleich mal, nämlich einen Überblick. Ich versuche, diesen Überblick hier in dieser Vorlesungsstunde durchzukriegen, damit wir nächste Woche einsteigen können, inhaltlich. Deswegen tut es mir leid, wenn ich nicht auf alles so genau eingehe. Sie können gerne Fragen stellen, wenn es Sie mehr interessiert. Aber das ist auch schon eine sehr, sehr kondensierte Zusammenfassung. Also einmal, das haben die aus GML schon gesehen, also Grundlagen des Maschinenlernens heißt die Vorlesung GML, dass KI selbst ein großes Gebiet ist, was viele Teilgebiete umfasst. Sie haben die ganzen Stichworte vorhin schon gesehen. Sie wollen Wissen repräsentieren. Also Wissensrepräsentation ist ein eigenes Gebiet. Automatisches Schließen ist ein Gebiet. Planen, Problemlösen. Das Maschinenlernen ist ein sehr großes, sehr sichtbares Gebiet. Computervision, jetzt wegen autonomem Fahren in aller Munde. Und natürlich auch für Sprachassistenten die Verarbeitung Sprache oder Automatische Besetzen. Hier nochmal, wie in der anderen Vorlesung, die Disclaimer. Für die meisten Begriffe gibt es englische Fachworte. Die deutschen klingen entweder komisch oder beschreiben das nicht ganz genau, was eigentlich gemeint ist. Deswegen, ich versuche konsistent zu bleiben in Deutsch-Englisch. Aber bitte verzeihen Sie mir, wenn ich dann oft so deutsch-englische Mischtexte habe, einfach weil der englische Begriff auch prägnanter ist und das Thema besser erfasst und Sie unter dem Begriff auch meistens die Literatur finden. KI hat natürlich Überlappungen mit anderen Fächern, mit Big Data, Data Science, Data Mining. Also ich bin auch überrascht, wie viele andere Vorlesungen hier schon Data Mining machen, was sich dann sehr stark mit Machine Learning überdeckt. Nicht ganz das Gleiche ist, aber große Beschneidung hat. Robotik natürlich, wo Sie jetzt natürlich Intelligenz verhalten wollen, wenn Sie autonomes Fahren oder autonome Roboter denken. Ja, sehen Sie jetzt gerade, es ist nicht Curiosity, Perseverance auf dem Mars gelandet und das Ding muss ja teilweise autonom agieren können. Deswegen haben Sie da auch immer KI. Und Sie haben auch die andere Richtung, die Kognitionswissenschaften. Gibt auch teilweise das eigene Studiengang. Das ist eine Mischung aus allem, was halt mit Denken, mit Kognition zu tun hat. Linguistik, Neurowissenschaften, KI, Psychologie. Also da geht es um die Frage, wenn wir hier Denken erforschen, auf eine sehr mathematische Art und Weise, können wir davon Rückschlüsse ziehen, die wiederum in die Psychologie, Pädagogik zurückgehen und natürlich vieles mehr. Also es gibt wahrscheinlich mittlerweile kaum ein Fach, wo es keine Überlappungen gibt. Und jetzt kommt die kurze Geschichte der KI. Einfach, damit Sie mal sehen, wie sich die KI entwickelt hat. Was ich sehr spannend finde, weil es demnach herkommt. Viele Dinge wusste ich halt natürlich auch. Habe ich auch erst in der Uni gelernt. Und es ist sehr interessant, dass man auch mal sieht, was alles schon sehr früh ging und was noch nicht so lange geht. Sie haben schon 1912 den ersten Schachcomputer. Und der wurde entwickelt von Leonardo Torres y Quevedo. Und das ist ein elektromechanischer Roboter. Also es gab damals noch keine Computer in diesem Sinne, wie heute. Der kann das sogenannte K.R.K. Endspiel spielen. Also K.R.K. spielt für König Rook. Rook ist der Turm. Und der gewinnt in maximal 50 Zügen. Und das war für die damalige Zeit schon krass. Stellen Sie sich vor, das ist vor über 100 Jahren, würden Sie mal sagen, ich habe eine Maschine, die kann Schach spielen. Oder einen sehr kleinen Teil von Schach. Dann passierte, sagen wir mal, lange nichts. Was auch vielleicht an diversen Weltkriegen liegen könnte. Aber wie es immer so ist, Kriege haben die Forschung immer beflügelt, weil viel Geld reingeflossen ist. Und 1943 hat jetzt keinen Bezug zum Weltkrieg gehabt. Aber da haben die Warren McCulloch und Walter Pitts das künstliche Neuron, das Konzept entwickelt. Und das kombiniert verschiedene Erkenntnisse. Also Sie müssen sich vorstellen, auch damals, auch über das Gehirn war noch nicht so viel bekannt. Und das hat verschiedene Erkenntnisse kombiniert. Nämlich einmal, dass man das Gehirn als Netzwerk von Neuronen betrachten kann, zur Informationsverarbeitung. Und dass man Aussagenlogik, die es ja schon viel länger gibt als Computer, mit Binärwerten in Digitalrechnern abbilden kann. Und außerdem hat Alan Turing auch wieder mit seiner Turing-Maschine ein hypothetisches Berechnungsmodell entwickelt und gezeigt, dass alle erdenklichen mathematischen Berechnungen durch die Turing-Maschine durchgeführt werden können. Sie kennen vielleicht den Begriff Turing-Mächtig. Wenn nicht, werden Sie den wahrscheinlich noch im Studium hören. Aus diesen drei Erkenntnissen haben die kombiniert, dass jede erdenkliche berechenbare Funktion durch ein Netzwerk künstlicher Neuronen berechnet werden kann. Und außerdem schlugen die beiden vor, dass man solches Netzwerk auch durch Anwendungen geeigneter Regeln trainieren kann und dass es lernen kann. Das war damals schon, also das war der Vorschlag. Und sechs Jahre später hat dann Donald Hebb eine einfache Lernregel gezeigt. Ich hätte es genannt Hebb'sche Lernregel, die einfach sagt, wenn zwei Neuronen, also Neuronen sind Zellen, die verbunden sind, das ist die einfache Fassung, wenn zwei verbundene Neuronen gleichzeitig aktiv sind, dann wird die Verbindung zwischen beiden gestärkt. Das ist die Hebb'sche Lernregel. Und damit kann man schon ein paar tolle Dinge zeigen. Wie vorhin schon gesagt, 1950 hat dann Alan Turing den Turing-Test vorgeschlagen. Der hat jetzt ja kein neues Felder KI geöffnet oder hat eine neue Lösung präsentiert. Aber er hat eine sehr schöne Messlatte gesetzt, die bis heute nicht erreicht wurde, wie man eventuell Intelligenz abtesten kann. Und 1951 haben Marvin Winsky und Dean Edmonds SNARK gebaut. Das ist der Stochastic Neural Analog Reinforcement Calculator. Das war der erste Neural Network Computer. Der bestand noch aus Röhren. Und der simuliert ein Netzwerk aus 40 Neuronen. Wahnsinn. Also für die damalige Zeit war das ein Novum natürlich. Heute wird man müde über Lachen. Und 1955 haben Alan Newell und Herbert A. Simon den Logic Theorist programmiert. Der konnte zum Beispiel, also das war natürlich sehr rein logisch, hatte jetzt nichts mit Neuronen zu tun. Aber der konnte schon 38 von 52 Theoremen aus einem Buch namens Prinzipia Mathematica beweisen, was für die damalige Zeit auch schon sehr beeindruckend war. Er hat wohl sogar für einige Theoremen einen eleganteren oder kürzeren Beweis gefunden. 1956 wird im Allgemeinen oder von vielen als das Jahr als die Geburt der KI betrachtet. Dann hat John McCarthy die Datenaufkonferenz in Hanover, New Hampshire, also nicht das deutsche Hannover, initiiert und hat da Leute eingeladen, denen er noch viel zugetraut hat im Bereich KI, oder die Namen hatten. Unter anderem Marvin Minsky, Claude Shannon, Alan Newell, Herbert A. Simon. Viele von den Namen haben es bestimmt schon mal gehört, oder Sie werden sie noch öfter hören. Und es standen folgende wichtige Aussagen als Ergebnis dieser Konferenz. Nämlich, dass sämtliche Eigenschaften der Intelligenz in Form abstrakter Modelle präzise beschreiben lassen. Das ist ja erst mal eine umstrittene These. Also keine klare These, und sie könnte umstritten sein. Also auch heute, wenn es auch Leute gibt, die sagen, Intelligenz kann man nicht nur durch reine Mathematik abbilden. Vielleicht auch einige von Ihnen. Es ist eine offene Frage. Ich bin der Meinung, man kann, aber das war damals schon ein revolutionärer Gedanke. Und auch die Idee, dass Denkprozesse nicht ausschließlich dem menschlichen Gehirn vorbehalten sind. Und dass Computer das beste bekannte außer-menschliches Instrument für diese Denkprozesse sind. Und die Konferenz selbst hat jetzt keine Durchbrüche in der Forschung als Ergebnis gehabt, aber die Leute kannten sich jetzt halt erst mal, konnten zusammen forschen. Also die Big Players damals und haben für viele Jahre das Gebiet der KI dominiert. 1952 bis 1969 wird im Allgemeinen als die Ära des Aufbruchs und Begeisterung bezeichnet. Computer waren neu und man dachte, die können gut rechnen und das war es. Sie kennen vielleicht noch diesen einen Spruch. Ich glaube, das war der Chef von IBM, der gesagt hat, er glaubt nicht, dass mehr als fünf Computer weltweit notwendig sind. Und das war natürlich eine ganz andere Vorstellung von Computern damals als heute. Mein Herd kann ich auf Werkseinstellung zurücksetzen. Also der hat wahrscheinlich mehr Intelligenz als viele Computer aus den 50ern oder 60ern. Und eine häufige Erwartung war damals auf jeden Fall noch, eine Maschine wird niemals X können. Ja, also kann nicht. Maschine wird niemals Schach spielen können. Maschine wird niemals was übersetzen können. Maschine wird niemals Bilder erkennen, autonom fahren, was auch immer. Es gab immer jemanden, der gesagt hat, also das werden Computer nicht können. Mit dem Ergebnis, dass meistens KI-Forscher dann danach eine Maschine gebaut haben, die genau das konnten. Und das wird gerne als die Look-Ma-No-Hands, also guck mal Mama ohne Hände, wäre beschrieben. Weil einfach immer wieder Dinge, wo man sagte, das ist unheimlich schwierig, das geht nicht, gezeigt wurde, ja, hier, wir haben es mal gelöst. Unter anderem, also Sie müssen das nicht alles auswendig kennen, aber Schrödeleau von Terry Reinograd. Die Sprache Lisp, also Lisp Processing von John McCarthy. Das Perzeptron, das werden wir uns vielleicht noch ein paar Mal begegnen von Frank Rosenblatt. Eliza, das sagt Ihnen vielleicht was von Joseph Walzenbaum. Also Eliza war ein, kommt das noch? Nein. Eliza war ein Dialogsystem, also wir konnten damit chatten und es hat Antworten geliefert. Allerdings, es konnte, glaube ich, nur 50 bis 100 verschiedene Antworten und trotzdem hätte man im ersten Moment meinen können, man redet mit einem Menschen, weil es auf sehr, sehr einfachen Regeln basiert hat. Aber heutzutage könnte damit niemand mehr hier das Licht füllen können. Und der General Problem Solver von Alan Newell und Herbert A. Simon, also der sollte wirklich allgemeine Probleme lösen, jedes Problem lösen können. Und naja, danach kam die Ernüchterung. Also die Erwartungen waren halt sehr, sehr groß. Mit so Aussagen wie von 1958, in zehn Jahren werden Digitalcomputer den Weltmeister in den Schach schlagen und in zehn Jahren werden Computer neue mathematische Beweise entdecken und beweisen. Das war 1958, also 1968 wollte man das eigentlich schon geschafft haben. Wir sind jetzt so weit, aber das ist also eher 50 Jahre später als zehn Jahre später. Und Maschinen werden in der Lage sein, innerhalb von 20 Jahren, da war man schon etwas vorsichtiger, jede Arbeit zu machen, die ein Mensch tun kann. Innerhalb einer Generation, also Sie merken schon, man wird immer ein bisschen vorsichtiger, werden wir das Problem oder die Herausforderung, eine KI zu erschaffen, im Prinzip gelöst haben, hat Marvin Minsky gesagt, 1967. Und 1970 noch, also in drei bis acht Jahren, haben wir eine Maschine mit einer generellen Intelligenz ungefähr wie der Durchschnittsmensch, auch von Marvin Minsky. Ja, ich glaube, Spoiler Alert, es hat nicht funktioniert. Aber dieser Running Gag, dass es immer zehn Jahre weit entfernt ist, der hat der KI lange nach, hing ihr lange nach. Und noch ein schönes Beispiel ist die Übersetzung. Man dachte halt damals, also das Übersetzen durch Reihen ist eine taktische Umstellung und die Übersetzung einzelner Wörter ihr Ziel erreichen können. Ich weiß nicht, wenn Sie mal eine andere Sprache gelernt haben oder lernen, also ich nutze teilweise Duolingo einfach, um ein bisschen meine Sprachen oder mein Vokabular zu halten. Und wenn Sie da in die Foren schauen, haben Sie ganz viele Menschen, die wirklich sagen, aber das Wort heißt doch das, warum kann ich es nicht so übersetzen? Ja, die schlagen dann einfach ein Wort nach und sind der Meinung, ja, okay, dann muss ich doch Wörter übersetzen können. Und Sprache ist eben nicht so einfach. Und da gibt es dieses schöne Beispiel, der Satz, the spirit is willing, but the flesh is weak, wurde von dem Programm ins Russische übersetzt und vom Russischen wieder zurück übersetzt. Und das Ergebnis war, the vodka is good, but the meat is rotten. Also, das habe ich oft gelesen. Ich hoffe einfach mal, dass es keine Urban Legend ist, aber das liegt es hier an, dass natürlich die Worte keine eindeutige Bedeutung haben. Also der Geist, Sie kennen, wenn Sie hier von Himbeergeist reden, dann ist es ein Schnaps. Ja, aber der Geist kann genauso gut, der ist Spukgespenst sein oder der Geist, den Sie im Kopf haben, also Bachergeist, der Zeitgeist, also dasselbe Wort hat viele verschiedene Bedeutungen. Und welche hier genau gemeint ist, hängt im Kontext ab. Und das ist viel, viel schwieriger, als man damals dachte. Und Kontext und Hintergrundwissen waren viel wichtiger als gedacht. Und da wurde dann auch die Finanzierung eingestellt 1966, da man einfach keine Erfolge mehr vorzuweisen hatte oder zu erwarten war. 1969 hat dann lustigerweise genau Marvin Minsky einen Sargnagel damals in den neuronalen Netze reingehauen. Der hat nämlich bewiesen, dass das Perzeptron die XOR-Funktion, also exklusives oder, nicht abbilden kann. Vorher hat man doch gemeint, man kann ja alles lernen damit. Und das führt zu rapide Schwindelinteresse an neuronalen Netzen. Er hatte recht, er hat es bewiesen. Aber das Perzeptron, müssen Sie sich vorstellen, das ist ein neuronales Netz, was aus einem Neuron besteht, einem einzigen. Und das XOR sehr wohllösbar ist mit zwei Schichten, ich glaube es reichen, ich glaube drei Neurone reichen aus, ansonsten sind es fünf. Das ist also lösbar, aber es hat damals dazu geführt, dass man dachte, oh neuronaler Netz könnte doch gar nicht so viel und das Interesse ist stark gesunken. Was ansonsten in der Zeit dann stattdessen hoch kam, waren die wissensbasierten Systeme oder auch Expertensysteme genannt. Gibt es auch heute noch. Also man hat einfach jetzt gesagt, also wir haben ja Experten und die haben Wissen und wir müssen dieses Wissen extrahieren und daraus Regeln ableiten, also Heuristiken. Und deswegen gab es damit auch sehr verstärkte Forschung an Wissensrepräsentationen. Also wenn Sie jetzt, was nehmen wir denn mal, sagen wir mal, Sie haben jetzt jemanden in der Versicherungswirtschaft oder Automobilbau, da kenne ich mich ein bisschen mit aus. Sie haben jemanden in Automobilbau und jetzt haben Sie einen Experten und der hat schon 30 Jahre Erfahrung und der sagt dann, nee, also hier brauchen Sie gar nicht mit Aluminium zu kommen, das ist viel zu, keine Ahnung, das geht nicht, da brauchen Sie schon Stahl. Oder nee, hier dürfen Sie gar keinen Kunststoff nehmen, das schwilzt. Und dann fragen Sie ja, was heißt denn hier und dann sagt, naja, wenn die Temperatur über so und so Grad ist, dann brauchen Sie dieses Material. Und solche Regeln kommen dann da langsam, kommen da vielleicht raus. Die hat man gesammelt und das müssen Sie ja irgendwie repräsentieren. Also der Satz, wir haben eben schon gemerkt, Sätze zu analysieren ist nicht so einfach wegen Kontext, deswegen mussten wir das formalisieren. Das heißt, es war sehr verstärkte Forschung daran, wie man Wissen wirklich auch für Computer verarbeitbar darstellt. Und da gab es auch Systeme wie Dendril oder Mycin. Mycin war ein Expertensystem, lassen Sie mich nicht lügen, der Name sagt ja schon, dass es da um Pilze geht und also in der Medizin wurden die teilweise eingesetzt. Mycin war ein Expertensystem von 1972 zur Erkennung, genau, zu Infektionskrankheiten also nicht nur Pilze. Und Sie müssen sich vorstellen, da geben Sie ein paar Ergebnisse von Analysen rein und dann sagt der, oh, es könnte das sein, testen Sie mal das. Und so hat man sich nach und nach dann zur Krankheit vorgearbeitet. Und das war recht erfolgreich. Außerdem hatten Sie dann noch Prolog, eine logische Programmiersprache, haben Sie vielleicht auch schon mal gehört. Also logische Programmiersprachen waren damals sehr in und wir werden ein paar davon auch eventuell alles mal anschauen. Also einfach, dass Sie es mal gesehen haben, auch wenn das heute keine Relevanz mehr hat. Aber Sie kennen vielleicht, es kommt irgendwie mal vor, dass Sie irgendwo so News lesen, dass man irgendwelche alten Informatiker aus der Pension oder aus dem Ruhestand holt, weil sie die einzelnen Programmiersprachen noch können und die Systeme verwalten können, weil es heute einfach nicht mehr beigebracht wird. Das war alles, also wir waren ja vorhin bei 1969 bis 1974, also das sind alles ungefähre Zeitangaben.)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | results
 und ganz viele Dinge wie zum Beispiel sowas das Spinnen krabbeln können und all solche Sachen da braucht man nicht viel denken da baut man kein Inferenzsystem auf das irgendwie beweist dass wenn ich mein Bein jetzt nach vorne nach vorne bewege dass ich dann mich glücklicher fühle so krabbeln Spinnen nicht und sehr viele Sachen sind sind auch Dinge die man sonst so für nicht so Intelligenzrelevant hält sind aber doch Spielen eine große Rolle wir sind eben nicht nur geistige Wesen sondern unsere Körper spielen auch eine große Rolle jetzt in dem menschlichen Vorbild stark anzunehmen das ist für Hunde und Delfine und Raben und sowas genauso ist und da gibt es dann so diese ganze Embodied AI die sagt ja aber wir müssen um Intelligenz überhaupt verstehen zu können müssen wir müssen die Biester Körper haben die müssen kommunizieren können die müssen tatsächlich nicht nur als als Metapher sondern die müssen echte Agenten sein und die müssen echt rumlaufen können und bei denen muss auch mal ein Bein abfallen ja und das was lernen sie denn dann oder die Batterie tatsächlich ausfallen was lernen sie denn dann das haben wir gar nicht gemacht also da ist eben Robotik ist sehr wichtig tatsächliche Sinnesorgane ja das so der große der Megatrend ist da diese ist Robocop wo die anfingen damit dass gerade 20 Jahre her stimmt gar nicht 21 aber dass dieser Robocop angefangen hat wo tatsächlich dann Roboter gegeneinander Fußball spielten mittlerweile gibt es da sehr viele verschiedene Ligen da gibt es Robocop Rescue wo irgendwie Roboter in eingestürzte Häuser fahren und Menschen versuchen zu bergen und aber nicht wissen wie es da drin aussieht die haben keine Landkarte vorher die müssen die Landkarte machen indem sie gucken und da sehr viel mit schwierigen Daten zurechtkommen da gibt es die Haushaltsroboter wo ähnliche Probleme sind da weißt du zwar wie die Zimmer aussehen aber du weißt nicht wie es deinen Mitbewohnern geht das musst du selber rauskriegen als Roboter solche Dinge da braucht man dann eben auch wiederum Spezialtechniken die dann aber auch sehr viel in so sagen wir mal Elektrotechnik oder so etwas gehen wenn man einen Roboter bauen will dann muss man mit Motoren rumfummeln und Strippen ziehen solche Sachen das haben wir hier noch gar nicht gemacht Sprache sehr wichtige sehr wichtige Funktion der der künstlichen Intelligenz oder der menschlichen Intelligenz man hat ja lange Zeit geklärt dass man glaubt dass Menschen die einzig sprachbegabten Agenten sind das stimmt nicht wir wissen dass Wale symbolisch kommunizieren können wir wissen dass Imprinaten symbolisch sprachlich kommunizieren können es ist sogar so dass Menschenaffen denen man irgendwelche Spezialsprachen im wesentlichen Zeichensprachen dass die die ihren Nachkommen beibringen und auch untereinander benutzen und wildfremde Menschen anquatschen die merken das zwar nicht weil die dann Zeichen machen gib mir bitte ein Eis oder so etwas aber Sprache gibt es im Tierreich eingeschränkt Shakespeare bei Delfinen ist noch nicht bekannt geworden aber wie funktioniert das überhaupt wichtiger Teil der künstlichen Intelligenz solche Sachen alle diese Sachen würden in einer KI3 drankommen aber dazu haben wir hier nicht die Ressourcen vor allen Dingen sie nicht es gibt einige Spezialvorlesungen es gibt den Stefan Ewert in der Computerlinguistik der macht im wesentlichen statistische Methoden zur Sprachverarbeitung also so machine learning basierter modernes Zeugs und ich biete im nächsten Semester eine kleine Vorlesung an zur logikbasierten Bedeutung natürlicher Sprache und da geht es darum also ich will jetzt sozusagen unmittelbar in die Werbung fürs nächste Semester eintreten und ich glaube nicht dass ich hinten mit KI1 kommen kann da gibt es eine Vorlesung wo es darum geht Sprache was bedeutet das überhaupt und die Idee ist dass man sprachlich solche Äußerungen so was wie Peter liebt seine Frau übersetzt in überführt in Formate wo man Inferenz machen kann wo man Sachen nachprüfen kann beschreibt das überhaupt was ich sagen wollte und da gibt es ein paar Phänomene wo man tatsächlich mehr braucht als statistische Methoden Statistische Methoden sind wunderbar wenn man rauskriegen will sind zwei Sätze ähnlich was Suchmaschinen Zeugs ich gebe ein Peter liebt seine Frau und dann kriege ich in Google irgendetwas wieder was irgendwie da mit was zu tun hat wobei aber die Trennschärfe die man hat unter Umständen nicht das ist was man will zum Beispiel so was wie Peter liebt seine Frau nicht gibt praktisch dieselbe Begründung wie Peter liebt seine Frau nicht gibt praktisch dieselben Resultate wie Peter liebt seine Frau obwohl das für seine Frau sehr unterschiedlich sehr unterschiedliche Welten sein könnten es geht um mit den statistischen Methoden kriegt man Ähnlichkeiten raus und solche Sachen während man mit Logik basierten Verfahren sehr viel klarere Dinge hat wenn man sie denn kriegt Logik basiert geht normalerweise gut wenn man extrem kleine Welten hat über die man sehr viel weiß dann gehen diese Dinge gut Statistische Verfahren geben einem immer irgendetwas manchmal weiß man nicht so genau was aber es ist total breit anwendbar und je nach Anwendung wird man mit dem einen oder dem anderen glücklich Sachen die wir uns angucken wollen sind sowas von der Bauart sehr häufig sowas wie Ambiguitäten es gibt immer in der Sprache mehrere Lesarten häufig erstaunlich viele Lesarten und dann fragt man sich welche der Lesarten sind denn okay wenn Sie sich sowas angucken wie Peter liebt seine Frau kann man sich vorstellen was das heißt und dann hört man einen elliptischen Satz wie Klaus auch das ist erstmal das Problem was bedeutet das was ist denn die Bedeutung von auch in diesem Fall liebt seine Frau das heißt auch ist irgendwie etwas was sagt ja kopier doch mal das relevante Zeugs vom vorherigen Satz runter wie fasst man sowas und wie Sie sehen wenn Sie sich das mal auf die Seite des Kultusminister und sagen wie Sie es sicherlich gesehen haben hier gibt es zwei Bedeutungen einmal die schlampige Bedeutung die sloppy nämlich in dem Klaus Peters Frau liebt und eine andere wo Klaus seine eigene hat und jetzt wie baut man Sachen dass das dass man hier genau die richtigen Bedeutungen kriegt oder solche Dinge wie jedermann liebt eine Frau es gibt zwei zwei Bedeutungen sehen Sie die jedermann es gibt einmal die die Bedeutung dass es für jeden Mann eine Frau gibt die er liebt zum Beispiel seine Mutter oder aber es gibt eine Frau die von allen Männern geliebt wird ja wenn die Welt katholisch wäre könnte man sagen die Jungfrau Maria aber das ist sie ja nicht also es ist etwas schwieriger aber dann hat systematisch bei diesem Satz hat man zwei Bedeutungen identische Satz jedes Auto hat ein Radio hat nur eine Bedeutung ja die Jungfrau Maria hat eine Bedeutung die gibt es nicht warum nicht weil das Radio ein physisches Teil des Autos ist und das kann deswegen nur in einem sein was vielleicht ein bisschen debattierbar ist heutzutage wenn man Softwareradios hat oder sowas naja aber dann muss sich halt das Beispiel ändern oder solche Sachen wie Peter jagt den Gangster im roten Sportwagen wie viel Bedeutung hat das ok welche? Peter jagt den Gangster im roten Sportwagen ich behaupte es gibt noch eine dritte haben Sie die? das ist ein sehr großer Sportwagen und die jagen sich auf dem Rücksitz rum ne Sie sehen schon die Bedeutung interagiert sehr stark und es gibt noch viele Beispiele sowas wie Peter hat einen Sportwagen und er hat einen Sportwagen und er hat einen Sportwagen und Peter mag seinen Hund wie heißt er? Spiff obwohl er ihn manchmal beißt was passiert da? Palast oder als letzte Frage kannst du sicher beantworten wie viele Tiere jeder Art hat Moses mit auf seines Arche genommen wie viele Tiere jeder Art Z collaborations Nämlich Jede Art между오여�hickezähler?retしょ 값 toddardakemyer? ö против centers ca counter affiliate packages and your self? Deskalleinhalt Z 68 till d'accumpliert j doorzer have not beta don't stop at all Je readers are Two? Das gleiche wieền Definitely Der Z неels des allers ist 마음sock um surt포ci technologie lose ins esqueren fand sie in der düsterle better Art Verstöre сначала was wir in diesem hochweg im Umweltschutz am заabl frames und少icht, dass Burger aber sowas sowas macheniva ist. Police-向 setup. Das ist Null.)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | retrieval 15)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | results
 Willkommen zum dritten Block von Einführung in die künstliche Intelligenz, in dem wir ausgewählte Themen behandeln. Heute geht es um die Bildverarbeitung oder das Bildverstehen. Bevor es aber losgeht, wie immer ein paar Quizfragen. Und wenn Sie die beantworten können, dann sind Sie bereit für die neue Einheit. Die Themen von heute sind vielfältig und wir wollen einmal quer durch das Gebiet hindurchgehen, entlang der sogenannten Image Processing Pipeline, also der Verarbeitungsschritte, die erfolgen, um Bilder zu verstehen. Wir beginnen mit der Merkmalserkennung, die Kantenerkennung, Konturen extrahieren, Linien in Bildern erkennen und werden uns dann dem eigentlichen Bildverstehen zuwenden. Einen konkreten Algorithmus herausgreifen, der auch noch mal Verbindungen zu den vorherigen Blöcken darstellt, Constraints und Bayesian-Netzwerke, wie auch Logiken. Und zum Abschluss einmal hineinschauen, was aktuell im Bereich maschinellem Lernen für die Bildverarbeitung passiert. Durch die Durcharbeitung dieser Einheit sollten Sie in der Lage sein, dass Sie die Aufgaben und die Schwierigkeiten, die im Bereich der Bildverarbeitung auf Sie lauern, dass Sie die beschreiben können, erklären können und dass Sie die einfachen Methoden der Linienextraktion, Konturextraktion anwenden können und auch eine 3D-Rekonstruktion anhand eines ausgewählten Algorithmus durchführen können. Des Weiteren sollte es Sie weiterhin darin etwas bestärken, wie die KR-Techniken, die Sie zuvor behandelt haben, in den letzten fast zwei Einheiten, hier mit dem Bereich des Computer Visions, also in der Bildverarbeitung, zum Einsatz kommen können, wie diese hier helfen. Zunächst einmal eine Definition. Worum geht es eigentlich bei Bildverarbeitung? Und das ist eigentlich ganz schön gesagt in einem häufig zu findenden Zitat, in dem es heißt, es geht darum, eine Verbindung, eine Brücke zu bauen zwischen Pixeln auf der einen Seite und Bedeutung auf der anderen Seite. Und all das, was die Verbindung zwischen Pixeln in einem Bild und Bedeutung darstellt, all die Techniken, das ist Bildverarbeitung, Computer Vision. Es gibt eine ganze Menge von Anwendungen hier, die durchaus ihre spezialisierten Techniken haben und es gibt auch eine Menge von Teilaufgaben in dem Gebiet. Wenn man das Gebiet mal so aufschreibt in seiner Fülle von Aufgaben, so kann man das entlang einer Achse von Low-Level bis High-Level hier beschriftet sortieren, indem in den unteren Stufen wir nah an dem Sensor sind, also an den Daten, die als Eingabe kommen und nach oben hin immer abstrakter werden. So ist die unterste Aufgabe etwas wie Farbkleckse zu erkennen, Blobs genannt oder bestimmte Merkmale. Vielleicht auch die Formen anhand einer wiederkehrenden Textur zu umschreiben und von dort an weiter vielleicht Bewegungen zu erkennen, einzelne Formen anhand ihrer Art zu identifizieren, also beispielsweise einen Objektivdeckel durch seine runde Form. Auf der Ebene darüber geht es darum, dass wir eine Objektrekonstruktion durchführen, beispielsweise auch aus einem Stereokamerabild, also zwei Kamerabildern, diese durch Überlagerung zu einem 3D-Bild zusammensetzen und von dort an weiter abstrakt vielleicht Bilder auf Elemente hin zu untersuchen, Gesichter zu erkennen, bestimmte Objekttypen zu erkennen, also jetzt nicht nur von der Form her zu sagen, das sieht aus wie ein Objektivdeckel, sondern an der Stelle wirklich zu sagen, wir haben jetzt hier einen Objektivdeckel erkannt, bis hin weiter auf die höheren Abstraktionsebenen, was sagt uns das? Was sagt uns, dass wir einen Objektivdeckel erkennen? Wahrscheinlich ist ein Objektiv nicht fern, wenn hier ein Objektivdeckel herumliegt. Das ist dann die höchste Stufe und auf all diesen Stufen können Sie mit KI-Methoden auf verschiedenste Art und Weise Beiträge leisten. Wie schaut es eigentlich heute aus? State of the art, also was ist der Stand der Wissenschaft heute? Es ist immer noch ein sehr, sehr aktives Gebiet in der Forschung seit vielen, vielen Jahren und es gibt eine ganze Menge von durchaus sehr reifen Techniken, die heute industriell eingesetzt werden. Eine ganze Menge industrieller Anwendungen, basiert auf den hier in der KI entwickelten Techniken. Aber dennoch ist die Bildverarbeitung noch sehr viel schlechter, als das, was wir Menschen können. Das ist besonders auf den höheren Stufen der Fall. Was wir heute finden, beispielsweise die Weiterentwicklung oder die Entwicklung des Gebietes zu zeigen, ist einerseits die Anwendung hier im Beispiel von Intel im Bereich der Prozesskontrolle. Industrielle Anwendungen, die Bildverarbeitung hier verwenden, um die Reinheit von Flaschen zu prüfen, die Füllgrade, auch durchaus von Obst, ob es eben verdorben ist, ob es gut aussieht, ob es Stellen hat, all das, das nennt man gar nicht mehr KI. Das ist eine industrielle Bildverarbeitung. Genauso gibt es im Bereich der medizinischen Anwendung. Erkennung von Krebszellen, die Durchführung von robotischen Chirurgieaktionen, all das sind sehr, sehr weit entwickelte Techniken, sodass man hier mit einer minimalinversiven Chirurgie bereits sehr eindrucksvolle Leistungen erbringen kann, die durchaus heute schon zum Klinikalltag gehören. Wir sehen auch Bildverarbeitung im Bereich der Robotik und der autonomen Fahrzeuge bzw. der halbautonomen Fahrzeuge, wenn wir an Warnsysteme denken. Hier ist ein Bild dargestellt aus einer Arbeit von der Gruppe um Sebastian Thrun von Stanford, in dem sie hier ein Auto, das ist ein VW, ein autonomer VW da, und in diesem Falle Laser Range Finder Scan, eine 3D-Punktwolke, die entsteht. Und man sieht hier, wenn Sie das Bild im PDF sicher mal heranzoomen, Fahrzeuge, genau auch das ist eine Aufgabe der Bildverarbeitung, die Szenen zu verstehen. Wir bekommen hier offenbar eine Kreuzung und dort kreuzen zwei Autos. Das ist auch Teil von Bildverarbeitung und wie Sie aus den Medien entnehmen können, einige von diesen Autos fahren bereits in halbwegs umzäunten Gebieten, ist das durchaus sehr robust bereits möglich. Über Risiken werden wir am Ende dieser Einheit noch kurz sprechen. Wenn wir einmal die maschinelle Bildverarbeitung mit der menschlichen gegenüberstellen, so kann man sagen, dass es tatsächlich zwei getrennte Verarbeitungszweige gibt, die sich einander ja nur grob entsprechend angefangen. Vom Auge, wo ein Bild aufgenommen wird, bzw. der Kamera, wird es dann durch entweder Computergehirn verarbeitet und soll am Ende zu einer Interpretation liefern. Und ein häufig verwendetes Zitat hier von 1971 sagt aus, dass die menschliche Bildwahrnehmung eigentlich eine kontrollierte Halluzination ist. Dieses Zitat kommt nicht von ungefähr, sondern betrachtet einfach einmal die Art der Verarbeitung, die stattfindet. Wir Menschen sind sehr, sehr zielgerichtet in dem, was wir sehen, was wir überhaupt interpretieren müssen. Gerade die frühen Ansätze der Bildverarbeitung und auch heute noch dominante Teile, die werden jedes Pixel des Bildes erst einmal gleich behandeln, versuchen zu interpretieren, zu Objekten zusammenzusetzen, und werden sich nicht mit dem zufriedengeben. An einem Bild, wie diesem hier, wird man als Mensch schnell abtun. Okay, ein Katzenbild, die Katze will Aufmerksamkeit, das war's. Und die weiteren Details, die interessieren den Menschen oft gar nicht. Und das ist aber auch vielleicht einer der Schlüsse, warum es beim Menschen so gut funktioniert im Vergleich zum Computer. Wir gehen da sehr zielgerichtet vor.)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | results
 Yes. So other examples. We use AI. Again, we have operation robots, but also we use... We use AI technology. We use AI techniques in making sure that our computers do actually what they were supposed to do. So there we go. How nice. For instance, at the time of your birth, I guess, or a little bit beforehand, Intel had what we now know as the Pentium disaster, which means they actually mass-produced a chip that... didn't divide quite right. The division, the integer division routine had a little error, which most people didn't notice, but still they had to basically recall all the chips, which means basically opening every computer in... every recent computer in existence at that time, that... and opening it up, changing the chip. Costum. And... And... And... And... And... And... And... And... And... And... And... I think half a billion dollars at the time. So they said, well, we don't want that again. So they employed people who actually use a program called an automated theorem prover. In this case, a colleague of mine. And they just basically bought up two big research groups. And they said, well, we need a way of actually generating proofs. mathematical proofs that division and multiplication and so on in this chip is actually correct. So that's what they did. And they're still employing a whole stable full of AI researchers, automated reasoning in this case researchers, who build programs that can actually prove that your program or your chip, which is kind of an in silico program, actually do what they're supposed to do. We have the same thing for many other things where we're actually verifying correctness of programs with, in this case, symbolic AI methods. And we routinely do so. Your credit card company will actually use AI methods. To spot instances of where you're actually using your credit card in Kuala Lumpur and in New York within minutes of each other. They basically find out something is not right here and they do whatever they do. So we have all these kind of methods where we're using AI methods. AI. Every day. In industry, privately, you're using Google Translate. And I'm sure that many of you do because, for instance, we only have German administrative websites annoyingly at this university. So that's a good way of actually surviving. AI technology. In this case, language technology. Okay. So. We've achieved. We've achieved a couple of things. AI technology is here, which it better be after 70 years, right? But there's still a lot to be done. I'm sure you've been waiting for this one, right? AlphaGo. 2016. This program beat the reigning champion, and leased it all in Go. Now, there was a, there's a history to this. Athenian. Game playing has always been a very respected topic in AI, and over the about 50 years or so that AI researchers were doing them, we have basically conquered all the games, or at least all the board games in the world. tic-tac-toe relatively early that was very easy and then things and then chess a little bit more recently there was only one holdout well actually two there was a game called checkers I think dam in German where they they had basically had programs that were better than all but one human and this human was just a whole category better than everybody else and so the the problem of checkers was that no longer being better than everybody in the world but being better than this one person and and unfortunately he died before before he could be beaten by a by a by a program so we believe that well right now it's true that no human can compete with a checker program but this one guy was mysterious and then there was one other exception which very consistently machines were doing very consistently machines were doing very very badly and that was Go and people became so frustrated that they just didn't believe that Go would be would be conquered anytime soon and so out of the blue came came Google DeepMind and they actually beat this guy with an interesting technique I'm going to go through this one and then I'll show you the other ones but I'm going to go back to the example later this semester when we can kind of understand what's going on there and so this is also something we have a we have a an AI topic game playing and you could now say Go winning at Go is no more not AI anymore but they give us kind of a grace period so we can consider Go for being AI for about 10 years but then people would say yeah but Go is also easy come on right there are lots of things that are not conquered by AI finding math proofs is something that AI programs are very bad at any unknown proofs any undergraduate math students can beat an automated theorem prover the automated theorem prover will typically find the proofs it will find in 50 milliseconds or something like this where I I proofs where I kind of take five minutes because but then and so there's a speed difference but more complex proofs humans are much much much much better not in this not at least in the same class yes there's a question)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | results
 Dieser Audiobeitrag wird von der Universität Erlangen-Nürnberg präsentiert. So, es ist nach. Ich erhoffe mich, dass auch in der zweiten Vorlesung noch viele da sind. Ich fange ja jetzt immer an, die ganze Sache, dass ich durch die Folien vom letzten Mal nochmal durchgehe, ein bisschen schneller als das letzte Mal und hoffe, dass ich Ihnen dazu dadurch einen Anhaltspunkt geben kann, vielleicht noch Fragen. Ich hoffe, dass ich die Erinnerung wieder zurückkomme und dann können wir das. Das ist vollkommen okay, deswegen machen wir das. Außerdem möchte ich... Ich will nicht die Sachen zu sagen, die ich beim letzten Mal vergessen habe. Und das so ein bisschen zusammenzufassen. Doch, richtig. Wir haben uns nochmal unterhalten darüber, wie am Anfang des letzten Semesters, uns zu fragen, was ist denn KI? Und dann hatten wir uns einige Definitionen angeguckt. Und... Im Prinzip das Wichtigste, was dabei rauskommt, egal wie man es macht, ist, dass man irgendwie so ein paar Komponenten hat, hat der Intelligenz, die man irgendwie versuchen muss abzudillen. Typischerweise intelligente Verhalten entsteht dadurch, dass man lernt, dass man Schlüsse ziehen kann, dass man die Umwelt wahrnehmen kann und bei Menschen auch die Sprache versteht. Und natürlich ist es die ganze Ebene der Emotionen, die man immer stärker sieht in letzter Zeit. Sehr starke Rückwirkungen auf all diese anderen Dinge hat. Am Anfang der künstlichen Intelligenz war es irgendwie so, dass man Emotionen und Geologien versucht hat, sie aufzulassen, weil man dachte, das ist so eine der Sachen, die man natürlich nicht braucht. Ja, das kommt einem im Wesentlichen in die Quere. Aber man versteht immer besser, dass Emotionen ihren Sinn haben und uns Möglichkeiten eröffnen. Und da sind wir. Ich habe sie versucht zu überzeugen, dass wir uns nicht nur in der Klinik verhalten, sondern auch in der Technologie verhalten. Und das ist das, was wir KI an allen Ecken und Enden sehen. Zwar nicht nach der Definition von Elaine Rich, nämlich KI ist das, was Menschen noch besser können. Demnach gibt es keine angewandte KI. Das fände ich ein bisschen traurig. Aber zumindest, wenn man sich die Dinge anguckt, wo sie denn herkommen, kommen sie irgendwie aus einer KI-Umgebung. Da sind ja sehr viele autonome Systeme, autonome Gefährte, die irgendwo rumfahren. Zum Beispiel auch im Mazda, das ist wichtig, weil wir keinen haben, der sie steuern kann. Zum Beispiel auf unseren Autobahnen, wo Menschen einfach teuer sind. Die Lastwagenindustrie, die sind wahnsinnig interessiert daran, selbstfah versucht, eine Lastwagen-Helden-Kette zu haben. braucht man weniger Lastwagenfahrer zu bezahlen. Deswegen hoffentlich dann, wenn es eine ganz neue Generation von Lastwagen abgesetzt werden kann, weil die Speditionen irgendwie auch die Gehälter der Fahrer verzichten können wollen. Und weil natürlich Computer keine Ruhezeiten einzuhalten brauchen. Menschen dürfen nur irgendwie acht Stunden fahren, während Computer vermutet man keine Ruhezeiten brauchen. Solche Sachen. Ersatz von menschlichen Fähigkeiten. Solche Arme. Hilfe im Haushalt. Hilfe bei der Altenpflege wird wahrscheinlich sehr wichtig für einen Landpflegenumstand. Eine der Möglichkeiten ist, nicht Polinen zu importieren, sondern solche da. Ob das natürlich die Alten besonders nett finden, ist die Frage. Das könnte irgendwann mal kostenlos werden. Weiter in der Medizin, gewisse Operationen werden heutzutage, zumindest in den USA, routinemäßig von solchen Monstern durchgeführt. KI-Algorithmen in Sicherheit, in Netzsicherheit, solche Dinge, Gefahren. Überall da sind diese Algorithmen. Und Repräsentationsmechanismen. Und natürlich, es gibt immer mal wieder große spektakuläre Dinge. Zum Beispiel das Kotzen der Körpergegewinne. Oder eben die AlphaGo gegen das im Prinzip letzte Spiel, das letzte Brettspiel. Das letzte Brettspiel jetzt. Die Maschinen besser sind. Wir haben im letzten Semester einen Teil von AlphaGo angeschaut. Wie das funktioniert. Und der andere Teil, mit elasticem Lärm, den wollen wir uns dieses Mal im Semester anschauen. Gut. Also KI ist die typische Wissenschaft, ich will mal sagen, der Therapie-resistenten Fälle. Alles was zu schwer ist für die Informatik, das ist in der KI. Und alles was in der KI gelöst wird, wird dann irgendwie in die Kerninformatik gehabt. Das wird ein eigenes Feld. Das heißt nicht, dass es nicht eben viel mit Dingen, die gut sind in der Informatik gibt, die nicht aus der KI kommen. Selbstverständlich. Ja. Aber es gibt schon drin so eine Art Pipeline.)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | results
 AI-Mag erschienen von den beiden, die das auf eine sehr anschauliche Weise darstellen. Das ist ja schon fast eher populärwissenschaftlich als hier wirklich ein wissenschaftlicher Artikel, aber sehr lesenswert und kurzweilig. Wenn nun Textverstehen schon so schwierig ist, wie sieht es denn aus mit Frage-Antwort-Systemen? Wenn Sie das Gefühl haben, dass Sie ihr Alexa, Google, Siri, Cortana und wie Sie auch immer alle heißen mögen, versteht, denken Sie bitte zurück an die Folien zuvor von Eliza. Mit ein paar Zeilen mehr Code kann man ein paar mehr Menschen beeindrucken. Und natürlich, dadurch, dass das Sprachverstehen und die gesprochene Sprache mit integriert ist, wirkt das Ganze schon sehr, sehr mächtig. Dem ist es leider nicht so. Die ersten erfolgreichen Systeme, die wir hatten im Bereich Sprachverstehen, gehen schon weiter zurück. Das war IBMs Watson-System, in dem sie eine Information-Retrieval-Komponente verbunden haben mit einem Sprachverstehen, das Fragen analysiert hat, um mit einer sehr schicken Balance dieser beiden und einem sehr interessanten Ansatz es geschafft haben, so ein Spiel Jeopardy gegen Menschen zu gewinnen. Im Spiel Jeopardy finden Sie ein Faktum vorgelegt und müssen eine Frage dazu geben, die auf das Faktum hinweist. Also man könnte eine Jahreszahl nennen und dann würde man sagen, in diesem was geschah oder wann wurde ein Land entdeckt beispielsweise. Die Systeme verbinden hier, wie man auch sieht, durchaus verschiedene Komponenten der KI, Sprachverarbeitung, Inferenzen, Schlussfolgerungen, wie auch Information-Retrieval. Aber keines dieser Systeme kommt an das heran, was Menschen leisten können. Wenn Sie beispielsweise eines dieser Systeme fragen wollten, wie wenn Sie Harry Potter denken, wo sind die Hockruchse versteckt? Keines der Systeme kann es antworten, denn es steht ja nicht im Text. Man muss es sich zusammensuchen über verschiedene Bücher oder Kapitel. Informationen, die wir zusammen puzzeln, die also Inferenz, Reasoning erfordern, sind den heutigen Systemen nicht zugänglich. Das macht sich sehr deutlich gerade auch, wenn Sie so maschinelle Lernverfahren basierte Systeme nehmen. Auch alleine schon da, wie man sich die Trainingsdatensätze anschaut. Ein großer Datensatz von Stanford, der Open Domain Question Answering mit Machine Learning erreichen möchte, definiert zu sagen, naja, wenn Sie eine Frage haben, ist die korrekte Antwort auf die Frage das Vorlesen des Wikipedia-Ansatzes aus Absatzes, aus dem man die Antwort ableiten kann. Wenn das Sprachverstehen ist, ja, dann ist das erreichbar in kurzer Zeit. Und wenn wir einmal in ein Frage-Antwort-System hineinschauen, dann finden wir was, was wir aus der Wissensrepräsentationsveranstaltung schon kennen. Etwas, das aussieht wie ein semantisches Netzwerk. Es ist dem auch sehr, sehr verwandt, heißt hier Multinet und hat seine Semantik durch eine abstrakte Logik erhalten. Es liegt zugrunde dem Log-Answer-Question-Answering-System, das Uli Furbach von der Universität Koblenz entwickelt hat. Hier sehen Sie Informationen, die aus Wikipedia automatisch, aus dem englischen Wikipedia extrahiert worden sind, die dann in diesem Netzwerk kodiert worden sind. Und aufgrund seiner logischen Semantik, dann sozusagen ein textologischer Konverter, dann mit Inferenzalgorithmen bearbeitet werden kann, sodass auf dem, was hier extrahiert werden konnte, komplexe Fragen beantwortet werden können. Ja, in dem Falle können Sie ja selbst einmal herauspuzzeln, um was es da geht und was man da vielleicht gefragt hat, was man genau mit diesem Ausschnitt des Netzwerkes beantworten kann.)
2025-10-19 22:56:28 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | retrieval 15)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | results
 ein paar von ihnen haben letztes Semester das Seminar Machine Learning bei Thomas Wieland belegt. Also ein paar von ihnen haben das hier schon mal gesehen vermutlich. Sogenannte Convolutional Neural Networks erkennen Ziffern besser als Menschen, schon seit einigen Jahren, auch Verkehrsschilder glaube ich. Also sie machen weniger Fehler. Es gibt Neural Style Transfer, der den Stil von Gemäden auf Bilder übertragen kann. Das ist auch Deep Learning. Super Sampling erzeugt hochauflösende Bilder aus kleinen Bildern. Sie können also eine kleine Auflösung auf eine hohe Auflösung hochrendern, sagen wir mal voller DO4K. Deep Learning, NVIDIA nennt es DLSS, also vermutlich Deep Learning Super Sampling, aber ich glaube, ich habe einen TM vergessen, der Begriff gehört denen. Deep Fake, wo sie Gesichter auf andere Personen draufsetzen können. Und GANs, also Generative Adversarial Networks, die echt aussehende Fotos erzeugen können und auch ganz viele andere Dinge erzeugen können. Also es gibt die Website This Person Doesn't Exist oder This Cat Doesn't Exist. Und das ist einfach krass, was diese Netzwerke können. Und das selbstfahrende Auto ist jetzt wirklich nur noch wenige Jahre entfernt. Diesmal wirklich. Also wenn wir es in zehn Jahren noch nicht haben, können Sie gerne sich bei mir melden und sagen, haha, wieder nicht. Aber aktuell ist es vermutlich primär ein Versicherungsproblem. Die Frage, wer ist schuld, wenn ihr Auto einen Unfall baut? Und wenn Sie sich mal alte Dokus anschauen, Sie hatten damals noch ganze VW-Busse, die hinten voller Computer waren. Und heute haben Sie dank Deep Learning und Grafikkarten, dank Hardware-Beschleunigung, haben Sie viel kleiner Computer, die in schon sehr vielen Situationen sehr autonom fahren können. Und hier nochmal ein paar Beispiele, was so in den letzten ein, zwei Jahren KI-Nachrichten waren. Das sind nicht nur dieselben, die Sie auch in der Verlösung GML gestern vielleicht gesehen haben. Das ist eine andere Auswahl. Es gibt Firmen, die KI, in dem Fall Machine Learning, bei der Jobbewerbung nutzen, um automatisch Kandidaten zu bewerten. Mit seinen Problemen natürlich. Was passiert, wenn die Frisur anders ist, wenn der Hintergrund anders ist, wenn er eine Brille trägt? Auch andere Probleme, wieder ethische Probleme. Also Deutschland ist 96, andere Länder sind einem Verbund gegen autonome Kampfroboter beigetreten, also Terminator lässt grüßen. Das ist das Problem. Wenn Sie irgendwann der Maschine, dem Computer, die Entscheidung überlassen, ob da jetzt irgendetwas jemanden umbringen soll oder nicht, dann haben wir eine Grenze überschritten, die wir hoffentlich lange nicht überschreiten. Aber es wird vermutlich kommen, einfach weil man es kann. Und das sind ethische Fragen, mit denen sich auch die KI beschäftigen muss. Sie haben den Fall mittlerweile von rassistischen oder sexistischen Fragen. Also die Twitter Bildauswahl. Wenn Sie ein zu großes Bild bei Twitter hochladen, wird ein Ausschnitt gezeigt. Und offenbar bevorzugt ihr die Twitter Bildauswahl weiße Gesichter. Also die Links können Sie, also die funktionieren hoffentlich alle. Da können Sie sich die Artikel gerne mal anschauen. Da ist Golem dabei, weil ich halt ein Golem-Abo habe. Es ist keine Werbung für die Zeitschrift, es ist einfach nur die Quelle gewesen, wo ich am schnellsten und am meisten relativ neue Nachrichten dazu kriegen konnte. Seit November gibt es auch eine neue Kombi-Serie von den Southpark Machern, die mit Deepfakes die Leute ersetzt. Also ich glaube, die Hauptfigur ist eigentlich das Gesicht von Donald Trump, aber man kennt es kaum, weil die Frisur nicht die richtige ist. Und im Januar haben auch Forscher Vorurteile im riesigen Sprachmodell aufgezeigt. Also Google hat dieses Sprachmodell GPT-3, was übrigens auch immense Energie gefressen hat, zu trainieren. Und das hat Vorurteile, einfach weil die Texte gebiased waren. Zum Beispiel, dass gewisse Dinge einfach, zum Beispiel eher mit Frauen, ich glaube also, wenn es allein darum geht, das Geschlecht zu schätzen, wurde bei Arzt, Anwalt eher auf Mann geschätzt und bei Krankenpfleger oder Lehrer eher auf Frau vermutet. Was ja genau das ist, was man heute eigentlich vermeiden möchte. Aber die Methoden sind dann teilweise nur so gut wie ihre Daten. Und damit, also mit diesem Problem, sage)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | results
 So before deploying, there is a review and then post-deployment, there should probably be a regular review of a smaller kind, just to see, you know, if things are really good. So what is often neglected is services that are already running and seem to be doing fine. As long as nothing crashes, they may not get checked, but over time, a deployed machine learning model may become more and more racist, as it happened to a Microsoft chatbot that was kind of retrained in a very nasty way by a little girl out of fun, until Microsoft discovered it and switched the thing off. But by that time, the reputational damage was already done and it was all over news headlines at the time. So when systems are adaptive, there should be an ongoing inspection at gradual, regular inspection points to see if models perhaps need to be updated to eliminate problematic cases, like in the image, Google photo example. And sometimes such a review may recommend a retraining of the model with a more balanced training data set that includes, you know, more examples for certain minorities or things like that. So it is a first process proposal, more than anything else, it is a straw man proposal so that we have something to attack and to discuss and to hopefully improve the model. So it is a process proposal, to hopefully improve incrementally, and maybe some company would be willing to implement this. But ethics boards generally in industry have been fraught with some difficulty. Read about the Google ethics board, for example, in the media, which has led to some some disagreements inside and outside the companies about what is okay and what is not okay. And we're just at the beginning of this. So we come to the end. So in summarizing this session, we have learned about a set of 11 ethical problems connected with AI or computing in general. And they include automation, abstraction, violation of privacy, fairness and algorithmic discrimination of minorities, bias and the filter bubble, lack of transparency, lack of prior consent, e-propaganda, aka fake news, voice morphing and deepfakes, dual use goods, and finally intelligent weapon systems. Again, this is not a complete list, but all of these are at least quite fundamental and becoming urgent to deal with and to address and to spread the awareness around. And we concluded with the ethical by design process, first proposal for an ethically guided development and research process. Thank you.)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | results
 I'll conclude with a brief description of an ethical design process and then we'll summarize. In this session we'll look at a set of 11 central ethical problems which result from computer science in general and artificial intelligence specifically. This is not a complete list but the problems are quite fundamental. We'll also learn about a proposal for a more ethical development process. The first ethical problem of artificial intelligence is a problem that all of computer science creates. It's the problem of automation. In particular automation means loss of jobs. And the reason is machines work more cheaply, machines never sleep, machines get no salary, take no sick days, are never even on vacation or on maternity leave. Machines also work faster and more consistent than humans. And together this is a very compelling financial proposition to replace humans by machines. Wherever this is possible and in a free market economy there will be a natural pressure to reduce cost at all times in order to be more competitive. And once one player starts adopting such a policy then others may be induced to do the same. Now it's not just about loss of jobs. Entirely new types of jobs are also created at the same time. For example, Software developers, Database administrators, Social Media community managers some of which have not been existed as jobs a couple of years ago. In the past automation duration of mostly physical and menial work came now. And the new thing now is also cognitive tasks can be automated. This time around jobs like lorry driver may be anHHH.... algunasóstom that flightiSEE sällbe immer so infinite синk globaland progne créev firing das des komED色 end привieren�sch influenced by Superman. Somehow joblogging in a sector might show up a concrete concern among all. may be affected as self-driving cars become available and regulated. And the problem is drivers won't readily be retrained. They may not be able to take on other roles or not willing to do so. And this is a problem because a lorry driver is actually one of the most, if not the most common job in North and South America. But work is about a number of dimensions. It's about the concerns regarding human dignity and one's identity as a worker. So we identify ourselves as the job we do. We give our name and our profession usually when we introduce ourselves so people can figure out what kind of person we are. By learning what we do, and of course livelihoods are affected and people have proposed alternatives such as universal basic income, UBI, which is the idea of giving everybody a certain sum of money regardless of whether they work or not. And these issues do not solve the issue of meaning of work or identifying with work.)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | results
 I'll conclude with a brief description of an ethical design process and then we'll summarize. In this session we'll look at a set of 11 central ethical problems which result from computer science in general and artificial intelligence specifically. This is not a complete list but the problems are quite fundamental. We'll also learn about a proposal for a more ethical development process. The first ethical problem of artificial intelligence is a problem that all of computer science creates. It's the problem of automation. In particular automation means loss of jobs. And the reason is machines work more cheaply, machines never sleep, machines get no salary, take no sick days, are never even on vacation or on maternity leave. Machines also work faster and more consistent than humans. And together this is a very compelling financial proposition to replace humans by machines. Wherever this is possible and in a free market economy there will be a natural pressure to reduce cost at all times in order to be more competitive. And once one player starts adopting such a policy then others may be induced to do the same. Now it's not just about loss of jobs. Entirely new types of jobs are also created at the same time. For example,たบめ restrai In the past automation happened of mostly physical and menial work and the new thing now is also cognitive tasks can be automated. This time round, jobs like loridriver, maybe a faecesy engineer, attack regulations, profit Renault, maybe a cog movements reviewer, maybe a woman there, yeah, we may do more. But that's just this, there's always room for more and lots more, and that's worth modeling. It's necessary for everybody affected as self-driving cars become available and regulated. And the problem is drivers won't readily be retrained. They may not be able to take on other roles or not willing to do so. And this is a problem because a lorry driver is actually one of the most, if not the most common job in North and South America, but work is about a number of dimensions, it's about the concerns regarding human dignity and one's identity as a worker, so we identify ourselves as the job we do, we give our name and our profession usually when we introduce ourselves, so people can figure out what kind of person we are by learning what we do and of course livelihoods are affected and people have proposed alternatives. Such as universal basic income, UBI, which is the idea of giving everybody a certain sum of money, regardless of whether they work or not. And these issues do not solve the issue of meaning of work or identifying with work.)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | results
 You can easily extrapolate how such a robot capability can be deployed in a war, for example. So these were 11 out of the total set of, I don't know how many ethical issues there are around AI, but what can we do as people who are likely to build systems that others may call semi-intelligent? So in 2009, the Canadian Chief Privacy Officer created a white paper called Privacy by Design. And in 2017, Vasilis Plahouras and I adopted some of the notions and kind of ported them from the privacy concept over to ethical notions, generalizing them a little. And here's what she postulated, what Ann Kavoukian postulated in our adjusted form. So there are these six postulates. So a process that is ethical by design that develops systems respecting ethical norms should be proactive instead of reactive. So we need to build in the ethics somehow. So ethics should be the default setting, not something that gets added as the icing on the cake. And then third, it should be embedded in the process. So not as an afterthought that, you know, when it's too late, potentially when the harm is done, you do an ethics review, that's not a good idea. Ethics should be an end-to-end ethics. Yeah. So the ethics should be pervasively present in the process. The process should be visible and transparent and respect user values. These are fairly obvious things. So the question is how to bake that into a development process or research pipeline. And if you look at the diagram below, which is a shortcut of our process that we suggested. So you typically have a pipeline that starts with research leading into product development, potentially two, three years down the line, depending on what it is about. And then after product development, you deploy the product in a marketplace. In the world of software, this is often done in the cloud. And there are certain checkpoints. So before you even start a research project, you could consult an ethics approval board, a sort of IRB, institutional review board, similar to what universities have when doing animal experiments or indeed experiments on human beings. Such research needs to be usually pre-approved. And we basically suggest that companies should have something like that as well. And this ethics approval board should have a veto or approval rights and should at certain touch points throughout the development process be mandatory. Checkpoints should be implemented. So after the research, again, you know, if something comes out of the research, it could be used for a product, then there should be another check because sometimes it's okay to try something really daring just to see whether it's even possible, you know, for the purposes of even informing even an ethical discussion. You learn a lot from it. It doesn't mean that you throw it out there in the marketplace. So this is an important check that when you plan to transition something to a product, because it works better than you thought, that you have a chance to say, look, this is really a bad idea to add to this drone an automatic gun or something like that and sell it to teenagers. A silly idea, don't do it, cancel the product development. Now, even after the product development or during the product development, new moral hazards can crop up. And sometimes these are not just, you know, ethical or moral problems. They're also in the interest of the company to sort out because the company has a reputation to lose. So this ethics approval board may be seen as something that is sort of a naysayer, something that, you know, stops innovation blocks things that could create a lot of revenue. But on the other hand, it could be seen as something positive that avoids silly scandal like the Google photo example from 2015. And this can work if, and only if the ethics approval board is given enough power to actually say no, so that the no actually gets implemented as well. And if, and only if the ethics approval board is installed and it comprises a diverse set of expertise, including moral philosophy, the law, technical slash scientific expertise, and perhaps a lot of common sense too. And some of these are hard to find. So before deploying, there is a review and then post-deployment, there should probably be a regular review of a smaller kind, just to see, you know, if things are really good. So what is often neglected is services that are already running and seem to be doing fine. As long as nothing crashes, they may not get checked, but over time, a deployed machine learning model may become more and more racist, as it happened to a Microsoft chatbot that was kind of retrained in a very nasty way by a little girl out of fun, until Microsoft discovered it and switched the thing off. But by that time, the reputational damage was already done and it was all over news headlines at the time. So when systems are adaptive, there should be an ongoing inspection at gradual, regular inspection points to see if models perhaps need to be updated to eliminate problematic cases, like in the image, Google photo example. And sometimes such a review may recommend a retraining of the model with a more balanced training data set that includes, you know, more examples for certain minorities or things like that. So it is a first process proposal, more than anything else, it is a straw man proposal so that we have something to attack and to discuss and to hopefully improve the model. So it is a process proposal, to hopefully improve incrementally, and maybe some company would be willing to implement this. But ethics boards generally in industry have been fraught with some difficulty. Read about the Google ethics board, for example, in the media, which has led to some some disagreements inside and outside the companies about what is okay and what is not okay. And we're just at the beginning of this. So we come to the end. So in summarizing this session, we have learned about a set of 11 ethical problems connected with AI or computing in general. And they include automation, abstraction, violation of privacy, fairness and algorithmic discrimination of minorities, bias and the filter bubble, lack of transparency, lack of prior consent, e-propaganda, aka fake news, voice morphing and deepfakes, dual use goods, and finally intelligent weapon systems. Again, this is not a complete list, but all of these are at least quite fundamental and becoming urgent to deal with and to address and to spread the awareness around.)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | results
 And for state actors. Another ethical challenge is around fairness and algorithmic discrimination. And in particular, discrimination of minorities. Take a web query pair as the following. Three black teenagers versus three white teenagers. When you Google three black teenagers, you may get some kind of mugshot from three black teenagers that got arrested for something. When you search for three white teenagers, you may get a happy smiley picture of three pretty girls, you know, hanging out, socializing, having fun. This is a bias based on the skin color of web search results. It is a reflection of news reporting bias that underlies the information content that Google indexes, of course. A second example for this bias in the context of minorities is the Google photo scandal which happened in 2015. Google photo then recognized humans with black skin as apes because the training data that it was trained on to classify pictures was mostly using humans with white skin. And Google quickly eliminated this particular classification output. And the fix was not to rebalance the training set. That is a huge effort and maybe also technically challenge to accomplish. But to basically give no output at all for certain cases, to kind of silence the classifier. This is also an important piece of evidence for the fact that we need to design systems where humans still have an opportunity to provide manual override of system output. If such scandals or disasters happen, that developers can still sort of prevent further harm. A third example is speech recognition. Imagine a world of phone banking. Bank branches are, in decline, they cost a lot and they are unnecessary in a world that becomes increasingly an online world. So, it is conceivable that in the future there will be no bank branches at all in most cities. No branches of a physical kind that you would call in only or use the internet to do your phone banking, internet banking. And in the case of phone banking, there may be a use of a speech recognition system rather than a human agent for cost reasons. Now imagine further that such speech recognizer may not or not properly recognize Scottish accent because it is not economically viable to develop a bespoke model for a minority group such as the Glaswegian variety of Scottish English. What to do about it? Well, one way is to enforce a certain balance, to enforce tests that include minority groups and to have some kind of audits and that would be a form of regulation similar to a web page regulation for the UK that already mandate accessibility of web content for blind people, for example. Another issue is the discrimination based on location. And the example here that everybody has been talking about is the scandal around Princeton tutorial fees. So, it is desirable to enter Princeton University, it's a very good university and there are tutors offering candidates help to do well in entrance exams. And as it turns out, these tutorial fees were actually priced depending on zip code, so that's a US way of calling the postcode, so that more affluent locations got a higher price advertised, assuming that people who live there may be able to afford to pay more for the tutorials. Now this is problematic because typically not everybody who lives in an on average, more affluent area is actually themselves more affluent. There are poor people in rich areas and rich people in poorer areas and they are sort of the boundaries or fringes of these affluent areas and so on. So it's unfair to those people that do not represent their own location's average income. And you might say it's even unfair to those people who are more wealthy just because they are more wealthy. They may not like to be charged more for the same good or service. This is already happening. And recommender systems are an amplifier of statistical bias and because they suggest personalized news to read, films to watch, they create what has been called a filter bubble, which is the notion that a subject gets recommended content that they like, that they care about, content similar to what they've engaged before, which ultimately results in no contrarian or alternative points of view are shown anymore. One moves within the microcosm of like-minded people. Now the corrective to that is to recommend as before using personalized algorithms, but interspersing personalized with diversified results. So showing a mix of random or even explicitly different views together with a larger quantity of the personalized news that the person cares about to avoid that they become increasingly isolated. And sometimes this has led to the belief of a minority that the whole world believes a minority view or that there is a large number of people that also join certain conspiracy theories.)
2025-10-19 22:56:29 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | retrieval 14)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | results
 Dieser Audiobeitrag wird von der Universität Erlangen-Nürnberg präsentiert. So, es ist nach. Ich erhoffe mich, dass auch in der zweiten Vorlesung noch viele da sind. Ich fange ja jetzt immer an, die ganze Sache, dass ich durch die Folien vom letzten Mal nochmal durchgehe, ein bisschen schneller als das letzte Mal und hoffe, dass ich Ihnen dazu dadurch einen Anhaltspunkt geben kann, vielleicht noch Fragen. Ich hoffe, dass ich die Erinnerung wieder zurückkomme und dann können wir das. Das ist vollkommen okay, deswegen machen wir das. Außerdem möchte ich... Ich will nicht die Sachen zu sagen, die ich beim letzten Mal vergessen habe. Und das so ein bisschen zusammenzufassen. Doch, richtig. Wir haben uns nochmal unterhalten darüber, wie am Anfang des letzten Semesters, uns zu fragen, was ist denn KI? Und dann hatten wir uns einige Definitionen angeguckt. Und... Im Prinzip das Wichtigste, was dabei rauskommt, egal wie man es macht, ist, dass man irgendwie so ein paar Komponenten hat, hat der Intelligenz, die man irgendwie versuchen muss abzudillen. Typischerweise intelligente Verhalten entsteht dadurch, dass man lernt, dass man Schlüsse ziehen kann, dass man die Umwelt wahrnehmen kann und bei Menschen auch die Sprache versteht. Und natürlich ist es die ganze Ebene der Emotionen, die man immer stärker sieht in letzter Zeit. Sehr starke Rückwirkungen auf all diese anderen Dinge hat. Am Anfang der künstlichen Intelligenz war es irgendwie so, dass man Emotionen und Geologien versucht hat, sie aufzulassen, weil man dachte, das ist so eine der Sachen, die man natürlich nicht braucht. Ja, das kommt einem im Wesentlichen in die Quere. Aber man versteht immer besser, dass Emotionen ihren Sinn haben und uns Möglichkeiten eröffnen. Und da sind wir. Ich habe sie versucht zu überzeugen, dass wir uns nicht nur in der Klinik verhalten, sondern auch in der Technologie verhalten. Und das ist das, was wir KI an allen Ecken und Enden sehen. Zwar nicht nach der Definition von Elaine Rich, nämlich KI ist das, was Menschen noch besser können. Demnach gibt es keine angewandte KI. Das fände ich ein bisschen traurig. Aber zumindest, wenn man sich die Dinge anguckt, wo sie denn herkommen, kommen sie irgendwie aus einer KI-Umgebung. Da sind ja sehr viele autonome Systeme, autonome Gefährte, die irgendwo rumfahren. Zum Beispiel auch im Mazda, das ist wichtig, weil wir keinen haben, der sie steuern kann. Zum Beispiel auf unseren Autobahnen, wo Menschen einfach teuer sind. Die Lastwagenindustrie, die sind wahnsinnig interessiert daran, selbstfah versucht, eine Lastwagen-Helden-Kette zu haben. braucht man weniger Lastwagenfahrer zu bezahlen. Deswegen hoffentlich dann, wenn es eine ganz neue Generation von Lastwagen abgesetzt werden kann, weil die Speditionen irgendwie auch die Gehälter der Fahrer verzichten können wollen. Und weil natürlich Computer keine Ruhezeiten einzuhalten brauchen. Menschen dürfen nur irgendwie acht Stunden fahren, während Computer vermutet man keine Ruhezeiten brauchen. Solche Sachen. Ersatz von menschlichen Fähigkeiten. Solche Arme. Hilfe im Haushalt. Hilfe bei der Altenpflege wird wahrscheinlich sehr wichtig für einen Landpflegenumstand. Eine der Möglichkeiten ist, nicht Polinen zu importieren, sondern solche da. Ob das natürlich die Alten besonders nett finden, ist die Frage. Das könnte irgendwann mal kostenlos werden. Weiter in der Medizin, gewisse Operationen werden heutzutage, zumindest in den USA, routinemäßig von solchen Monstern durchgeführt. KI-Algorithmen in Sicherheit, in Netzsicherheit, solche Dinge, Gefahren. Überall da sind diese Algorithmen. Und Repräsentationsmechanismen. Und natürlich, es gibt immer mal wieder große spektakuläre Dinge. Zum Beispiel das Kotzen der Körpergegewinne. Oder eben die AlphaGo gegen das im Prinzip letzte Spiel, das letzte Brettspiel. Das letzte Brettspiel jetzt. Die Maschinen besser sind. Wir haben im letzten Semester einen Teil von AlphaGo angeschaut. Wie das funktioniert. Und der andere Teil, mit elasticem Lärm, den wollen wir uns dieses Mal im Semester anschauen. Gut. Also KI ist die typische Wissenschaft, ich will mal sagen, der Therapie-resistenten Fälle. Alles was zu schwer ist für die Informatik, das ist in der KI. Und alles was in der KI gelöst wird, wird dann irgendwie in die Kerninformatik gehabt. Das wird ein eigenes Feld. Das heißt nicht, dass es nicht eben viel mit Dingen, die gut sind in der Informatik gibt, die nicht aus der KI kommen. Selbstverständlich. Ja. Aber es gibt schon drin so eine Art Pipeline.)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | results
 Yes. So other examples. We use AI. Again, we have operation robots, but also we use... We use AI technology. We use AI techniques in making sure that our computers do actually what they were supposed to do. So there we go. How nice. For instance, at the time of your birth, I guess, or a little bit beforehand, Intel had what we now know as the Pentium disaster, which means they actually mass-produced a chip that... didn't divide quite right. The division, the integer division routine had a little error, which most people didn't notice, but still they had to basically recall all the chips, which means basically opening every computer in... every recent computer in existence at that time, that... and opening it up, changing the chip. Costum. And... And... And... And... And... And... And... And... And... And... And... I think half a billion dollars at the time. So they said, well, we don't want that again. So they employed people who actually use a program called an automated theorem prover. In this case, a colleague of mine. And they just basically bought up two big research groups. And they said, well, we need a way of actually generating proofs. mathematical proofs that division and multiplication and so on in this chip is actually correct. So that's what they did. And they're still employing a whole stable full of AI researchers, automated reasoning in this case researchers, who build programs that can actually prove that your program or your chip, which is kind of an in silico program, actually do what they're supposed to do. We have the same thing for many other things where we're actually verifying correctness of programs with, in this case, symbolic AI methods. And we routinely do so. Your credit card company will actually use AI methods. To spot instances of where you're actually using your credit card in Kuala Lumpur and in New York within minutes of each other. They basically find out something is not right here and they do whatever they do. So we have all these kind of methods where we're using AI methods. AI. Every day. In industry, privately, you're using Google Translate. And I'm sure that many of you do because, for instance, we only have German administrative websites annoyingly at this university. So that's a good way of actually surviving. AI technology. In this case, language technology. Okay. So. We've achieved. We've achieved a couple of things. AI technology is here, which it better be after 70 years, right? But there's still a lot to be done. I'm sure you've been waiting for this one, right? AlphaGo. 2016. This program beat the reigning champion, and leased it all in Go. Now, there was a, there's a history to this. Athenian. Game playing has always been a very respected topic in AI, and over the about 50 years or so that AI researchers were doing them, we have basically conquered all the games, or at least all the board games in the world. tic-tac-toe relatively early that was very easy and then things and then chess a little bit more recently there was only one holdout well actually two there was a game called checkers I think dam in German where they they had basically had programs that were better than all but one human and this human was just a whole category better than everybody else and so the the problem of checkers was that no longer being better than everybody in the world but being better than this one person and and unfortunately he died before before he could be beaten by a by a by a program so we believe that well right now it's true that no human can compete with a checker program but this one guy was mysterious and then there was one other exception which very consistently machines were doing very consistently machines were doing very very badly and that was Go and people became so frustrated that they just didn't believe that Go would be would be conquered anytime soon and so out of the blue came came Google DeepMind and they actually beat this guy with an interesting technique I'm going to go through this one and then I'll show you the other ones but I'm going to go back to the example later this semester when we can kind of understand what's going on there and so this is also something we have a we have a an AI topic game playing and you could now say Go winning at Go is no more not AI anymore but they give us kind of a grace period so we can consider Go for being AI for about 10 years but then people would say yeah but Go is also easy come on right there are lots of things that are not conquered by AI finding math proofs is something that AI programs are very bad at any unknown proofs any undergraduate math students can beat an automated theorem prover the automated theorem prover will typically find the proofs it will find in 50 milliseconds or something like this where I I proofs where I kind of take five minutes because but then and so there's a speed difference but more complex proofs humans are much much much much better not in this not at least in the same class yes there's a question)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | results
 AI-Mag erschienen von den beiden, die das auf eine sehr anschauliche Weise darstellen. Das ist ja schon fast eher populärwissenschaftlich als hier wirklich ein wissenschaftlicher Artikel, aber sehr lesenswert und kurzweilig. Wenn nun Textverstehen schon so schwierig ist, wie sieht es denn aus mit Frage-Antwort-Systemen? Wenn Sie das Gefühl haben, dass Sie ihr Alexa, Google, Siri, Cortana und wie Sie auch immer alle heißen mögen, versteht, denken Sie bitte zurück an die Folien zuvor von Eliza. Mit ein paar Zeilen mehr Code kann man ein paar mehr Menschen beeindrucken. Und natürlich, dadurch, dass das Sprachverstehen und die gesprochene Sprache mit integriert ist, wirkt das Ganze schon sehr, sehr mächtig. Dem ist es leider nicht so. Die ersten erfolgreichen Systeme, die wir hatten im Bereich Sprachverstehen, gehen schon weiter zurück. Das war IBMs Watson-System, in dem sie eine Information-Retrieval-Komponente verbunden haben mit einem Sprachverstehen, das Fragen analysiert hat, um mit einer sehr schicken Balance dieser beiden und einem sehr interessanten Ansatz es geschafft haben, so ein Spiel Jeopardy gegen Menschen zu gewinnen. Im Spiel Jeopardy finden Sie ein Faktum vorgelegt und müssen eine Frage dazu geben, die auf das Faktum hinweist. Also man könnte eine Jahreszahl nennen und dann würde man sagen, in diesem was geschah oder wann wurde ein Land entdeckt beispielsweise. Die Systeme verbinden hier, wie man auch sieht, durchaus verschiedene Komponenten der KI, Sprachverarbeitung, Inferenzen, Schlussfolgerungen, wie auch Information-Retrieval. Aber keines dieser Systeme kommt an das heran, was Menschen leisten können. Wenn Sie beispielsweise eines dieser Systeme fragen wollten, wie wenn Sie Harry Potter denken, wo sind die Hockruchse versteckt? Keines der Systeme kann es antworten, denn es steht ja nicht im Text. Man muss es sich zusammensuchen über verschiedene Bücher oder Kapitel. Informationen, die wir zusammen puzzeln, die also Inferenz, Reasoning erfordern, sind den heutigen Systemen nicht zugänglich. Das macht sich sehr deutlich gerade auch, wenn Sie so maschinelle Lernverfahren basierte Systeme nehmen. Auch alleine schon da, wie man sich die Trainingsdatensätze anschaut. Ein großer Datensatz von Stanford, der Open Domain Question Answering mit Machine Learning erreichen möchte, definiert zu sagen, naja, wenn Sie eine Frage haben, ist die korrekte Antwort auf die Frage das Vorlesen des Wikipedia-Ansatzes aus Absatzes, aus dem man die Antwort ableiten kann. Wenn das Sprachverstehen ist, ja, dann ist das erreichbar in kurzer Zeit. Und wenn wir einmal in ein Frage-Antwort-System hineinschauen, dann finden wir was, was wir aus der Wissensrepräsentationsveranstaltung schon kennen. Etwas, das aussieht wie ein semantisches Netzwerk. Es ist dem auch sehr, sehr verwandt, heißt hier Multinet und hat seine Semantik durch eine abstrakte Logik erhalten. Es liegt zugrunde dem Log-Answer-Question-Answering-System, das Uli Furbach von der Universität Koblenz entwickelt hat. Hier sehen Sie Informationen, die aus Wikipedia automatisch, aus dem englischen Wikipedia extrahiert worden sind, die dann in diesem Netzwerk kodiert worden sind. Und aufgrund seiner logischen Semantik, dann sozusagen ein textologischer Konverter, dann mit Inferenzalgorithmen bearbeitet werden kann, sodass auf dem, was hier extrahiert werden konnte, komplexe Fragen beantwortet werden können. Ja, in dem Falle können Sie ja selbst einmal herauspuzzeln, um was es da geht und was man da vielleicht gefragt hat, was man genau mit diesem Ausschnitt des Netzwerkes beantworten kann.)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | results
 Direkt danach folgte der sogenannte erste KI-Winter. Also ich habe in meinem Studium noch sehr viel über KI-Winter gehört, wenn ich es danach, als ich danach recherchiert hatte, finden Sie verschiedene Darstellungen oder auch nicht so prominent die Bezeichnung KI-Winter, aber ich fand das sehr einprägsam. Das waren Anlehnungen an den nuklearen Winter, also wo danach nichts, nach dem Atomkrieg nichts mehr wächst, weil alles zugeschneit ist und keine Sonne mehr auf die Erde kommt. Im Prinzip hat man durch die vielen Versprechungen und die nicht eingehaltenen Versprechungen das Interesse und die Investitionen so geschädigt, dass da erstmal nichts mehr gewachsen ist an KI oder nicht viel. Damals wurde so viel Geld draufgeworfen auf die KI und hat man irgendwann gesagt, also da kommt ja nichts zurück, also wir streichen jetzt alle Forschungsgelder für undirected explanatory research. Also hat gesagt, so hier hast du ein paar Millionen Dollar und forsch mal bitte. Und Sie kennen, heute ist es ja so, heute brauchen Sie immer auch heute noch ein sehr genaues Forschungsziel. Einfach sagen, ich forsche an KI, damit werden Sie wahrscheinlich kein Geld kriegen. Die Probleme damals waren halt auch, dass Sie dann noch eine sehr beschränkte Rechenkraft hatten. Also wir reden hier von den 70ern. Das ist wirklich alles nicht zu vergleichen zu dem, was wir heute an Rechenfrauen haben, allein schon, was wahrscheinlich jeder zu Hause stehen hat. Die Bewegungserkältung der Netzhaut hat man, kann man schätzen, mit circa 1000 Millionen, also eine Milliarden Instruktionen pro Sekunde. Also allein, was die Nervenzellen in Ihrer Netzhaut, nicht mehr hinten im Gehirn, sondern in der Netzhaut leisten, betrifft das um Vielfaches, was die schnellsten Suchcomputer damals konnten. Die hatten nämlich maximal 100 Millionen, also Million Instruktionen pro Sekunde. Und viele Dinge waren dann auch aufgrund der Rechenkraft nicht lösbar. Und das Problem ist auch, wenn Sie sich viele Probleme anschauen, also die von Ihnen, die jetzt schon Algorithmen und Datenstrukturen gehört haben, also Informatiker von Ihnen kennen das, die VZler kennen, wenn sie das nächste Semester hören, vermute ich auch bei mir übrigens, da haben Sie bei ganz vielen Problemen eine kombinatorische Explosion. Also Sie haben ganz schnell auch im echten Leben, gibt es so viele Dinge zu beachten, so viele Variablen, dass Sie so viele Möglichkeiten haben, dass Sie unheimliche Rechenpower brauchen, um das zu lösen. Zum Beispiel Sprachverständnis, wenn Sie versuchen würden, alle möglichen Sätze, die es gibt, auch zu listen. Naja, das wären sehr viele, wenn nicht sogar unendlich viele. Das hat 1980, wurde das oder bildet sich das sogenannte Bora-Wegsche-Paradox, nämlich, dass es vergleichsweise einfach ist, einen Computer dazu zu bringen, Leistungen auf Erwachsenenniveau bei Intelligenztests oder beim Damenspielen zu erbringen. Also Schachcomputer waren damals schon möglich, aber es ist schwierig oder unmöglich, in die Fähigkeit eines Einjährigen in Bezug auf Wahrnehmung und Mobilität zu vermitteln. Also wir denken daran, Schachspielen konnten Computer schon lange, aber Laufen auf zwei Beinen nicht so. Und das ist ja schon seltsam, dass man sagt, man konnte einfach die Sachen, die nur auf Logik basieren, viel einfacher nachbilden, als die Sachen, die andere Dinge als Logik benötigen. Und Hans Moraweg hat das so formuliert, im Allgemeinen sind wir uns am wenigsten bewusst, was unser Verstand am besten kann. Wir sind uns einfacher Prozesse, die nicht gut funktionieren, mehr bewusst als komplexe Prozesse, die fehlerfrei funktionieren. Also wenn ich Sie jetzt fragen würde, also ich gebe Ihnen einen Ball zu, und Sie sollen mir erklären, wie Sie den jetzt fangen, also woher Sie wissen, dass Sie da die Hand hin tun sollen, Sie können es wahrscheinlich auch nicht erklären. Ich könnte es Ihnen auch nicht erklären. Aber wenn ich Ihnen jetzt erkläre, wie Sie, oder wenn Sie mir erklären sollen, wie man eine Ableitung herstellt, mathematische Ableitung, oder wie man den größten gemeinsamen Teil erfindet, das ist relativ einfach zu erklären, aber das ist halt rein logisch. Und das wurde hier als Moraweg-Schutzparadox bezeichnet. In den 80ern gab es dann wieder die ersten kommerziellen Erfolge in der KI. Also Expertensysteme haben sich dann doch ein bisschen durchgesetzt. Es gab die verschiedensten Anwendungen, also R1, später ist es X-Con zur Konfiguration von Macs, das waren auch wieder Rechner. Und das war so, also das hat auch Geld verdient. Das war der erste Beweis, dass KI echt nützlich sein kann. Also auf einmal haben die Firmen da auch was wieder investiert, weil es nicht einfach nur ein Geldgrab war, sondern auch was damit verdienen konnte. Und das hat dazu geführt, dass auch wieder KI im größeren Stil gefördert wurde und viele Firmen eine KI-Abteilung hatten. Dann kam der zweite KI-Winter, das hat sich nämlich herausgestellt, dass sie, wenn sie so ein Expertensystem haben, also wir haben ja gesagt, ein Expertensystem, das basiert auf vielen Regeln von Experten. Und Sie können sich vorstellen, da kommt immer mehr Wissen hinzu. Aber das neue Wissen beeinflusst das alte Wissen. Die Regeln interagieren und deswegen wurde die Wartung immer teurer. Irgendwann haben sie mehr Aufwand gehabt, so ein System zu warten, als sie Zeit hatte. Und da sind die so ein bisschen an ihr Ende gestoßen. Und Desktop-Computer, IBM und Apple wurden schneller als teure Lisp-Computer. Also wir hatten ja vorhin Lisp, also diese Sprache, Lisp-Processing, das war damals quasi das, womit man KI gemacht hat. Während meiner Doktorandenzeit, als ich auch eine Vorlesung KI betreute, hat mein Doktorvater die ersten vier Übungsblätter nur in Lisp machen lassen. Und ich sage Ihnen, das ist kein Spaß. Das artet meistens daran aus, dass Sie die fehlende Klammer suchen, weil Sie haben mehr Klammern als sonst was in dieser Sprache. Wir werden uns das mal anschauen, einfach mal, einfach damit Sie sehen, wie gut Sie es jetzt haben, dass Sie andere Sprachen nutzen können. Das war damals aber das, was man genutzt hat. Und da gab es Firmen, die haben spezielle Computer hergestellt oder programmiert, die nur das konnten. Und dieser Markt ist dann auch eingebrochen. Und es gab in Japan ein großes KI-Projekt, Fifth Generation, hat auch die Erwartung nicht erfüllt, also wieder mal zu große Versprechungen. Und dann ist das Interesse wieder zurückgegangen. 1986 gab es dann auch die Rückkehr der neuronalen Metze. Wie gesagt, hatte Minsky der ganzen Sache so ein bisschen einen Sargnagel, den letzten Sargnagel verpasst und das Interesse ging zurück. Dann hat man aber die sogenannte Backpropagation-Lernung wiederentdeckt. Das wurde schon vorher 1969 von Bryson und Ho entwickelt. Da geht es also darum, wie Sie in einem tiefschichtigen neuronalen Netzwerk oder einem mehrschichtigen neuronalen Netzwerk die Gewichtung, die Verbindung zwischen Neuronen anpassen können. Und also das wurde schon mal entdeckt, aber was hat man da jetzt wiederentdeckt? Und das führte auch zu der Wiederentdeckung oder dem Aufkommen des Konnektionismus als Gegensatz zu symbolischen Ansätzen. Das werde ich später vielleicht noch mal kurz erwähnen, aber um es hier mal zu sagen, wenn Sie, nehmen wir das Beispiel nochmal mit Formelnbeweisen oder solchen Sachen, ableiten, Logik einfach. Sie haben Symbole. Sie haben sowas wie f von x gleich x Quadrat, steht auf Symbolen. Die Symbole sind einfach verarbeitbar. Sie können einfache Regeln anwenden. Es sind wenig Symbole vor allem, wenn Sie aber jetzt eine Bilderkennung haben zum Beispiel und Sie haben eine Kamera, die jetzt nur Voll-HD-Auflösung hat. Dann haben Sie ja Millionen von Pixeln, Millionen von Werten und Sie können nicht jeden einzelnen Wert eine Bedeutung und Symbol zu messen. Und das ist der Konnektionismus, der, wo man gerne unterteilt zwischen symbolischer und sub-symbolischer KI. Symbolisch heißt, Sie haben einzelne Einheiten. Ein Wort ist ein Symbol. Ein Zeichen ist ein Symbol. Und Sie machen Symbolmanipulation. Und beim sub-symbolischen Ansatz, wie in normalen Netzen, haben Sie sehr, sehr viele Zahlen, die in sich keine Bedeutung haben, aber im Zusammenspiel auf einmal intelligentes Verhalten zeigen. Was man ja bei normalen Netzen, vor allem am Deep Learning stark sehen kann, dass dieser Konnektionismus einfach ein sehr guter Ansatz ist. Und normalen Netzen wurden dann wieder mächtiger. Man konnte viel mehr Probleme auf einmal damit lösen. Außerdem wurde die KI empirisch. Die KI war lange rebellisch über der Statistik. Also, wenn Sie so sind wie ich im Studium, dann haben Sie nicht viel Interesse an Statistik oder verstehen es nicht oder mögen es nicht. Und wahrscheinlich ging es den Leuten damals auch so. Und Statistik war ihnen damals zu stringent. Und man hat gesagt, nein, wir machen einfach mal. Wir machen das alles anders. Und die haben sich damit auch ein bisschen davon losgelöst und wollten sich loslösen. Und dadurch wurde KI auch rebellisch mehr, aber isoliert, weil man mit denen nicht gesprochen hat. Man wollte ja alles anders machen. Und nach und nach hat man sich wieder angenähert, weil man gemerkt hat, dass diese klassischen Methoden in der Mathematik, die sind ja alle seit Jahrzehnten, Jahrhunderten teilweise bewiesen. Sie haben sehr, sehr fundierte Grundlagen, auf denen Sie aufbauen können, wo Sie Dinge beweisen können, wo Sie Dinge einfach mal mathematisch herleiten können. Und durch diese Annäherung wurde das Ganze ein bisschen erwachsener. Also empirisch in dem Fall jetzt. Beispiele sind zum Beispiel Hidden Markov Models oder Bayesian Methoden, mit denen Sie auch sehr genau quantifizieren können, wie gut ist Ihre Lösung, wie sicher sind Sie sich Ihrer Lösung. Und das hat der KI nochmal eine neue Richtung verpasst. Ich weiß nicht, was Ihr Jahrgang ist, aber ich habe es noch nicht bekommen. Live damals am 11. Mai 1997 hat der Computer Deep Blue erstmals den Schachgrossmeister, Weltmeister Gary Kasper aufgeschlagen. Und das war damals ein Meilenstein. Wir erinnern uns, ich gehe mal kurz zurück, wir erinnern uns, das hat, haben wir es hier, ja, 1958 hat man gedacht, dass man innerhalb von zehn Jahren den Schachweltmeister besiegt. Hat ein bisschen länger gedauert, sagen wir mal 30 Jahre statt zehn Jahre, aber es hat funktioniert. Und Sie werden es vielleicht wissen, auch damals haben, kann sein. Übrigens auch ein beliebtes Thema, also ein Kommentar ist, dass er nicht gut gespielt hat. Ein Thema ist, oder ein Argument ist, dass die Leute denken, ja, ich spiele Computer so gut, kann ja nicht sein. Und dann spielen sie nicht so gut, wie sie könnten, weil sie den Computer unterschätzen. Ist auch ein Faktor. Ich glaube, in Wahrheit er hat auch dreieinhalb zu zweieinhalb gewonnen. Also es gab sehr viele Unentschieden. Und Gary Kasper hat, glaube ich, sogar vermutet, dass es nicht so war, Dinge nicht mit rechten Dingen zu gehen, dass da vielleicht Menschen geholfen haben. Und trotzdem, das war, also es war schon ein Meilenstein, also es war schon ein Moment in der Geschichte, wo man sagt, oh, jetzt hat ein Computer was geschafft, was man sonst nur nur Menschen, oder wo Menschen besser waren. So ist dann auch passiert, dass nach und nach Computer immer besser wurden, in denen Menschen bisher einfach die Führung hatten. Dazu kommt, dass sie ab den 2000ern die Verfügbarkeit von sehr großen Datensätzen auf einmal haben. Also wir reden jetzt hier nicht von Big Data, aber man hat früher sich auf Algorithmen fokussiert. Ja, wir wollen den Algorithmus verbessern. Man hat dann aber auch gemerkt, dass man mit besseren Daten auch was reißen kann. Und zum Beispiel, also das eine Beispiel, was ich herausgepickt habe, ist das Wort Bank. Bank kann Sitzgelegenheit bedeuten oder Kreditinstitut. Auf der Bank können Sie sitzen oder Sie bringen Ihr Geld auf die Bank. Und jetzt nehmen Sie mal eine Handvoll Sätze und sollen jetzt unterscheiden, also ein Programm schreiben, was entscheidet, welches, was gerade gemeint ist in diesem Satz. Und die Idee war, die Unterscheidung nur anhand von Wortdefinitionen zu machen, also ungelabelten Beispielsätzen und, also nee, anhand von Wortdefinitionen und ungelabelten Beispielsätzen. Also ich gebe Ihnen quasi jetzt die Duden-Definition von Bank und hunderttausende Millionen von Beispielsätzen, wo das Wort drin vorkommt. Und ein mittelmäßiger Algorithmus mit 100 Millionen Wörtern als Trainingsdaten ist besser als der beste Algorithmus mit nur einer Million Wörter Trainingsdaten. Also allein durch die schiere Masse an Trainingsdaten konnten wir das Problem lösen oder erschlagen, was übrigens auch jetzt beim Deep Learning oft vorkommt. Wenn ich lese, was, also wenn Sie mal googlen, was ist Deep Learning, finden Sie auch sehr viele Definitionen, die, sag ich mal, aus Bereichen kommen, die nicht Informatiker sind, wo dann oft gesagt wird, Deep Learning braucht sehr, sehr viele Daten. Das stimmt. Das ist nicht das, aber nicht das, wobei ich Deep Learning definieren würde. Aber hier ist es auch so. Sie haben, wenn Sie die Regelmäßigkeiten erkennen wollen, brauchen Sie viele Daten. Und hier hat sich gezeigt, dass, wenn Sie die Daten besser auswählen und viel mehr Daten haben, Sie auch Probleme teilweise besser lösen können, als wenn Sie einfach nur den Algorithmus verbessern. Und da war auch die Erkenntnis, dass manche Probleme sich besser durch Lernen lösen lassen, als durch handgemachte wissensbasierte Systeme. Das sind auch die beiden Welten. Wissensbasierte Systeme oder viele Algorithmen der KI sind handgemacht, wenn Sie so wollen, Intelligent Design. Sie haben eine Idee und sie programmieren das intelligente Verhalten. Und da ist nichts mehr dem, sag ich mal, dem Zufall überlassen. Das ist alles vorgegeben. Und beim Lernen, auch beim machine learning Lernen, haben sie ein paar Grundregeln definiert, den Rest lernt das System von alleine. Und Umfragen in den 2000ern haben aber ergeben, dass KI immer noch schlecht angesehen war. Da gibt es ein paar schöne Zitate im Economist von Juni 2007. Da hat ein Investor gesagt, also sie wurden von dem Begriff Spracherkennung ein bisschen abgeschreckt, weil es wie das Wort künstliche Intelligenz mit Systemen verbunden wurde, die sehr oft einfach nicht das eingehalten haben, was sie versprochen haben. Patty Tascarella in der Pittsburgh Business Times hat gesagt, manche glauben, dass das Wort Robotik mittlerweile genauso ein Stigma trägt wie KI und die Finanzierung von Firmen sogar schädigt. Stellen Sie sich vor, Sie nennen etwas Blablabla Robotics und Sie wissen ja, dass noch die, die Sachen nicht können. Dann würden Sie auch weniger Geld reingeben. Das ist im Prinzip das Gegenteil davon, was Sie heute teilweise haben, dass Firmen einfach nur irgendwo Bitcoin oder Cryptocurrency in ihren Namen stecken und auf einmal Geld erhalten. Also die Worte waren ein bisschen verbrannt. Und das war sogar so, dass auch jemand gesagt hat in den New York Times, also im Tiefpunkt haben Computerwissenschaftler, also Computer Scientist und Software Engineer den Begriff KI einfach komplett vermieden, einfach weil man Angst hatte, dass man das einfach nur als hingespinzt oder als, naja, als klappt ja eh nicht erkennt oder sieht. Und das hat auch dazu geführt, dass sich dann diese auch viele Teilgebiete der KI ergeben haben, die sich nicht mehr KI genannt haben. Zum Beispiel maschinelles Lernen, kognitive Systeme, wissensbasierte Systeme. Also in den 2000ern, also ich habe ja von 2003 bis 2008 studiert, da war es wirklich noch so, dass ich damals oft dachte, ach, das ist doch eher KI, aber man hat es nicht KI genannt. Wissensbasierte Systeme, Mustererkennung, also Pattern Recognition, einfach weil der Name KI verbrannt war. Und jetzt ist die Frage, was ist der Stand heute? Der KI-Effekt ist, dass mittlerweile sehr viele KI-Anwendungen, also KI-Methoden in die Anwendung geschafft haben und ohne, dass man die KI nennt. Sie haben es gerade eben gehört, weil man KI nicht so toll fand, den Begriff, oder weil er negativ konnotiert war. Und das führt dazu, dass KI jetzt überall ist und man es nicht als solcher erkennt, weil man es auch nicht so nennt. Das Umgekehrte ist auch der Fall. Ich rede, da kommen KI-Chips in Handys und da werden KI-Chips gebaut und eigentlich sind es nur, sage ich mal, in GPUs, also Schleuder-Prozessoren. Aber man nennt es jetzt wieder KI. Aber 2006 hatten sie noch sehr viele KI-Systeme, die man einfach nicht so genannt hat und das hat dazu geführt, dass das nicht so ankam. Also man hat die Erfolge nicht als KI erkannt. Und da hat Marvin Minsky, der lebt leider nicht mehr, das war 2016, ist er gestorben, aber der hat es nochmal zu Wort gewählt, 2011, gesagt, das Paradoxe an der Situation ist, dass jedes Mal, wenn ein KI-Projekt einen Erfolg hatte, eine neue Entdeckung gemacht hat, dass man das schnell, dass es ein Produkt gab, was eine neue Art von, was man als neue Spezialität bei einem Spin-off, neue Methode, neue Richtung erkannt hat oder genannt hat, mit einem eigenen Namen und das man dann nicht mehr mit KI assoziiert hat. Und dann Fragen außenstehende, ja, aber warum macht KI keine Fortschritte? Weil die Fortschritte in lauter Teilgebieten der KI entstanden sind, die manche nicht mit KI assoziiert haben. Und sehr schön ist auch, das gilt auch heute noch von 1970, das Zitat, Intelligenz ist, was auch immer Maschinen noch nicht gemacht haben. Als das erste Mal erklärt wurde oder bekannt wurde, wie die Blue funktioniert, also der Schachcomputer, dass er nämlich einfach, grob gesagt, alle Kombinationen, alle möglichen Züge bis einer gewissen Tiefe durchprobiert, hat man gesagt, das ist ja keine Intelligenz, der probiert ja nur durch. Und so ist es auch jedes Mal, wenn Sie jetzt eine KI programmieren, die irgendwas löst, eine Wegfindung, hier Routenplanung, sonst irgendwas, da heißt es dann, wenn jemand versteht, wie es geht und merkt, das ist ja eigentlich ganz viel Rechnen und ganz viel Mathematik, dann heißt es oft, das ist ja keine Intelligenz. Da sind wir wieder bei diesem Vergleich, kann ein U-Boot schwimmen? Das ist, wenn wir sagen, ja, das ist ja kein Schwimmen in dem Sinne. Und da sagt man, ja, es ist ja kein Denken in dem Sinne. Wieder bei dem Punkt, Intelligentes Handeln und Intelligentes Denken. Intelligentes Denken wird in Programmen einfach auch abgesprochen, aber Intelligent Handeln, naja, soweit sind wir mittlerweile schon. Ich habe diese Folie nochmal, also Verzeihung an die Informatiker, die es schon gesehen haben, die Folie kennen Sie. Ich habe 2015 einen Vortrag gehalten und habe damals diese Folie gemacht, Stand der KI heute, also das ist jetzt schon sechs Jahre alt, einfach um Ihnen auch nochmal den Vergleich zu geben, was hat sich seitdem getan. Das autonom fahrende Auto von Google hat 2015 elf Unfälle auf 1,5 Millionen autonom gefahrenen Kilometern verursacht und an keinem oder war beteiligt gehabt und an keinem davon war das Google Auto selbst schuld. Mittlerweile gibt es ein paar mehr Fälle, wo selbstfahrende Autos schuld waren, aber das war, also dieser Treppenblitz, dass es immer zehn Jahre entfernt ist, kommt langsam zum Ende, weil die KI nun doch schon nah dran ist. Genauso die Spracherkennung. Ich habe es gestern auch schon erzählt. Ich kann mich an Spracherkennung erinnern, dass es nicht funktioniert hat. Trepperquoten von 90, 95 Prozent, also hier ist das zwanzigste Wort falsch und das hat mir damals, war für mich nicht anwendbar. Vor allem auch, weil ich schnell spreche, war für mich die Spracherkennung nie richtig gut. Aber wenn ich jetzt sehe, was mein Handy oder was Amazon Alexa alles erkennt, ist schon sehr beeindruckend. Also auch was für einen Akzente, Genuschel, Dialekte, verschiedene Sprachen, ist schon krass, was es kann und wir sehen sie ja auch in der FAZ von 2014 war auch der Kommentar Spracherkennung. Das war auch die Technik, die nicht perfekt funktioniert hat, oder? Und die Leute waren überrascht, weil sie es auch noch kennen als so klappt es ja auch nicht. Und so wie man von KI-Wintern redet, redet man auch oft vom KI-Frühling, also das ist nach dem Winter kommt der Frühling, dass durch Deep Learning jetzt wieder sehr viele KI-Anwendungen, also sehr viel KI in den Fokus gerückt ist. Es gibt wieder richtigen KI-Hype. Alles ist Deep Learning. Überall heißt es, wir wollen nicht Deep Learning machen. Und das wird auch erfolgreich eingesetzt, wie gesagt, bei Amazon Alexa, Google Sprachassistent, Apple Siri, was sie alles haben. Sie haben Spiele-KIs, die mittlerweile Menschen schlagen. AlphaGo Master hat neue Strategien entwickelt. AlphaGo Zero im selben Jahr entwickelt hat, also beim Go-Spiel, hat sogar erfolgreiche Beispiele gelernt, indem es nur gegen sich selbst gespielt hat und dadurch die Regeln gelernt hat. Und nach nur 40 Tagen, aber immensen Hardware und wahrscheinlich auch Stromkosten, war es besser als alle seine vorherigen Versionen. Und 2019 hat AlphaStar in StarCraft II Großmeisterrang erreicht. Und das ist hier nochmal was anderes, weil das in Echtzeit Strategiespiel ist und nicht rundenbasiert wie Schach oder Go. Also die Frage kam gestern, rundenbasiert heißt ja in dem Fall, sie haben fast beliebig viel Zeit. Sie haben eine gewisse Zeit, ihre Entscheidung, ihren nächsten Zug zu überlegen und dann lässt der Gegner seinen Zug. Und in Echtzeit, während sie überlegen, entwickelt sich die Welt weiter. Das ist der große Unterschied und deswegen ist es nochmal schwieriger, weil sie schnell Entscheidungen treffen müssen und auch während sie Entscheidungen treffen, vielleicht neue Informationen in ihre Entscheidungen einfließen lassen müssen. Und Deep Learning hat viele Durchbrüche verursacht. Also ich habe auch gesehen, ein paar von ihnen haben letztes Semester das Seminar Machine Learning bei Thomas Wieland belegt. Also ein paar von ihnen haben das hier schon mal gesehen vermutlich. Sogenannte Convolutional Neural Networks erkennen Ziffern besser als Menschen, schon seit einigen Jahren, auch Verkehrsschilder glaube ich. Also sie machen weniger Fehler. Es gibt Neural Style Transfer, der den Stil von Gemäden auf Bilder übertragen kann. Das ist auch Deep Learning. Super Sampling erzeugt hochauflösende Bilder aus kleinen Bildern. Sie können also eine kleine Auflösung auf eine hohe Auflösung hochrendern, sagen wir mal voller DO4K. Deep Learning, NVIDIA nennt es DLSS, also vermutlich Deep Learning Super Sampling, aber ich glaube, ich habe einen TM vergessen, der Begriff gehört denen. Deep Fake, wo sie Gesichter auf andere Personen draufsetzen können. Und GANs, also Generative Adversarial Networks, die echt aussehende Fotos erzeugen können und auch ganz viele andere Dinge erzeugen können. Also es gibt die Website This Person Doesn't Exist oder This Cat Doesn't Exist. Und das ist einfach krass, was diese Netzwerke können. Und das selbstfahrende Auto ist jetzt wirklich nur noch wenige Jahre entfernt. Diesmal wirklich.)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | results
 Und dann gibt es irgendwie Probleme, die neue Features haben, mit der dann die Community auf neue Herausforderungen gelenkt werden soll. Ja. Wir haben, hier habe ich mal ein paar von den, ein paar von den Systemen aufgeschrieben. Es gibt, wie gesagt, 50 Benchmark Domains, die uns hier so ein bisschen, die wir kennen, beziehungsweise die wir uns angucken werden, sind einmal die Blockswelt. Dann gibt es FreeSell. Das ist dieses Kartenspiel. Wir haben Logistik, wenn es darum geht zu planen, wo man irgendwie eine Flotte von Lastwagen her schickt, so dass man irgendwelche Güter transportieren kann. Eine, ein ganz interessantes ist dieses Myconic System. Das ist ein Aufzugssteuerungssystem von, das habe ich schon wieder vergessen, Honeywell vielleicht, so was. Wo es darum geht, das ist so ein bisschen wie, wenn man auf dem Weg zum Hitchhiker, wenn man sehr große, wenn man sehr große Gebäude hat, die dann eben so was wie 12 oder so viel Aufzüge hat, dann kann man entweder die Leute warten lassen, bis ein Aufzug in die richtige Richtung geht. Sie kennen das alle von da drüben. Oder aber man kann die Aufzüge planen, um möglichst viel, möglichst effizient die Aufzüge zu bewegen. Das heißt, man hat ein System, das kann man dann auch für Leute vorher ihre Fahrt anmelden. Da würde man dann dahin gehen und dann würde man sagen, ich möchte in den 12. Stock. Und dann sagt das, nimm Aufzug Nummer 6. Okay. Und dann kann das System planen, online, sehr schnell, die Aufzüge besonders auszulasten und natürlich die Wartezeiten für Leute. Zu minimieren. Klassisches Problem, klassisches Planungsproblem, nicht ganz trivial, aber extrem angewandt. Dieses System MyConnect ist in größeren Gebäuden im Einsatz. Heutzutage stellt man sich da mit seinem Smartphone davor und kriegt dann irgendwas, wird dann einem Aufzug zugewiesen und es erlaubt es, Aufzüge zu schweigen. Und dann kann man sich das System auch sparen. Sie können sich vorstellen, bei sehr großen Gebäuden brauchen Aufzüge eine ganze Menge Platz. Platz, den man sonst als Büros nutzen und vermieten könnte. Und wenn man die besser ausnutzt, dann braucht man weniger Aufzüge.)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | results
 Wir erinnern uns, ich gehe mal kurz zurück, wir erinnern uns, das hat, haben wir es hier, ja, 1958 hat man gedacht, dass man innerhalb von zehn Jahren den Schachweltmeister besiegt. Hat ein bisschen länger gedauert, sagen wir mal 30 Jahre statt zehn Jahre, aber es hat funktioniert. Und Sie werden es vielleicht wissen, auch damals haben, kann sein. Übrigens auch ein beliebtes Thema, also ein Kommentar ist, dass er nicht gut gespielt hat. Ein Thema ist, oder ein Argument ist, dass die Leute denken, ja, ich spiele Computer so gut, kann ja nicht sein. Und dann spielen sie nicht so gut, wie sie könnten, weil sie den Computer unterschätzen. Ist auch ein Faktor. Ich glaube, in Wahrheit er hat auch dreieinhalb zu zweieinhalb gewonnen. Also es gab sehr viele Unentschieden. Und Gary Kasper hat, glaube ich, sogar vermutet, dass es nicht so war, Dinge nicht mit rechten Dingen zu gehen, dass da vielleicht Menschen geholfen haben. Und trotzdem, das war, also es war schon ein Meilenstein, also es war schon ein Moment in der Geschichte, wo man sagt, oh, jetzt hat ein Computer was geschafft, was man sonst nur nur Menschen, oder wo Menschen besser waren. So ist dann auch passiert, dass nach und nach Computer immer besser wurden, in denen Menschen bisher einfach die Führung hatten. Dazu kommt, dass sie ab den 2000ern die Verfügbarkeit von sehr großen Datensätzen auf einmal haben. Also wir reden jetzt hier nicht von Big Data, aber man hat früher sich auf Algorithmen fokussiert. Ja, wir wollen den Algorithmus verbessern. Man hat dann aber auch gemerkt, dass man mit besseren Daten auch was reißen kann. Und zum Beispiel, also das eine Beispiel, was ich herausgepickt habe, ist das Wort Bank. Bank kann Sitzgelegenheit bedeuten oder Kreditinstitut. Auf der Bank können Sie sitzen oder Sie bringen Ihr Geld auf die Bank. Und jetzt nehmen Sie mal eine Handvoll Sätze und sollen jetzt unterscheiden, also ein Programm schreiben, was entscheidet, welches, was gerade gemeint ist in diesem Satz. Und die Idee war, die Unterscheidung nur anhand von Wortdefinitionen zu machen, also ungelabelten Beispielsätzen und, also nee, anhand von Wortdefinitionen und ungelabelten Beispielsätzen. Also ich gebe Ihnen quasi jetzt die Duden-Definition von Bank und hunderttausende Millionen von Beispielsätzen, wo das Wort drin vorkommt.)
2025-10-19 22:56:30 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | retrieval 15)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | results
 Okay. On to the new stuff. So. I would like to tell you a little bit about what this funny animal artificial intelligence might be. And I'll reveal to you that we really, really don't know ourselves. And I'll try to answer these kind of questions. What is AI? What have we achieved? We're going to take a very quick walk through the topics we're going to cover this semester. And of course, with all that talent in the room, I'm going to make a very quick advertisement about this stuff. You can do research about in my group. There must be some advantage of me actually standing up in front of you. Good. So, what is AI? There's a couple of definitions. Wikipedia has one. AI is intelligence exhibited by machines. Big surprise. Now. Philostomies. Philosophically, that's fine. All right. It basically says it's artificial, i.e. exhibited by a machine. Intelligence. Now, if I told you here's the definition, go and build AI. Would you know what to do? No. I wouldn't either. All right. It's a nice definition. But it's not, if you think about it, operational. All right. There are definitions. There are definitions where you know exactly what to do. This one isn't one of those. You can find that beautiful or you can find it annoying. All right. So, there are other definitions. AI is a subfield of computer science that is concerned with automation of intelligent behavior. Now, that has a little bit more information. It basically says, truly or falsely, it's a field of computer science. Right? We're not building AI by teaching anthills to do certain things, which one could think is a good way of arriving at AI. And some people do think that. Right? You may have heard about swarm intelligence and all of those kind of things. That's not what we're doing. We're using computers. Helpful. But then the rest is kind of automation. Right? Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. A definition that I like is due to Elaine Rich, which says AI studies how we can make the computer do things that humans still do better at the moment. It's slightly more operational. It basically tells us what we don't have to do, i.e. what is not AI. Right? There are certain things like regulating the temperature in a room that a thermostat does very well, thank you very much. Right? So that's not AI. That's, I don't know, domestic engineering or whatever. There are a lot of, I've been advertising these seats in the front here without much success. But there is place here and you can actually reach it without climbing. You can reach it without sitting over anybody. Okay? So for some parts of AI, I'm going to adopt Elaine Rich's definition. It's slightly problematic. And that's also something you can like or not. But it describes reality pretty well. AI is... It's somewhat the study of problems that are just too hard to be actually solved. Right? We haven't solved the AI problem after 70 years of trying. The wonderful thing is we've developed loads of very, very useful stuff. Many of the things that we're calling computer science nowadays started out as AI. Right? Including things like functional programming languages. Right? That are just in the age of parallelism are making a great contribution. They were invented because the old imperative languages weren't actually cutting it when you were trying to build systems or programs that would build... Would build... Would build... Would build... Would build... Would build... Intelligent behavior. Intelligent behavior. Parallel programming was actually very much driven forward by AI. And many other things. We're going to see a couple this semester. Constraint programming. Constraint solving is an old AI problem. Planning, which some people think is no longer AI because we are pretty good at it. We're pretty good at planning stuff. You could not actually be successful in the Ukraine War if you didn't have very complex planning algorithms that tells you where to move your trucks and your tanks and all of those kind of things. They do it automatically. Scheduling is something that I still remember being done with... I think it was a computer science thing. I think it was a computer science thing. I think it was a computer science thing. I think it was a computer science thing. They had these wonderful big boards that had all these little loads and loads and loads of little tiny paper pockets in them and you could stick nice and colorful cards in them and then you would have people standing in front of this board for two weeks trying to schedule where which course went. We can do this now by pressing a button. Okay? So, all of those things which are now considered engineering and have been taken over by the engineers are not considered AI anymore. So AI is kind of always stuck in this corner of problems that are too hard to solve. I like that corner. The big problems still. We don't know how to solve them. We have lots of crazy ideas of how this might... And the instant we solve a problem, it automatically becomes computer science. It's like pathology in medicine. The department of therapy resistant cases. I think it's important. Okay. And we can have a lot of fun here. But, I think it's important. Okay. But, we also invent lots of things that later become really, really, really well understood as part of computer science. Right. So, this is a definition of AI. The main problem in this, and you will have noticed, is that the last definition here is the only one. That... I'm laughing right now. This is IT. The last... So if you believe that hemos, the first one was the yo-yo depression, right, ago a long time ago. And this is what boobs means then. To evaluate intelligence class. What Robinson has written about intelligence class. Now, right here. Here is time period that not all psychiatrists can follow. So, all of you can wanna adapt this. Then obviously Share practiced intelligence effectively here. What it should do no less, is to apply зал of intelligence classes... It is not a set list, but is still an integral part of the program and does effectively satisfy its use. We now we've got a final statement that points out what is intelligent. We don't have enough ideas to explain. This has to do, these are the images you see here, exist. You can define intelligence as... knowing what intelligence is, they'll tell you, I know it when I see it, but I cannot define it. Okay, and if you press them really hard about what intelligence is, then they say, well, it's that what an intelligence test measures. Right, you can pull your hair out at this answer. Right, so, but Elaine Rich's definition, and that's why I like it, actually gets by without saying anything about intelligence. So, we can also try and look at artificial intelligence by saying, well, what are the components of artificial intelligence? And I'm going to give you five that we're pretty sure are part of intelligence. Not all of them we thought would be there 50 years ago. So, one of the things that we do consider part of AI, and necessary and important component, is the ability to learn. Right, everything that we would probably call intelligence. Right, we'll see other things. The ability to learn has some kind of an ability to learn. Ambrose Cherlency, who's doing a lot of writing here, he's also on the Library ofction Board. Just some time ago, in the last session in university. I can tell you by looking in the round table at the UE steak, and all that stuff about magic and most of these details don't get in. One thing I remember from reading over work until now, even something like the meme 그 I learned in Poland, that isn gruenbos bora, is that if you put out more of those words as your report, right. So learning seems to be important. Inference. The ability to process knowledge and to come up with things we consider to be true or valid from other things that we consider true or valid is an important thing in AI. Humans do it.)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | results
 Dieser Audiobeitrag wird von der Universität Erlangen-Nürnberg präsentiert. So, es ist nach. Ich erhoffe mich, dass auch in der zweiten Vorlesung noch viele da sind. Ich fange ja jetzt immer an, die ganze Sache, dass ich durch die Folien vom letzten Mal nochmal durchgehe, ein bisschen schneller als das letzte Mal und hoffe, dass ich Ihnen dazu dadurch einen Anhaltspunkt geben kann, vielleicht noch Fragen. Ich hoffe, dass ich die Erinnerung wieder zurückkomme und dann können wir das. Das ist vollkommen okay, deswegen machen wir das. Außerdem möchte ich... Ich will nicht die Sachen zu sagen, die ich beim letzten Mal vergessen habe. Und das so ein bisschen zusammenzufassen. Doch, richtig. Wir haben uns nochmal unterhalten darüber, wie am Anfang des letzten Semesters, uns zu fragen, was ist denn KI? Und dann hatten wir uns einige Definitionen angeguckt. Und... Im Prinzip das Wichtigste, was dabei rauskommt, egal wie man es macht, ist, dass man irgendwie so ein paar Komponenten hat, hat der Intelligenz, die man irgendwie versuchen muss abzudillen. Typischerweise intelligente Verhalten entsteht dadurch, dass man lernt, dass man Schlüsse ziehen kann, dass man die Umwelt wahrnehmen kann und bei Menschen auch die Sprache versteht. Und natürlich ist es die ganze Ebene der Emotionen, die man immer stärker sieht in letzter Zeit. Sehr starke Rückwirkungen auf all diese anderen Dinge hat. Am Anfang der künstlichen Intelligenz war es irgendwie so, dass man Emotionen und Geologien versucht hat, sie aufzulassen, weil man dachte, das ist so eine der Sachen, die man natürlich nicht braucht. Ja, das kommt einem im Wesentlichen in die Quere. Aber man versteht immer besser, dass Emotionen ihren Sinn haben und uns Möglichkeiten eröffnen. Und da sind wir. Ich habe sie versucht zu überzeugen, dass wir uns nicht nur in der Klinik verhalten, sondern auch in der Technologie verhalten. Und das ist das, was wir KI an allen Ecken und Enden sehen. Zwar nicht nach der Definition von Elaine Rich, nämlich KI ist das, was Menschen noch besser können. Demnach gibt es keine angewandte KI. Das fände ich ein bisschen traurig. Aber zumindest, wenn man sich die Dinge anguckt, wo sie denn herkommen, kommen sie irgendwie aus einer KI-Umgebung. Da sind ja sehr viele autonome Systeme, autonome Gefährte, die irgendwo rumfahren. Zum Beispiel auch im Mazda, das ist wichtig, weil wir keinen haben, der sie steuern kann. Zum Beispiel auf unseren Autobahnen, wo Menschen einfach teuer sind. Die Lastwagenindustrie, die sind wahnsinnig interessiert daran, selbstfah versucht, eine Lastwagen-Helden-Kette zu haben. braucht man weniger Lastwagenfahrer zu bezahlen. Deswegen hoffentlich dann, wenn es eine ganz neue Generation von Lastwagen abgesetzt werden kann, weil die Speditionen irgendwie auch die Gehälter der Fahrer verzichten können wollen. Und weil natürlich Computer keine Ruhezeiten einzuhalten brauchen. Menschen dürfen nur irgendwie acht Stunden fahren, während Computer vermutet man keine Ruhezeiten brauchen. Solche Sachen. Ersatz von menschlichen Fähigkeiten. Solche Arme. Hilfe im Haushalt. Hilfe bei der Altenpflege wird wahrscheinlich sehr wichtig für einen Landpflegenumstand. Eine der Möglichkeiten ist, nicht Polinen zu importieren, sondern solche da. Ob das natürlich die Alten besonders nett finden, ist die Frage. Das könnte irgendwann mal kostenlos werden. Weiter in der Medizin, gewisse Operationen werden heutzutage, zumindest in den USA, routinemäßig von solchen Monstern durchgeführt. KI-Algorithmen in Sicherheit, in Netzsicherheit, solche Dinge, Gefahren. Überall da sind diese Algorithmen. Und Repräsentationsmechanismen. Und natürlich, es gibt immer mal wieder große spektakuläre Dinge. Zum Beispiel das Kotzen der Körpergegewinne. Oder eben die AlphaGo gegen das im Prinzip letzte Spiel, das letzte Brettspiel. Das letzte Brettspiel jetzt. Die Maschinen besser sind. Wir haben im letzten Semester einen Teil von AlphaGo angeschaut. Wie das funktioniert. Und der andere Teil, mit elasticem Lärm, den wollen wir uns dieses Mal im Semester anschauen. Gut. Also KI ist die typische Wissenschaft, ich will mal sagen, der Therapie-resistenten Fälle. Alles was zu schwer ist für die Informatik, das ist in der KI. Und alles was in der KI gelöst wird, wird dann irgendwie in die Kerninformatik gehabt. Das wird ein eigenes Feld. Das heißt nicht, dass es nicht eben viel mit Dingen, die gut sind in der Informatik gibt, die nicht aus der KI kommen. Selbstverständlich. Ja. Aber es gibt schon drin so eine Art Pipeline.)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | results
 Wir können gewisse Teilfunktionen der menschlichen Intelligenz annähern, zum Teil sogar übertreffen, zum Beispiel beim Multiplizieren großer Zahlen. Menschen längst nicht mehr so gut. Wie Maschinen. Aber, so dieses Problem, der Flexibilität des Geistes, oder auch überhaupt unsere Fähigkeit, des Selbstbewusstseins, über sich selber nachzudenken. Stellen Sie sich mal vor, wenn Ihr Computer plötzlich sagt, ich denke, also bin ich. Ja, ich glaube, da sind wir noch eine Weile von entfernt. Was für mich eigentlich nur heißt, ob ich nur so eine Beziehung habe, oder ob ich nur so eine Beziehung habe, ob ich nun persönlich glaube, the brain happens to be a meat machine. Also im Prinzip könnten wir KI machen, wenn wir denn schlau genug wären. Oder, ob ich das Gefühl habe, es geht im Prinzip gar nicht, aber es ist nützlich, manche Funktionen nachzubilden. Das ist relativ unwichtig. Wir können Spezialfunktionen, wie zum Beispiel Go spielen, können wir, das ist empirisch klar, können wir nachbilden. Und wir können auch noch weiter danach streben, künstliche Intelligenz zu bauen. Aber letztlich sind es Anwendungen wie diese, vielleicht nicht wie diese, vielleicht eher wie diese, die dann hinterher, ihnen den Job sichern. Während sie anderen Leuten die Jobs wegrationalisieren. Oder Sachen besser machen. Ich meine, es ist ja nicht nur so, gewisse Jobs sind ja, ist ja ganz gut, wenn die wegfallen. Bei VW Lackierer zu sein, war eine extrem gesundheitsschädliche Geschichte. Da ist es gut, wenn man plötzlich Industrieroboter hat, die eben nicht anstecken, sondern die dann auch wieder in die Hand nehmen. Und das ist ja auch ein ganz wichtiger Punkt. Die eben nicht atmen müssen. Und deswegen diese ganzen, die dann nicht so gesundheitlich geschädigt werden. Das sind ja auch gewisse Tätigkeiten, die bisher Menschen gemacht haben. Ist ja ganz gut, wenn wir die nicht mehr machen müssen. Weil sie zu gefährlich sind. Eine interessante Sache ist, dass wahrscheinlich jetzt in den nächsten Monaten die ersten verkehrszugelassenen, selbstfahrenden, total autonomen Autos, auf öffentlichen Straßen werden wahrscheinlich in Deutschland zugelassen.)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | results
 I'll conclude with a brief description of an ethical design process and then we'll summarize. In this session we'll look at a set of 11 central ethical problems which result from computer science in general and artificial intelligence specifically. This is not a complete list but the problems are quite fundamental. We'll also learn about a proposal for a more ethical development process. The first ethical problem of artificial intelligence is a problem that all of computer science creates. It's the problem of automation. In particular automation means loss of jobs. And the reason is machines work more cheaply, machines never sleep, machines get no salary, take no sick days, are never even on vacation or on maternity leave. Machines also work faster and more consistent than humans. And together this is a very compelling financial proposition to replace humans by machines. Wherever this is possible and in a free market economy there will be a natural pressure to reduce cost at all times in order to be more competitive. And once one player starts adopting such a policy then others may be induced to do the same. Now it's not just about loss of jobs. Entirely new types of jobs are also created at the same time. For example,たบめ restrai In the past automation happened of mostly physical and menial work and the new thing now is also cognitive tasks can be automated. This time round, jobs like loridriver, maybe a faecesy engineer, attack regulations, profit Renault, maybe a cog movements reviewer, maybe a woman there, yeah, we may do more. But that's just this, there's always room for more and lots more, and that's worth modeling. It's necessary for everybody affected as self-driving cars become available and regulated. And the problem is drivers won't readily be retrained. They may not be able to take on other roles or not willing to do so. And this is a problem because a lorry driver is actually one of the most, if not the most common job in North and South America, but work is about a number of dimensions, it's about the concerns regarding human dignity and one's identity as a worker, so we identify ourselves as the job we do, we give our name and our profession usually when we introduce ourselves, so people can figure out what kind of person we are by learning what we do and of course livelihoods are affected and people have proposed alternatives. Such as universal basic income, UBI, which is the idea of giving everybody a certain sum of money, regardless of whether they work or not. And these issues do not solve the issue of meaning of work or identifying with work.)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | results
 I'll conclude with a brief description of an ethical design process and then we'll summarize. In this session we'll look at a set of 11 central ethical problems which result from computer science in general and artificial intelligence specifically. This is not a complete list but the problems are quite fundamental. We'll also learn about a proposal for a more ethical development process. The first ethical problem of artificial intelligence is a problem that all of computer science creates. It's the problem of automation. In particular automation means loss of jobs. And the reason is machines work more cheaply, machines never sleep, machines get no salary, take no sick days, are never even on vacation or on maternity leave. Machines also work faster and more consistent than humans. And together this is a very compelling financial proposition to replace humans by machines. Wherever this is possible and in a free market economy there will be a natural pressure to reduce cost at all times in order to be more competitive. And once one player starts adopting such a policy then others may be induced to do the same. Now it's not just about loss of jobs. Entirely new types of jobs are also created at the same time. For example, Software developers, Database administrators, Social Media community managers some of which have not been existed as jobs a couple of years ago. In the past automation duration of mostly physical and menial work came now. And the new thing now is also cognitive tasks can be automated. This time around jobs like lorry driver may be anHHH.... algunasóstom that flightiSEE sällbe immer so infinite синk globaland progne créev firing das des komED色 end привieren�sch influenced by Superman. Somehow joblogging in a sector might show up a concrete concern among all. may be affected as self-driving cars become available and regulated. And the problem is drivers won't readily be retrained. They may not be able to take on other roles or not willing to do so. And this is a problem because a lorry driver is actually one of the most, if not the most common job in North and South America. But work is about a number of dimensions. It's about the concerns regarding human dignity and one's identity as a worker. So we identify ourselves as the job we do. We give our name and our profession usually when we introduce ourselves so people can figure out what kind of person we are. By learning what we do, and of course livelihoods are affected and people have proposed alternatives such as universal basic income, UBI, which is the idea of giving everybody a certain sum of money regardless of whether they work or not. And these issues do not solve the issue of meaning of work or identifying with work.)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | results
 Nein, ich bin mir ziemlich sicher, dass es das nicht gäbe. Das würden Sie in den Nachrichten größer sehen. Aber das ist das, was Sie eigentlich immer in der Science Fiction sehen, die starke KI. Deswegen ist auch das vielleicht das, was immer so präsent ist. Also ich bin auch groß geworden mit Knight Rider und ich fand die Idee total toll. Entsprechendes Auto, kann alles möglich machen, hat eine Persönlichkeit. Das hat mich als Kind sehr geprägt. Da habe ich schon mein Interesse an KI entwickelt. Sie kennen es dann vielleicht als nächstes auch. Woran man oft denkt, wenn man an KI denkt, ist Terminator oder in dem Fall Terminator 2. Die Maschinen werden intelligent und unterjochen oder löschen die Menschheit aus. Es ist oft die Angst, wo man sagt, sollten wir wirklich so weit forschen? Was ist, wenn uns die KI irgendwann überflügelt und uns loswerden will? Ist ja sehr, sehr, sehr häufig das Thema in Filmen, also Science Fiction. Aber auch schon viel früher, in einem Film von 1968. Also Sie kennen den Film vermutlich 2001 und ich sehe im Weltraum. Ich will jetzt nicht spoilern, falls Sie den Film schon gesehen haben, aber es geht auch um KI. Ja, genau. Leben in einer Matrix. Auch sehr philosophisch, hat aber erstmal nichts mit KI zu tun. Genau, also Sie sehen, es ist in Science Fiction, es ist sehr weit präsent und wenn es Ihnen so ein bisschen geht wie mir, dann sind Sie dadurch schon beeinflusst. Boston Dynamics, für die, die es nicht kennen, die stellen diese Roboter her und das ist schon, ich sage gerne mal creepy, was die können. Vielleicht als kurzen Datenpunkt dazu. 2009 habe ich an einem, noch als, noch vor meiner Promotion habe ich noch an einem, ja, Kollege hieß das, teilgenommen. Es kann auch für sich vielleicht interessant werden, ich muss mal einen Flyer raussuchen. Das interdisziplinäre Kollege, der geht zu Kognitionswissenschaften, wo auch, wo sehr viel um KI geht oder um alles, was man mit kognitiven Fähigkeiten verbinden kann. Und da waren noch Kollegen oder Kompetenten von der Uni Kaiserlautern da und damals war das zweibeinige Laufen noch nicht gelöst. Es gab damals noch keine zweibeinig laufenden Roboter. Es ging einfach nicht. Also hat man nicht hinbekommen. Und wenn Sie jetzt sehen, was diese Boston Dynamics Roboter können, das ist schon mehr als nur zweibeiniges Laufen. Also es hat in den letzten zehn Jahren wahnsinnige Fortschritte gemacht. Und zu den Fortschritten kommen wir jetzt gleich mal, nämlich einen Überblick. Ich versuche, diesen Überblick hier in dieser Vorlesungsstunde durchzukriegen, damit wir nächste Woche einsteigen können, inhaltlich. Deswegen tut es mir leid, wenn ich nicht auf alles so genau eingehe. Sie können gerne Fragen stellen, wenn es Sie mehr interessiert. Aber das ist auch schon eine sehr, sehr kondensierte Zusammenfassung. Also einmal, das haben die aus GML schon gesehen, also Grundlagen des Maschinenlernens heißt die Vorlesung GML, dass KI selbst ein großes Gebiet ist, was viele Teilgebiete umfasst. Sie haben die ganzen Stichworte vorhin schon gesehen. Sie wollen Wissen repräsentieren. Also Wissensrepräsentation ist ein eigenes Gebiet. Automatisches Schließen ist ein Gebiet. Planen, Problemlösen. Das Maschinenlernen ist ein sehr großes, sehr sichtbares Gebiet. Computervision, jetzt wegen autonomem Fahren in aller Munde. Und natürlich auch für Sprachassistenten die Verarbeitung Sprache oder Automatische Besetzen. Hier nochmal, wie in der anderen Vorlesung, die Disclaimer. Für die meisten Begriffe gibt es englische Fachworte. Die deutschen klingen entweder komisch oder beschreiben das nicht ganz genau, was eigentlich gemeint ist. Deswegen, ich versuche konsistent zu bleiben in Deutsch-Englisch. Aber bitte verzeihen Sie mir, wenn ich dann oft so deutsch-englische Mischtexte habe, einfach weil der englische Begriff auch prägnanter ist und das Thema besser erfasst und Sie unter dem Begriff auch meistens die Literatur finden. KI hat natürlich Überlappungen mit anderen Fächern, mit Big Data, Data Science, Data Mining. Also ich bin auch überrascht, wie viele andere Vorlesungen hier schon Data Mining machen, was sich dann sehr stark mit Machine Learning überdeckt. Nicht ganz das Gleiche ist, aber große Beschneidung hat. Robotik natürlich, wo Sie jetzt natürlich Intelligenz verhalten wollen, wenn Sie autonomes Fahren oder autonome Roboter denken. Ja, sehen Sie jetzt gerade, es ist nicht Curiosity, Perseverance auf dem Mars gelandet und das Ding muss ja teilweise autonom agieren können. Deswegen haben Sie da auch immer KI. Und Sie haben auch die andere Richtung, die Kognitionswissenschaften. Gibt auch teilweise das eigene Studiengang. Das ist eine Mischung aus allem, was halt mit Denken, mit Kognition zu tun hat. Linguistik, Neurowissenschaften, KI, Psychologie. Also da geht es um die Frage, wenn wir hier Denken erforschen, auf eine sehr mathematische Art und Weise, können wir davon Rückschlüsse ziehen, die wiederum in die Psychologie, Pädagogik zurückgehen und natürlich vieles mehr. Also es gibt wahrscheinlich mittlerweile kaum ein Fach, wo es keine Überlappungen gibt. Und jetzt kommt die kurze Geschichte der KI. Einfach, damit Sie mal sehen, wie sich die KI entwickelt hat. Was ich sehr spannend finde, weil es demnach herkommt. Viele Dinge wusste ich halt natürlich auch. Habe ich auch erst in der Uni gelernt. Und es ist sehr interessant, dass man auch mal sieht, was alles schon sehr früh ging und was noch nicht so lange geht. Sie haben schon 1912 den ersten Schachcomputer. Und der wurde entwickelt von Leonardo Torres y Quevedo. Und das ist ein elektromechanischer Roboter. Also es gab damals noch keine Computer in diesem Sinne, wie heute. Der kann das sogenannte K.R.K. Endspiel spielen. Also K.R.K. spielt für König Rook. Rook ist der Turm. Und der gewinnt in maximal 50 Zügen. Und das war für die damalige Zeit schon krass. Stellen Sie sich vor, das ist vor über 100 Jahren, würden Sie mal sagen, ich habe eine Maschine, die kann Schach spielen. Oder einen sehr kleinen Teil von Schach. Dann passierte, sagen wir mal, lange nichts. Was auch vielleicht an diversen Weltkriegen liegen könnte. Aber wie es immer so ist, Kriege haben die Forschung immer beflügelt, weil viel Geld reingeflossen ist. Und 1943 hat jetzt keinen Bezug zum Weltkrieg gehabt. Aber da haben die Warren McCulloch und Walter Pitts das künstliche Neuron, das Konzept entwickelt. Und das kombiniert verschiedene Erkenntnisse. Also Sie müssen sich vorstellen, auch damals, auch über das Gehirn war noch nicht so viel bekannt. Und das hat verschiedene Erkenntnisse kombiniert. Nämlich einmal, dass man das Gehirn als Netzwerk von Neuronen betrachten kann, zur Informationsverarbeitung. Und dass man Aussagenlogik, die es ja schon viel länger gibt als Computer, mit Binärwerten in Digitalrechnern abbilden kann. Und außerdem hat Alan Turing auch wieder mit seiner Turing-Maschine ein hypothetisches Berechnungsmodell entwickelt und gezeigt, dass alle erdenklichen mathematischen Berechnungen durch die Turing-Maschine durchgeführt werden können. Sie kennen vielleicht den Begriff Turing-Mächtig. Wenn nicht, werden Sie den wahrscheinlich noch im Studium hören. Aus diesen drei Erkenntnissen haben die kombiniert, dass jede erdenkliche berechenbare Funktion durch ein Netzwerk künstlicher Neuronen berechnet werden kann. Und außerdem schlugen die beiden vor, dass man solches Netzwerk auch durch Anwendungen geeigneter Regeln trainieren kann und dass es lernen kann. Das war damals schon, also das war der Vorschlag. Und sechs Jahre später hat dann Donald Hebb eine einfache Lernregel gezeigt. Ich hätte es genannt Hebb'sche Lernregel, die einfach sagt, wenn zwei Neuronen, also Neuronen sind Zellen, die verbunden sind, das ist die einfache Fassung, wenn zwei verbundene Neuronen gleichzeitig aktiv sind, dann wird die Verbindung zwischen beiden gestärkt. Das ist die Hebb'sche Lernregel. Und damit kann man schon ein paar tolle Dinge zeigen. Wie vorhin schon gesagt, 1950 hat dann Alan Turing den Turing-Test vorgeschlagen. Der hat jetzt ja kein neues Felder KI geöffnet oder hat eine neue Lösung präsentiert. Aber er hat eine sehr schöne Messlatte gesetzt, die bis heute nicht erreicht wurde, wie man eventuell Intelligenz abtesten kann. Und 1951 haben Marvin Winsky und Dean Edmonds SNARK gebaut. Das ist der Stochastic Neural Analog Reinforcement Calculator. Das war der erste Neural Network Computer. Der bestand noch aus Röhren. Und der simuliert ein Netzwerk aus 40 Neuronen. Wahnsinn. Also für die damalige Zeit war das ein Novum natürlich. Heute wird man müde über Lachen. Und 1955 haben Alan Newell und Herbert A. Simon den Logic Theorist programmiert. Der konnte zum Beispiel, also das war natürlich sehr rein logisch, hatte jetzt nichts mit Neuronen zu tun. Aber der konnte schon 38 von 52 Theoremen aus einem Buch namens Prinzipia Mathematica beweisen, was für die damalige Zeit auch schon sehr beeindruckend war. Er hat wohl sogar für einige Theoremen einen eleganteren oder kürzeren Beweis gefunden. 1956 wird im Allgemeinen oder von vielen als das Jahr als die Geburt der KI betrachtet. Dann hat John McCarthy die Datenaufkonferenz in Hanover, New Hampshire, also nicht das deutsche Hannover, initiiert und hat da Leute eingeladen, denen er noch viel zugetraut hat im Bereich KI, oder die Namen hatten. Unter anderem Marvin Minsky, Claude Shannon, Alan Newell, Herbert A. Simon. Viele von den Namen haben es bestimmt schon mal gehört, oder Sie werden sie noch öfter hören. Und es standen folgende wichtige Aussagen als Ergebnis dieser Konferenz. Nämlich, dass sämtliche Eigenschaften der Intelligenz in Form abstrakter Modelle präzise beschreiben lassen. Das ist ja erst mal eine umstrittene These. Also keine klare These, und sie könnte umstritten sein. Also auch heute, wenn es auch Leute gibt, die sagen, Intelligenz kann man nicht nur durch reine Mathematik abbilden. Vielleicht auch einige von Ihnen. Es ist eine offene Frage. Ich bin der Meinung, man kann, aber das war damals schon ein revolutionärer Gedanke. Und auch die Idee, dass Denkprozesse nicht ausschließlich dem menschlichen Gehirn vorbehalten sind. Und dass Computer das beste bekannte außer-menschliches Instrument für diese Denkprozesse sind. Und die Konferenz selbst hat jetzt keine Durchbrüche in der Forschung als Ergebnis gehabt, aber die Leute kannten sich jetzt halt erst mal, konnten zusammen forschen. Also die Big Players damals und haben für viele Jahre das Gebiet der KI dominiert. 1952 bis 1969 wird im Allgemeinen als die Ära des Aufbruchs und Begeisterung bezeichnet. Computer waren neu und man dachte, die können gut rechnen und das war es. Sie kennen vielleicht noch diesen einen Spruch. Ich glaube, das war der Chef von IBM, der gesagt hat, er glaubt nicht, dass mehr als fünf Computer weltweit notwendig sind. Und das war natürlich eine ganz andere Vorstellung von Computern damals als heute. Mein Herd kann ich auf Werkseinstellung zurücksetzen. Also der hat wahrscheinlich mehr Intelligenz als viele Computer aus den 50ern oder 60ern. Und eine häufige Erwartung war damals auf jeden Fall noch, eine Maschine wird niemals X können. Ja, also kann nicht. Maschine wird niemals Schach spielen können. Maschine wird niemals was übersetzen können. Maschine wird niemals Bilder erkennen, autonom fahren, was auch immer. Es gab immer jemanden, der gesagt hat, also das werden Computer nicht können. Mit dem Ergebnis, dass meistens KI-Forscher dann danach eine Maschine gebaut haben, die genau das konnten. Und das wird gerne als die Look-Ma-No-Hands, also guck mal Mama ohne Hände, wäre beschrieben. Weil einfach immer wieder Dinge, wo man sagte, das ist unheimlich schwierig, das geht nicht, gezeigt wurde, ja, hier, wir haben es mal gelöst. Unter anderem, also Sie müssen das nicht alles auswendig kennen, aber Schrödeleau von Terry Reinograd. Die Sprache Lisp, also Lisp Processing von John McCarthy. Das Perzeptron, das werden wir uns vielleicht noch ein paar Mal begegnen von Frank Rosenblatt. Eliza, das sagt Ihnen vielleicht was von Joseph Walzenbaum. Also Eliza war ein, kommt das noch? Nein. Eliza war ein Dialogsystem, also wir konnten damit chatten und es hat Antworten geliefert. Allerdings, es konnte, glaube ich, nur 50 bis 100 verschiedene Antworten und trotzdem hätte man im ersten Moment meinen können, man redet mit einem Menschen, weil es auf sehr, sehr einfachen Regeln basiert hat. Aber heutzutage könnte damit niemand mehr hier das Licht füllen können. Und der General Problem Solver von Alan Newell und Herbert A. Simon, also der sollte wirklich allgemeine Probleme lösen, jedes Problem lösen können. Und naja, danach kam die Ernüchterung. Also die Erwartungen waren halt sehr, sehr groß. Mit so Aussagen wie von 1958, in zehn Jahren werden Digitalcomputer den Weltmeister in den Schach schlagen und in zehn Jahren werden Computer neue mathematische Beweise entdecken und beweisen. Das war 1958, also 1968 wollte man das eigentlich schon geschafft haben. Wir sind jetzt so weit, aber das ist also eher 50 Jahre später als zehn Jahre später. Und Maschinen werden in der Lage sein, innerhalb von 20 Jahren, da war man schon etwas vorsichtiger, jede Arbeit zu machen, die ein Mensch tun kann. Innerhalb einer Generation, also Sie merken schon, man wird immer ein bisschen vorsichtiger, werden wir das Problem oder die Herausforderung, eine KI zu erschaffen, im Prinzip gelöst haben, hat Marvin Minsky gesagt, 1967. Und 1970 noch, also in drei bis acht Jahren, haben wir eine Maschine mit einer generellen Intelligenz ungefähr wie der Durchschnittsmensch, auch von Marvin Minsky. Ja, ich glaube, Spoiler Alert, es hat nicht funktioniert. Aber dieser Running Gag, dass es immer zehn Jahre weit entfernt ist, der hat der KI lange nach, hing ihr lange nach. Und noch ein schönes Beispiel ist die Übersetzung. Man dachte halt damals, also das Übersetzen durch Reihen ist eine taktische Umstellung und die Übersetzung einzelner Wörter ihr Ziel erreichen können. Ich weiß nicht, wenn Sie mal eine andere Sprache gelernt haben oder lernen, also ich nutze teilweise Duolingo einfach, um ein bisschen meine Sprachen oder mein Vokabular zu halten. Und wenn Sie da in die Foren schauen, haben Sie ganz viele Menschen, die wirklich sagen, aber das Wort heißt doch das, warum kann ich es nicht so übersetzen? Ja, die schlagen dann einfach ein Wort nach und sind der Meinung, ja, okay, dann muss ich doch Wörter übersetzen können. Und Sprache ist eben nicht so einfach. Und da gibt es dieses schöne Beispiel, der Satz, the spirit is willing, but the flesh is weak, wurde von dem Programm ins Russische übersetzt und vom Russischen wieder zurück übersetzt. Und das Ergebnis war, the vodka is good, but the meat is rotten. Also, das habe ich oft gelesen. Ich hoffe einfach mal, dass es keine Urban Legend ist, aber das liegt es hier an, dass natürlich die Worte keine eindeutige Bedeutung haben. Also der Geist, Sie kennen, wenn Sie hier von Himbeergeist reden, dann ist es ein Schnaps. Ja, aber der Geist kann genauso gut, der ist Spukgespenst sein oder der Geist, den Sie im Kopf haben, also Bachergeist, der Zeitgeist, also dasselbe Wort hat viele verschiedene Bedeutungen. Und welche hier genau gemeint ist, hängt im Kontext ab. Und das ist viel, viel schwieriger, als man damals dachte. Und Kontext und Hintergrundwissen waren viel wichtiger als gedacht. Und da wurde dann auch die Finanzierung eingestellt 1966, da man einfach keine Erfolge mehr vorzuweisen hatte oder zu erwarten war. 1969 hat dann lustigerweise genau Marvin Minsky einen Sargnagel damals in den neuronalen Netze reingehauen. Der hat nämlich bewiesen, dass das Perzeptron die XOR-Funktion, also exklusives oder, nicht abbilden kann. Vorher hat man doch gemeint, man kann ja alles lernen damit. Und das führt zu rapide Schwindelinteresse an neuronalen Netzen. Er hatte recht, er hat es bewiesen. Aber das Perzeptron, müssen Sie sich vorstellen, das ist ein neuronales Netz, was aus einem Neuron besteht, einem einzigen. Und das XOR sehr wohllösbar ist mit zwei Schichten, ich glaube es reichen, ich glaube drei Neurone reichen aus, ansonsten sind es fünf. Das ist also lösbar, aber es hat damals dazu geführt, dass man dachte, oh neuronaler Netz könnte doch gar nicht so viel und das Interesse ist stark gesunken. Was ansonsten in der Zeit dann stattdessen hoch kam, waren die wissensbasierten Systeme oder auch Expertensysteme genannt. Gibt es auch heute noch. Also man hat einfach jetzt gesagt, also wir haben ja Experten und die haben Wissen und wir müssen dieses Wissen extrahieren und daraus Regeln ableiten, also Heuristiken. Und deswegen gab es damit auch sehr verstärkte Forschung an Wissensrepräsentationen. Also wenn Sie jetzt, was nehmen wir denn mal, sagen wir mal, Sie haben jetzt jemanden in der Versicherungswirtschaft oder Automobilbau, da kenne ich mich ein bisschen mit aus. Sie haben jemanden in Automobilbau und jetzt haben Sie einen Experten und der hat schon 30 Jahre Erfahrung und der sagt dann, nee, also hier brauchen Sie gar nicht mit Aluminium zu kommen, das ist viel zu, keine Ahnung, das geht nicht, da brauchen Sie schon Stahl. Oder nee, hier dürfen Sie gar keinen Kunststoff nehmen, das schwilzt. Und dann fragen Sie ja, was heißt denn hier und dann sagt, naja, wenn die Temperatur über so und so Grad ist, dann brauchen Sie dieses Material. Und solche Regeln kommen dann da langsam, kommen da vielleicht raus. Die hat man gesammelt und das müssen Sie ja irgendwie repräsentieren. Also der Satz, wir haben eben schon gemerkt, Sätze zu analysieren ist nicht so einfach wegen Kontext, deswegen mussten wir das formalisieren. Das heißt, es war sehr verstärkte Forschung daran, wie man Wissen wirklich auch für Computer verarbeitbar darstellt. Und da gab es auch Systeme wie Dendril oder Mycin. Mycin war ein Expertensystem, lassen Sie mich nicht lügen, der Name sagt ja schon, dass es da um Pilze geht und also in der Medizin wurden die teilweise eingesetzt. Mycin war ein Expertensystem von 1972 zur Erkennung, genau, zu Infektionskrankheiten also nicht nur Pilze. Und Sie müssen sich vorstellen, da geben Sie ein paar Ergebnisse von Analysen rein und dann sagt der, oh, es könnte das sein, testen Sie mal das. Und so hat man sich nach und nach dann zur Krankheit vorgearbeitet. Und das war recht erfolgreich. Außerdem hatten Sie dann noch Prolog, eine logische Programmiersprache, haben Sie vielleicht auch schon mal gehört. Also logische Programmiersprachen waren damals sehr in und wir werden ein paar davon auch eventuell alles mal anschauen. Also einfach, dass Sie es mal gesehen haben, auch wenn das heute keine Relevanz mehr hat. Aber Sie kennen vielleicht, es kommt irgendwie mal vor, dass Sie irgendwo so News lesen, dass man irgendwelche alten Informatiker aus der Pension oder aus dem Ruhestand holt, weil sie die einzelnen Programmiersprachen noch können und die Systeme verwalten können, weil es heute einfach nicht mehr beigebracht wird. Das war alles, also wir waren ja vorhin bei 1969 bis 1974, also das sind alles ungefähre Zeitangaben.)
2025-10-19 22:56:31 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 23:27:55 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:32:33 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:39:30 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:41:43 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:44:07 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:47:54 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:52:54 | INFO | tasks.main | Redis server not found, starting it now...
2025-10-19 23:52:55 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-19 23:53:05 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:53:18 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-19 23:55:02 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-19 23:55:34 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:34 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:34 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:34 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:34 | INFO | retrieval.faiss_segments | deduped 13)
2025-10-19 23:55:34 | INFO | retrieval.faiss_segments | 

joined deduped 13)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-19 23:55:35 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:36 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-19 23:55:37 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-19 23:55:38 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-19 23:55:39 | INFO | retrieval.faiss_segments | hits 15)
2025-10-19 23:55:39 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-19 23:55:39 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:05:19 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 00:05:19 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 00:05:29 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:05:36 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:05:42 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:05:53 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:05:53 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:05:53 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:05:54 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:05:54 | INFO | retrieval.faiss_segments | deduped 13)
2025-10-20 00:05:54 | INFO | retrieval.faiss_segments | 

joined deduped 13)
2025-10-20 00:08:28 | INFO | pipelines.chatbot | Hits: 13
2025-10-20 00:08:28 | INFO | pipelines.chatbot | Filtered hits: 9
2025-10-20 00:08:28 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:08:28 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:08:28 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:08:28 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:08:28 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:08:28 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:08:58 | INFO | pipelines.chatbot | No search needed.
2025-10-20 00:09:00 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:09:00 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:09:00 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:09:00 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:09:00 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-20 00:09:01 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-20 00:09:01 | INFO | pipelines.chatbot | Hits: 14
2025-10-20 00:09:01 | INFO | pipelines.chatbot | Filtered hits: 14
2025-10-20 00:10:22 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:10:25 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:10:31 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:31 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:31 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:31 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:31 | INFO | retrieval.faiss_segments | deduped 13)
2025-10-20 00:10:31 | INFO | retrieval.faiss_segments | 

joined deduped 13)
2025-10-20 00:10:31 | INFO | pipelines.chatbot | Hits: 13
2025-10-20 00:10:31 | INFO | pipelines.chatbot | Filtered hits: 9
2025-10-20 00:10:32 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:32 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:32 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:32 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:32 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:10:32 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:10:33 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:10:33 | INFO | pipelines.chatbot | Filtered hits: 8
2025-10-20 00:10:33 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:33 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:33 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:33 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:33 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-20 00:10:33 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-20 00:10:34 | INFO | pipelines.chatbot | Hits: 14
2025-10-20 00:10:34 | INFO | pipelines.chatbot | Filtered hits: 9
2025-10-20 00:10:34 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:34 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:34 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:35 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:35 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-20 00:10:35 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-20 00:10:36 | INFO | pipelines.chatbot | Hits: 14
2025-10-20 00:10:36 | INFO | pipelines.chatbot | Filtered hits: 6
2025-10-20 00:10:36 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:36 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:36 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:36 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:36 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:10:36 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:10:37 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:10:37 | INFO | pipelines.chatbot | Filtered hits: 8
2025-10-20 00:10:37 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:37 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:37 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:37 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:37 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:10:37 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:10:38 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:10:38 | INFO | pipelines.chatbot | Filtered hits: 4
2025-10-20 00:10:39 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:39 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:39 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:39 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:39 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:10:39 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:10:39 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:10:39 | INFO | pipelines.chatbot | Filtered hits: 15
2025-10-20 00:10:40 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:10:40 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:10:40 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:10:40 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:10:40 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:10:40 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:10:41 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:10:41 | INFO | pipelines.chatbot | Filtered hits: 0
2025-10-20 00:12:36 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:12:38 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:12:43 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:43 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:43 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:43 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:43 | INFO | retrieval.faiss_segments | deduped 13)
2025-10-20 00:12:44 | INFO | retrieval.faiss_segments | 

joined deduped 13)
2025-10-20 00:12:44 | INFO | pipelines.chatbot | Hits: 13
2025-10-20 00:12:44 | INFO | pipelines.chatbot | Filtered hits: 9
2025-10-20 00:12:44 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:44 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:44 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:44 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:44 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:12:44 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:12:44 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:12:44 | INFO | pipelines.chatbot | Filtered hits: 8
2025-10-20 00:12:45 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:45 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:45 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:45 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:45 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-20 00:12:45 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-20 00:12:45 | INFO | pipelines.chatbot | Hits: 14
2025-10-20 00:12:45 | INFO | pipelines.chatbot | Filtered hits: 9
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | 

joined deduped 14)
2025-10-20 00:12:46 | INFO | pipelines.chatbot | Hits: 14
2025-10-20 00:12:46 | INFO | pipelines.chatbot | Filtered hits: 6
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:12:46 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:12:46 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:12:46 | INFO | pipelines.chatbot | Filtered hits: 8
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:12:47 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:12:47 | INFO | pipelines.chatbot | Filtered hits: 4
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:47 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:12:48 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:12:48 | INFO | pipelines.chatbot | Filtered hits: 15
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:12:48 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:12:49 | INFO | retrieval.faiss_segments | 

joined deduped 15)
2025-10-20 00:12:49 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:12:49 | INFO | pipelines.chatbot | Filtered hits: 0
2025-10-20 00:13:46 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 00:13:46 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 00:13:55 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:14:05 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:14:08 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:14:13 | INFO | pipelines.chatbot | start
2025-10-20 00:14:19 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:19 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:19 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:19 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:19 | INFO | retrieval.faiss_segments | deduped 13)
2025-10-20 00:14:20 | INFO | pipelines.chatbot | Hits: 13
2025-10-20 00:14:20 | INFO | pipelines.chatbot | Filtered hits: 9
2025-10-20 00:14:20 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:20 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:20 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:20 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:20 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:14:20 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:14:20 | INFO | pipelines.chatbot | Filtered hits: 8
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-20 00:14:21 | INFO | pipelines.chatbot | Hits: 14
2025-10-20 00:14:21 | INFO | pipelines.chatbot | Filtered hits: 9
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:21 | INFO | retrieval.faiss_segments | deduped 14)
2025-10-20 00:14:21 | INFO | pipelines.chatbot | Hits: 14
2025-10-20 00:14:21 | INFO | pipelines.chatbot | Filtered hits: 6
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:14:22 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:14:22 | INFO | pipelines.chatbot | Filtered hits: 8
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:22 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:23 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:23 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:14:23 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:14:23 | INFO | pipelines.chatbot | Filtered hits: 4
2025-10-20 00:14:23 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:23 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:23 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:23 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:23 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:14:23 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:14:23 | INFO | pipelines.chatbot | Filtered hits: 15
2025-10-20 00:14:24 | INFO | retrieval.faiss_segments | retrieval audio)
2025-10-20 00:14:24 | INFO | retrieval.faiss_segments | retrieval gpt)
2025-10-20 00:14:24 | INFO | retrieval.faiss_segments | retrieval texttiling)
2025-10-20 00:14:24 | INFO | retrieval.faiss_segments | hits 15)
2025-10-20 00:14:24 | INFO | retrieval.faiss_segments | deduped 15)
2025-10-20 00:14:24 | INFO | pipelines.chatbot | Hits: 15
2025-10-20 00:14:24 | INFO | pipelines.chatbot | Filtered hits: 0
2025-10-20 00:14:24 | INFO | pipelines.chatbot | end
2025-10-20 00:19:20 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 00:19:20 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 00:19:29 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:19:46 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:19:48 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:25:42 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 00:25:42 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 00:25:58 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:26:00 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:32:01 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 00:32:01 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 00:32:14 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:32:16 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:32:18 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:33:37 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 00:33:37 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 00:33:48 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:33:50 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 00:33:53 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 00:34:05 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 00:34:05 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 00:34:06 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 00:34:07 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 00:34:07 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 00:34:08 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 00:34:09 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 00:34:09 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:43:52 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 08:43:52 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 08:44:04 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 08:44:12 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 08:44:17 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 08:44:42 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:42 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:42 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:44:44 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:44 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:44 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:44:45 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:45 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:45 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:44:48 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:48 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:48 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:44:50 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:50 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:50 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:44:53 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:53 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:53 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:44:54 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:54 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:54 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:44:56 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:44:56 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:44:56 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:15 | INFO | pipelines.chatbot | Search queries: [
  "What is computer science?"
]
2025-10-20 08:45:34 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:34 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:34 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:36 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:36 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:36 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:37 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:37 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:37 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:39 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:39 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:39 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:40 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:40 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:40 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:42 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:42 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:42 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:43 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:43 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:43 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 08:45:45 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 08:45:45 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 08:45:45 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:01:25 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 09:01:25 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 09:01:38 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:01:42 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:01:45 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 09:01:57 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:01:57 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:01:57 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:01:57 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:01:57 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:01:57 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:01:58 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:01:58 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:01:58 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:01:58 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:01:58 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:01:58 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:01:59 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:01:59 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:01:59 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:02:00 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:02:00 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:02:00 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:02:00 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:02:00 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:02:00 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:02:01 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:02:01 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:02:01 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:02:14 | INFO | pipelines.chatbot | Search queries: [
  "What are algorithms?",
  "definition of algorithms",
  "types of algorithms",
  "applications of algorithms"
]
2025-10-20 09:02:32 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:02:32 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:02:32 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:04:29 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics"
]
2025-10-20 09:04:52 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:04:52 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:04:52 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:04:54 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:04:54 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:04:54 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:05:57 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:05:57 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:05:57 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:05:58 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:05:58 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:05:58 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:06:00 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:06:00 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:06:00 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:06:01 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:06:01 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:06:01 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:06:03 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:06:03 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:06:03 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:06:04 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:06:04 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:06:04 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:06:06 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:06:06 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:06:06 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:06:07 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:06:07 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:06:07 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:07:29 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 09:07:29 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 09:07:41 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:07:46 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:07:51 | INFO | pipelines.chatbot | Search queries: [
  "What is artificial intelligence?",
  "definition of artificial intelligence",
  "types of artificial intelligence"
]
2025-10-20 09:08:02 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:02 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:02 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:08:03 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:03 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:03 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:08:03 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:03 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:03 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:08:04 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:04 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:04 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:08:05 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:05 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:05 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:08:05 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:05 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:05 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:08:06 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:06 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:06 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:08:07 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:08:07 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:08:07 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:09:59 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns about artificial intelligence",
  "AI ethics issues"
]
2025-10-20 09:10:43 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:43 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:43 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:10:43 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:43 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:43 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:10:44 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:44 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:44 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:10:45 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:45 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:45 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:10:45 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:45 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:45 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:10:46 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:46 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:46 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:10:46 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:46 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:46 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:10:47 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:10:47 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:10:47 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:05 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 09:26:05 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 09:26:16 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:26:30 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:26:33 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns about artificial intelligence",
  "AI ethics issues"
]
2025-10-20 09:26:55 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:55 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:55 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:56 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:56 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:56 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:56 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:56 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:56 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:57 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:57 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:57 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:58 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:58 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:58 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:58 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:58 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:58 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:59 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:59 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:59 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:26:59 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:26:59 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:26:59 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:42:50 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:44:10 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 09:44:10 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 09:44:18 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:44:30 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 09:44:59 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:44:59 | INFO | pipelines.chatbot | After filtering: 5
2025-10-20 09:44:59 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:44:59 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:44:59 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:00 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:45:00 | INFO | pipelines.chatbot | After filtering: 10
2025-10-20 09:45:00 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:00 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:00 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:01 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:45:01 | INFO | pipelines.chatbot | After filtering: 3
2025-10-20 09:45:01 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:01 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:01 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:01 | INFO | pipelines.chatbot | Before filtering: 14
2025-10-20 09:45:01 | INFO | pipelines.chatbot | After filtering: 7
2025-10-20 09:45:01 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:01 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:01 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:02 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:45:02 | INFO | pipelines.chatbot | After filtering: 5
2025-10-20 09:45:02 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:02 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:02 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:03 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:45:03 | INFO | pipelines.chatbot | After filtering: 3
2025-10-20 09:45:03 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:03 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:03 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:03 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:45:03 | INFO | pipelines.chatbot | After filtering: 9
2025-10-20 09:45:03 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:03 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:03 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:04 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:45:04 | INFO | pipelines.chatbot | After filtering: 13
2025-10-20 09:45:04 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:04 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:04 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:45:05 | INFO | pipelines.chatbot | Before filtering: 14
2025-10-20 09:45:05 | INFO | pipelines.chatbot | After filtering: 6
2025-10-20 09:45:05 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:45:05 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:45:05 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:07 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 09:46:07 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 09:46:19 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:46:22 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:46:24 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 09:46:36 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:46:36 | INFO | pipelines.chatbot | After filtering: 5
2025-10-20 09:46:36 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:36 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:36 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:37 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:46:37 | INFO | pipelines.chatbot | After filtering: 10
2025-10-20 09:46:37 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:37 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:37 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:37 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:46:37 | INFO | pipelines.chatbot | After filtering: 3
2025-10-20 09:46:37 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:37 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:37 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:38 | INFO | pipelines.chatbot | Before filtering: 14
2025-10-20 09:46:38 | INFO | pipelines.chatbot | After filtering: 7
2025-10-20 09:46:38 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:38 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:38 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:38 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:46:38 | INFO | pipelines.chatbot | After filtering: 5
2025-10-20 09:46:38 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:38 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:38 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:39 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:46:39 | INFO | pipelines.chatbot | After filtering: 3
2025-10-20 09:46:39 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:39 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:39 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:39 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:46:39 | INFO | pipelines.chatbot | After filtering: 9
2025-10-20 09:46:39 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:39 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:39 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:40 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:46:40 | INFO | pipelines.chatbot | After filtering: 13
2025-10-20 09:46:40 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:40 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:40 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:46:41 | INFO | pipelines.chatbot | Before filtering: 14
2025-10-20 09:46:41 | INFO | pipelines.chatbot | After filtering: 6
2025-10-20 09:46:41 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:46:41 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:46:41 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:24 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 09:49:24 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 09:49:34 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:49:38 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:49:40 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 09:49:52 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:49:52 | INFO | pipelines.chatbot | Video IDs: {'230', '231', '175', '232'}
2025-10-20 09:49:52 | INFO | pipelines.chatbot | After filtering: 5
2025-10-20 09:49:52 | INFO | pipelines.chatbot | Video IDs: {'230', '175'}
2025-10-20 09:49:52 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:52 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:52 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:53 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:49:53 | INFO | pipelines.chatbot | Video IDs: {'232', '331', '230', '175', '231', '257'}
2025-10-20 09:49:53 | INFO | pipelines.chatbot | After filtering: 10
2025-10-20 09:49:53 | INFO | pipelines.chatbot | Video IDs: {'230', '257', '175', '331'}
2025-10-20 09:49:53 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:53 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:53 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:53 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:49:53 | INFO | pipelines.chatbot | Video IDs: {'230', '231', '232'}
2025-10-20 09:49:53 | INFO | pipelines.chatbot | After filtering: 3
2025-10-20 09:49:53 | INFO | pipelines.chatbot | Video IDs: {'230'}
2025-10-20 09:49:53 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:53 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:53 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:54 | INFO | pipelines.chatbot | Before filtering: 14
2025-10-20 09:49:54 | INFO | pipelines.chatbot | Video IDs: {'230', '231', '175', '232'}
2025-10-20 09:49:54 | INFO | pipelines.chatbot | After filtering: 7
2025-10-20 09:49:54 | INFO | pipelines.chatbot | Video IDs: {'230', '175'}
2025-10-20 09:49:54 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:54 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:54 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:54 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:49:54 | INFO | pipelines.chatbot | Video IDs: {'230', '231', '232'}
2025-10-20 09:49:54 | INFO | pipelines.chatbot | After filtering: 5
2025-10-20 09:49:54 | INFO | pipelines.chatbot | Video IDs: {'230'}
2025-10-20 09:49:54 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:54 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:54 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:55 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:49:55 | INFO | pipelines.chatbot | Video IDs: {'230', '231', '175', '232'}
2025-10-20 09:49:55 | INFO | pipelines.chatbot | After filtering: 3
2025-10-20 09:49:55 | INFO | pipelines.chatbot | Video IDs: {'230', '175'}
2025-10-20 09:49:55 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:55 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:55 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:55 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:49:55 | INFO | pipelines.chatbot | Video IDs: {'232', '230', '175', '231', '309', '300'}
2025-10-20 09:49:55 | INFO | pipelines.chatbot | After filtering: 9
2025-10-20 09:49:55 | INFO | pipelines.chatbot | Video IDs: {'230', '309', '300', '175'}
2025-10-20 09:49:55 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:55 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:55 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:56 | INFO | pipelines.chatbot | Before filtering: 15
2025-10-20 09:49:56 | INFO | pipelines.chatbot | Video IDs: {'246', '232', '230', '175', '31', '327', '86', '334', '269'}
2025-10-20 09:49:56 | INFO | pipelines.chatbot | After filtering: 13
2025-10-20 09:49:56 | INFO | pipelines.chatbot | Video IDs: {'246', '230', '175', '31', '327', '86', '334', '269'}
2025-10-20 09:49:56 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:56 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:56 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:49:57 | INFO | pipelines.chatbot | Before filtering: 14
2025-10-20 09:49:57 | INFO | pipelines.chatbot | Video IDs: {'230', '231', '232'}
2025-10-20 09:49:57 | INFO | pipelines.chatbot | After filtering: 6
2025-10-20 09:49:57 | INFO | pipelines.chatbot | Video IDs: {'230'}
2025-10-20 09:49:57 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:49:57 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:49:57 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:54:29 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 09:54:29 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 09:54:42 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 09:54:49 | INFO | pipelines.chatbot | Search queries: [
  "What is computer science?",
  "computer science definition",
  "computer science overview"
]
2025-10-20 09:55:08 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:55:08 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:55:08 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:55:09 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:55:09 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:55:09 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:55:09 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:55:09 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:55:09 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:55:10 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:55:10 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:55:10 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:55:11 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:55:11 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:55:11 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:55:11 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:55:11 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:55:11 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 09:55:12 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 09:55:12 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 09:55:12 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:42:37 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 10:42:37 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 10:45:04 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 10:45:49 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics"
]
2025-10-20 10:46:14 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:14 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:14 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:14 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:14 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:14 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:15 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:15 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:15 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:15 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:15 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:15 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:16 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:16 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:16 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:17 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:17 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:17 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:17 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:17 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:17 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:18 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:18 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:18 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 10:46:19 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 10:46:19 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 10:46:19 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:01:55 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 11:01:55 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 11:02:14 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 11:02:38 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 11:02:40 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics"
]
2025-10-20 11:02:51 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:51 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:51 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:52 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:52 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:52 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:52 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:52 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:52 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:53 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:53 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:53 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:54 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:54 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:54 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:54 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:54 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:54 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:55 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:55 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:55 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:55 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:55 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:55 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:02:56 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:02:56 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:02:56 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:03:49 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 11:03:49 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 11:04:03 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 11:04:05 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 11:04:09 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics"
]
2025-10-20 11:04:21 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:21 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:21 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:21 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:21 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:21 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:22 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:22 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:22 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:22 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:22 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:22 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:23 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:23 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:23 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:24 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:24 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:24 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:24 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:24 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:24 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:25 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:25 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:25 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 11:04:27 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 11:04:27 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 11:04:27 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:13:18 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 12:13:18 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 12:13:34 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 12:13:42 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 12:13:45 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 12:14:26 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:14:26 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:14:26 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:14:41 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:14:41 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:14:41 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:14:45 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:14:45 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:14:45 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:14:52 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:14:52 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:14:52 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:14:59 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:14:59 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:14:59 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:15:07 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:15:07 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:15:07 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:15:13 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:15:13 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:15:13 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:15:20 | INFO | pipelines.chatbot | 
[FAISS IoU]
2025-10-20 12:15:20 | INFO | pipelines.chatbot | 
[here?]
2025-10-20 12:15:20 | INFO | pipelines.chatbot | [FAISS IoU] [except] failed to select best hit
2025-10-20 12:52:58 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 12:52:58 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 12:53:16 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 12:53:21 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 12:53:25 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 15:37:51 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 15:37:51 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 15:38:20 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 15:38:45 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 16:01:30 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 16:01:30 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 16:01:50 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 16:02:00 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 16:13:04 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 16:13:04 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 16:13:21 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 16:13:32 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 16:13:34 | INFO | pipelines.chatbot | Search queries: [
  "ethical concerns of artificial intelligence",
  "AI ethics issues"
]
2025-10-20 20:20:32 | INFO | tasks.main | Redis server not found, starting it now...
2025-10-20 20:20:33 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 20:21:29 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 20:21:50 | INFO | pipelines.chatbot | Search queries: [
  "ethical considerations of artificial intelligence",
  "AI ethics"
]
2025-10-20 20:22:27 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Hopefully Improve , Process Proposal , What Okay', content='Ethical considerations of artificial intelligence include the need for regular reviews of deployed machine learning models to ensure they do not develop biases over time.\nAn example cited is a Microsoft chatbot that became problematic due to being retrained inappropriately, highlighting the importance of ongoing inspection of adaptive systems.\nA proposal for ethical AI development includes the need for retraining models with more balanced datasets to eliminate algorithmic discrimination against minorities.\nThe passage lists 11 ethical problems connected with AI, including automation, violation of privacy, fairness and algorithmic discrimination, bias, lack of transparency, and intelligent weapon systems.\nThe discussion emphasizes the urgency of addressing these ethical issues and spreading awareness about them.', last_edit_date=None, url='https://faiss.local/audio/230#t=3325', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 3325500, 'start_sec': 3325.5, 'end_ms': 3527820, 'end_sec': 3527.82, 'video_id': 230, 'segment_index': 46}, similarity_score=0.28, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include the need for regular reviews of deployed machine learning models to ensure they do not develop biases over time.', 'An example cited is a Microsoft chatbot that became problematic due to being retrained inappropriately, highlighting the importance of ongoing inspection of adaptive systems.', 'A proposal for ethical AI development includes the need for retraining models with more balanced datasets to eliminate algorithmic discrimination against minorities.', 'The passage lists 11 ethical problems connected with AI, including automation, violation of privacy, fairness and algorithmic discrimination, bias, lack of transparency, and intelligent weapon systems.', 'The discussion emphasizes the urgency of addressing these ethical issues and spreading awareness about them.']), SearchResultBlock(document_title='KI1_[21S] (Artificial Intelligence 1)', section_title='Also , Haben , Deep Learning', content='Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible if a self-driving car causes an accident.\nThere are concerns about bias in AI systems, particularly when machine learning is used for job applications, as it may not account for variations in appearance or background.\nThe potential for autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.\nThere are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like biased image selection on social media platforms.', last_edit_date=None, url='https://faiss.local/audio/175#t=4630', num_tokens=0, block_metadata={'language': 'de', 'index_name': 'audio', 'course_name': 'KI1_[21S]', 'course_term': '2022 SS', 'start_ms': 4630520, 'start_sec': 4630.52, 'end_ms': 4899840, 'end_sec': 4899.84, 'video_id': 175, 'segment_index': 65}, similarity_score=0.278, probability_score=0.0, summary=['Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible if a self-driving car causes an accident.', 'There are concerns about bias in AI systems, particularly when machine learning is used for job applications, as it may not account for variations in appearance or background.', 'The potential for autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.', 'There are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like biased image selection on social media platforms.'])]
2025-10-20 20:22:31 | INFO | pipelines.chatbot |  [0, 1]
2025-10-20 20:22:36 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Algorithm Machine , Machine Learning , Learning Model', content='The lack of transparency in artificial intelligence (AI) is considered a bad thing, as affected parties have a moral right to an explanation of how decisions were made.\nThere is an intuitive expectation from individuals to understand the reasoning behind decisions made by algorithms or machine learning models, especially when those decisions adversely affect them.\nIt is important to address how someone adversely affected by a decision caused by an algorithm or machine learning model can obtain help, rectification, or compensation.', last_edit_date=None, url='https://faiss.local/audio/230#t=1347', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1347660, 'start_sec': 1347.66, 'end_ms': 1412300, 'end_sec': 1412.3, 'video_id': 230, 'segment_index': 23}, similarity_score=0.259, probability_score=0.0, summary=['The lack of transparency in artificial intelligence (AI) is considered a bad thing, as affected parties have a moral right to an explanation of how decisions were made.', 'There is an intuitive expectation from individuals to understand the reasoning behind decisions made by algorithms or machine learning models, especially when those decisions adversely affect them.', 'It is important to address how someone adversely affected by a decision caused by an algorithm or machine learning model can obtain help, rectification, or compensation.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Hopefully Improve , Process Proposal , What Okay', content='Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.\nA notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.\nKey ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.\nThe discussion emphasizes the importance of an ethically guided development and research process for AI.', last_edit_date=None, url='https://faiss.local/audio/230#t=3325', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 3325500, 'start_sec': 3325.5, 'end_ms': 3527820, 'end_sec': 3527.82, 'video_id': 230, 'segment_index': 46}, similarity_score=0.224, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.', 'A notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.', 'Key ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.', 'The discussion emphasizes the importance of an ethically guided development and research process for AI.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Explanation , North Point , Legal', content='Ethical considerations in artificial intelligence include the need for transparency in automated systems, ensuring they do not pretend to be human.\nThere is a call for regulations that require systems to identify themselves as automated.\nThe North Point scandal in Wisconsin serves as a case study highlighting issues of racial bias in algorithmic risk scoring for legal offenders, where the software Compass was found to disadvantage black individuals.\nThe lack of explanation for algorithmic decisions, such as parole denials based on risk scores, undermines legal due process and the ability of individuals to appeal decisions.\nThe secrecy surrounding the algorithms used in such systems, justified as trade secrets, prevents affected individuals from understanding or contesting their scores.', last_edit_date=None, url='https://faiss.local/gpt/230#t=1476', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1476060, 'start_sec': 1476.06, 'end_ms': 1727180, 'end_sec': 1727.18, 'video_id': 230, 'segment_index': 7}, similarity_score=0.238, probability_score=0.0, summary=['Ethical considerations in artificial intelligence include the need for transparency in automated systems, ensuring they do not pretend to be human.', 'There is a call for regulations that require systems to identify themselves as automated.', 'The North Point scandal in Wisconsin serves as a case study highlighting issues of racial bias in algorithmic risk scoring for legal offenders, where the software Compass was found to disadvantage black individuals.', 'The lack of explanation for algorithmic decisions, such as parole denials based on risk scores, undermines legal due process and the ability of individuals to appeal decisions.', 'The secrecy surrounding the algorithms used in such systems, justified as trade secrets, prevents affected individuals from understanding or contesting their scores.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Machine Learning , Because , People', content='Recommender systems can amplify statistical bias and create filter bubbles, where users only see content similar to what they have engaged with before, leading to isolation from contrarian or alternative viewpoints.\nAn ethical issue in AI is the lack of transparency, where affected parties have a moral right to an explanation of decisions made by algorithms or machine learning models.\nThe expectation for clarity in decision-making processes is a natural one, as individuals want to understand why certain outcomes occurred, especially if they are adverse.\nErrors in input data or gaps in systems can lead to significant mistakes, such as poor credit scores affecting access to services.', last_edit_date=None, url='https://faiss.local/gpt/230#t=1209', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1209980, 'start_sec': 1209.98, 'end_ms': 1474540, 'end_sec': 1474.54, 'video_id': 230, 'segment_index': 6}, similarity_score=0.237, probability_score=0.0, summary=['Recommender systems can amplify statistical bias and create filter bubbles, where users only see content similar to what they have engaged with before, leading to isolation from contrarian or alternative viewpoints.', 'An ethical issue in AI is the lack of transparency, where affected parties have a moral right to an explanation of decisions made by algorithms or machine learning models.', 'The expectation for clarity in decision-making processes is a natural one, as individuals want to understand why certain outcomes occurred, especially if they are adverse.', 'Errors in input data or gaps in systems can lead to significant mistakes, such as poor credit scores affecting access to services.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='People , Because , Personalized News', content='Recommender systems can amplify statistical bias, leading to unfair treatment of individuals based on the average income of their area, which may not reflect their actual financial situation.\nThe concept of a "filter bubble" arises from personalized news and content recommendations, resulting in users only seeing content that aligns with their previous engagements, thus isolating them from contrarian or alternative viewpoints.\nA proposed corrective measure is to intersperse personalized recommendations with diversified results to prevent users from becoming increasingly isolated in their views.\nA significant ethical issue in AI is the lack of transparency, where affected parties have a moral right to understand the reasoning behind decisions that impact them.\nThe expectation for clarity and explanations for decisions is a natural human response, and the lack of transparency can lead to distrust and dissatisfaction.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=1199', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1199980, 'start_sec': 1199.98, 'end_ms': 1396220, 'end_sec': 1396.22, 'video_id': 230, 'segment_index': 15}, similarity_score=0.228, probability_score=0.0, summary=['Recommender systems can amplify statistical bias, leading to unfair treatment of individuals based on the average income of their area, which may not reflect their actual financial situation.', 'The concept of a "filter bubble" arises from personalized news and content recommendations, resulting in users only seeing content that aligns with their previous engagements, thus isolating them from contrarian or alternative viewpoints.', 'A proposed corrective measure is to intersperse personalized recommendations with diversified results to prevent users from becoming increasingly isolated in their views.', 'A significant ethical issue in AI is the lack of transparency, where affected parties have a moral right to understand the reasoning behind decisions that impact them.', 'The expectation for clarity and explanations for decisions is a natural human response, and the lack of transparency can lead to distrust and dissatisfaction.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Explanation , Legal , Trade Secret', content='The use of algorithmic scoring in assessing the re-offending risk of criminals raises ethical concerns, particularly regarding racial bias against black individuals.\nThe lack of explanation for how scores are generated means that individuals cannot understand or contest decisions made about their parole, undermining their legal rights and due process.\nThe owner of the scoring software, North Point, claims that the methodology is a trade secret, which prevents transparency and accountability in the legal process.\nThe absence of prior consent in the use of such algorithms is another ethical consideration.\nThere is significant literature discussing these issues in both legal and social contexts, including a recommended ProPublica article from 2016.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=1594', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1594860, 'start_sec': 1594.86, 'end_ms': 1750620, 'end_sec': 1750.62, 'video_id': 230, 'segment_index': 19}, similarity_score=0.209, probability_score=0.0, summary=['The use of algorithmic scoring in assessing the re-offending risk of criminals raises ethical concerns, particularly regarding racial bias against black individuals.', 'The lack of explanation for how scores are generated means that individuals cannot understand or contest decisions made about their parole, undermining their legal rights and due process.', 'The owner of the scoring software, North Point, claims that the methodology is a trade secret, which prevents transparency and accountability in the legal process.', 'The absence of prior consent in the use of such algorithms is another ethical consideration.', 'There is significant literature discussing these issues in both legal and social contexts, including a recommended ProPublica article from 2016.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Artificial Intelligence , Ethical , Computer Science', content='The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.\nIt mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.\nThe first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=0', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 0, 'start_sec': 0.0, 'end_ms': 87560, 'end_sec': 87.56, 'video_id': 230, 'segment_index': 1}, similarity_score=0.207, probability_score=0.0, summary=['The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.', 'It mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.', 'The first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.'])]
2025-10-20 20:22:39 | INFO | pipelines.chatbot |  [0, 1, 2, 3, 4, 5, 6]
2025-10-20 20:22:41 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Hopefully Improve , Process Proposal , What Okay', content='Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.\nA notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.\nKey ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.\nThe discussion emphasizes the importance of an ethically guided development and research process for AI.', last_edit_date=None, url='https://faiss.local/audio/230#t=3325', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 3325500, 'start_sec': 3325.5, 'end_ms': 3527820, 'end_sec': 3527.82, 'video_id': 230, 'segment_index': 46}, similarity_score=0.234, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.', 'A notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.', 'Key ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.', 'The discussion emphasizes the importance of an ethically guided development and research process for AI.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Algorithm Machine , Machine Learning , Learning Model', content='The lack of transparency in artificial intelligence (AI) is considered a bad thing, as affected parties have a moral right to an explanation of how decisions were made.\nThere is an intuitive expectation from individuals to understand the reasoning behind decisions made by algorithms or machine learning models, especially when those decisions adversely affect them.\nIt is important to address how someone adversely affected by a decision caused by an algorithm or machine learning model can obtain help, rectification, or compensation.', last_edit_date=None, url='https://faiss.local/audio/230#t=1347', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1347660, 'start_sec': 1347.66, 'end_ms': 1412300, 'end_sec': 1412.3, 'video_id': 230, 'segment_index': 23}, similarity_score=0.233, probability_score=0.0, summary=['The lack of transparency in artificial intelligence (AI) is considered a bad thing, as affected parties have a moral right to an explanation of how decisions were made.', 'There is an intuitive expectation from individuals to understand the reasoning behind decisions made by algorithms or machine learning models, especially when those decisions adversely affect them.', 'It is important to address how someone adversely affected by a decision caused by an algorithm or machine learning model can obtain help, rectification, or compensation.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Artificial Intelligence , Ethical , Computer Science', content='The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.\nIt mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.\nThe first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=0', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 0, 'start_sec': 0.0, 'end_ms': 87560, 'end_sec': 87.56, 'video_id': 230, 'segment_index': 1}, similarity_score=0.248, probability_score=0.0, summary=['The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.', 'It mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.', 'The first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.'])]
2025-10-20 20:22:44 | INFO | pipelines.chatbot |  [0, 1, 2]
2025-10-20 20:22:49 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Human , Programming Interface , Data Record', content='Ethical considerations of artificial intelligence involve respect for human dignity, preventing the reduction of human subjects to mere numbers or data records.\nThe moral hazard arises when individuals are reduced to numeric identifiers, neglecting the human aspect behind the data.\nCrowdsourcing, exemplified by platforms like Amazon Mechanical Turk, illustrates the ethical problem where workers become nameless and faceless, leading to a lack of personal relationship and duty of care.\nThe abstraction of humans to anonymous resources in AI applications raises significant moral concerns, as it disconnects the human element from the work being performed.', last_edit_date=None, url='https://faiss.local/audio/230#t=273', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 273660, 'start_sec': 273.66, 'end_ms': 427180, 'end_sec': 427.18, 'video_id': 230, 'segment_index': 7}, similarity_score=0.209, probability_score=0.0, summary=['Ethical considerations of artificial intelligence involve respect for human dignity, preventing the reduction of human subjects to mere numbers or data records.', 'The moral hazard arises when individuals are reduced to numeric identifiers, neglecting the human aspect behind the data.', 'Crowdsourcing, exemplified by platforms like Amazon Mechanical Turk, illustrates the ethical problem where workers become nameless and faceless, leading to a lack of personal relationship and duty of care.', 'The abstraction of humans to anonymous resources in AI applications raises significant moral concerns, as it disconnects the human element from the work being performed.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Data , Have Right , About', content='Ethical considerations in artificial intelligence include the lack of seeking prior consent for data usage, which raises moral and legal concerns.\nThere exists a duty to obtain explicit and prior consent from affected persons before actions concerning person-related data, particularly in the EU under GDPR.\nThe analogy is made between medical consent and data consent, emphasizing that individuals should be informed and agree to the use of their data, similar to how patients must consent to medical procedures.\nThe potential for identity theft and the right to a private sphere are highlighted as important ethical issues when sharing personal information.', last_edit_date=None, url='https://faiss.local/gpt/230#t=1727', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1727820, 'start_sec': 1727.82, 'end_ms': 2169900, 'end_sec': 2169.9, 'video_id': 230, 'segment_index': 8}, similarity_score=0.229, probability_score=0.0, summary=['Ethical considerations in artificial intelligence include the lack of seeking prior consent for data usage, which raises moral and legal concerns.', 'There exists a duty to obtain explicit and prior consent from affected persons before actions concerning person-related data, particularly in the EU under GDPR.', 'The analogy is made between medical consent and data consent, emphasizing that individuals should be informed and agree to the use of their data, similar to how patients must consent to medical procedures.', 'The potential for identity theft and the right to a private sphere are highlighted as important ethical issues when sharing personal information.']), SearchResultBlock(document_title='Artificial_Intelligence_II_2023 (Artificial Intelligence)', section_title='Data , Right , All', content="That would be something I dream of when I'm not in front of you. Right? But that's not something I can do. The system doesn't allow it. Right? So, you can be very tempted to sell your competency data to your possible employers. And I'm sure they would be very interested in this. We're not doing that. So, we're trying to keep your data private. Any time we're using your data for generating a guided tour, this is behind a crypto wall. Behind single sign-on. We're very careful about this. And you can at all times see what we know about you. Might be interesting. What your learner model might be. And whenever you feel misrepresented or unfairly treated, you can just delete all the data. But of course, if you do that, all the data is gone. Right? Except, so-and-so purged her own data Friday, 6 o'clock. That's the end of the story. That's a datum we keep. And all of your guided tours are going to look terrible. And your card stacks are going to be huge. Because the system says, oh, this person knows nothing. Let's test her on it. Okay, good. So, right.", last_edit_date=None, url='https://faiss.local/gpt/257#t=4078', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Artificial_Intelligence_II_2023', 'course_term': '2023 SS', 'start_ms': 4078500, 'start_sec': 4078.5, 'end_ms': 4174500, 'end_sec': 4174.5, 'video_id': 257, 'segment_index': 39}, similarity_score=0.215, probability_score=0.0, summary=[]), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Commercially Governments , Certainly Commercially , Maintained Limitations', content='There is a notion of a right to a private sphere, and sharing information can lead to a loss of privacy.\nIt is important to ensure that shared information is properly maintained and that there are limitations on its use, particularly by commercial entities and governments.\nThe General Data Protection Regulation (GDPR) in the EU requires seeking prior consent for the use of personal data and addresses violations of this consent.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=1945', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1945340, 'start_sec': 1945.34, 'end_ms': 1992540, 'end_sec': 1992.54, 'video_id': 230, 'segment_index': 23}, similarity_score=0.236, probability_score=0.0, summary=['There is a notion of a right to a private sphere, and sharing information can lead to a loss of privacy.', 'It is important to ensure that shared information is properly maintained and that there are limitations on its use, particularly by commercial entities and governments.', 'The General Data Protection Regulation (GDPR) in the EU requires seeking prior consent for the use of personal data and addresses violations of this consent.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='People Consent , Other Things , Moral', content="Ethical considerations in artificial intelligence include the need for explicit and prior consent from individuals before storing and using their personal data.\nThere is a moral expectation that individuals should be informed about how their data will be used and given the opportunity to agree or opt out.\nThe establishment of legal frameworks may be necessary to sanction actions taken without individuals' consent, addressing the potential for unethical behavior in data handling.", last_edit_date=None, url='https://faiss.local/texttiling/230#t=1775', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 1775980, 'start_sec': 1775.98, 'end_ms': 1867180, 'end_sec': 1867.18, 'video_id': 230, 'segment_index': 21}, similarity_score=0.214, probability_score=0.0, summary=['Ethical considerations in artificial intelligence include the need for explicit and prior consent from individuals before storing and using their personal data.', 'There is a moral expectation that individuals should be informed about how their data will be used and given the opportunity to agree or opt out.', "The establishment of legal frameworks may be necessary to sanction actions taken without individuals' consent, addressing the potential for unethical behavior in data handling."]), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Human , Data Record , User', content='One ethical consideration of artificial intelligence is the problem of abstraction, which involves respecting human dignity and preventing the reduction of human subjects to mere numbers, such as user IDs or data records.\nThe concern arises when individuals are reduced to numeric identifiers, leading to a moral hazard by forgetting the human being behind the record or user identity.\nAn example of this issue can be illustrated through crowdsourcing, where the focus may shift away from the individual contributions to the collective data.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=264', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 264520, 'start_sec': 264.52, 'end_ms': 331200, 'end_sec': 331.2, 'video_id': 230, 'segment_index': 4}, similarity_score=0.212, probability_score=0.0, summary=['One ethical consideration of artificial intelligence is the problem of abstraction, which involves respecting human dignity and preventing the reduction of human subjects to mere numbers, such as user IDs or data records.', 'The concern arises when individuals are reduced to numeric identifiers, leading to a moral hazard by forgetting the human being behind the record or user identity.', 'An example of this issue can be illustrated through crowdsourcing, where the focus may shift away from the individual contributions to the collective data.'])]
2025-10-20 20:22:53 | INFO | pipelines.chatbot |  [0, 1, 3, 4, 5]
2025-10-20 20:22:57 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Machines , Problem , Lorry Driver', content='The first ethical problem of artificial intelligence is the issue of automation, which leads to job loss as machines can work more cheaply and efficiently than humans.\nAutomation creates pressure in a free market economy to reduce costs, leading to the replacement of human jobs with machines.\nWhile automation results in job loss, it also creates new types of jobs, such as software developers and database administrators.\nThe automation of cognitive tasks, such as those performed by lorry drivers, poses a significant ethical concern, especially since affected workers may not be readily retrained or willing to take on new roles.', last_edit_date=None, url='https://faiss.local/audio/230#t=79', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 79680, 'start_sec': 79.68, 'end_ms': 204160, 'end_sec': 204.16, 'video_id': 230, 'segment_index': 4}, similarity_score=0.301, probability_score=0.0, summary=['The first ethical problem of artificial intelligence is the issue of automation, which leads to job loss as machines can work more cheaply and efficiently than humans.', 'Automation creates pressure in a free market economy to reduce costs, leading to the replacement of human jobs with machines.', 'While automation results in job loss, it also creates new types of jobs, such as software developers and database administrators.', 'The automation of cognitive tasks, such as those performed by lorry drivers, poses a significant ethical concern, especially since affected workers may not be readily retrained or willing to take on new roles.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Machines , Problem , Artificial Intelligence', content='The passage discusses about 11 central ethical problems related to artificial intelligence, including the issue of automation.\nAutomation leads to job loss because machines work more cheaply, do not require salaries, and can operate continuously without breaks.\nWhile automation results in job loss, it also creates new job roles, such as software developers and database administrators.\nThe passage highlights that cognitive tasks can now also be automated, affecting jobs like lorry drivers as self-driving cars become available.\nA significant concern is that affected workers, such as lorry drivers, may not be readily retrained or willing to take on new roles, which poses an ethical dilemma.', last_edit_date=None, url='https://faiss.local/gpt/230#t=37', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 37480, 'start_sec': 37.48, 'end_ms': 204160, 'end_sec': 204.16, 'video_id': 230, 'segment_index': 2}, similarity_score=0.282, probability_score=0.0, summary=['The passage discusses about 11 central ethical problems related to artificial intelligence, including the issue of automation.', 'Automation leads to job loss because machines work more cheaply, do not require salaries, and can operate continuously without breaks.', 'While automation results in job loss, it also creates new job roles, such as software developers and database administrators.', 'The passage highlights that cognitive tasks can now also be automated, affecting jobs like lorry drivers as self-driving cars become available.', 'A significant concern is that affected workers, such as lorry drivers, may not be readily retrained or willing to take on new roles, which poses an ethical dilemma.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Machines , Lorry Driver , Loss Jobs', content='Automation leads to the loss of jobs because machines work more cheaply, do not require salaries, and can operate continuously without breaks.\nThere is a financial incentive in a free market economy to replace humans with machines to reduce costs, which can create pressure on companies to adopt automation.\nWhile automation results in job loss, it also creates entirely new types of jobs, such as software developers and database administrators, which did not exist a few years ago.\nThe automation of cognitive tasks is a new development, affecting jobs like lorry drivers as self-driving cars become available and regulated.\nA significant issue is that lorry drivers may not be readily retrained for new roles, as it is one of the most common jobs in North and South America.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=87', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 87560, 'start_sec': 87.56, 'end_ms': 204160, 'end_sec': 204.16, 'video_id': 230, 'segment_index': 2}, similarity_score=0.282, probability_score=0.0, summary=['Automation leads to the loss of jobs because machines work more cheaply, do not require salaries, and can operate continuously without breaks.', 'There is a financial incentive in a free market economy to replace humans with machines to reduce costs, which can create pressure on companies to adopt automation.', 'While automation results in job loss, it also creates entirely new types of jobs, such as software developers and database administrators, which did not exist a few years ago.', 'The automation of cognitive tasks is a new development, affecting jobs like lorry drivers as self-driving cars become available and regulated.', 'A significant issue is that lorry drivers may not be readily retrained for new roles, as it is one of the most common jobs in North and South America.']), SearchResultBlock(document_title='Künstliche_Intelligenz_II_2017 (Artificial Intelligence)', section_title='Wie Diese , Diese Vielleicht , Ganz Gut', content='The passage discusses the ethical considerations of artificial intelligence, particularly in relation to job displacement and safety.\nIt mentions that while AI can eliminate certain jobs, it can also improve safety by taking over dangerous tasks, such as those performed by industrial workers.\nThe text highlights the potential benefits of AI, such as the introduction of autonomous vehicles, which may be allowed on public roads in the near future.', last_edit_date=None, url='https://faiss.local/texttiling/331#t=2295', num_tokens=0, block_metadata={'language': 'de', 'index_name': 'texttiling', 'course_name': 'Künstliche_Intelligenz_II_2017', 'course_term': '2017 SS', 'start_ms': 2295860, 'start_sec': 2295.86, 'end_ms': 2378860, 'end_sec': 2378.86, 'video_id': 331, 'segment_index': 36}, similarity_score=0.219, probability_score=0.0, summary=['The passage discusses the ethical considerations of artificial intelligence, particularly in relation to job displacement and safety.', 'It mentions that while AI can eliminate certain jobs, it can also improve safety by taking over dangerous tasks, such as those performed by industrial workers.', 'The text highlights the potential benefits of AI, such as the introduction of autonomous vehicles, which may be allowed on public roads in the near future.'])]
2025-10-20 20:23:00 | INFO | pipelines.chatbot |  [0, 1, 2, 3]
2025-10-20 20:23:03 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='KI1_[21S] (Artificial Intelligence 1)', section_title='Also , Haben , Deep Learning', content='Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible when an autonomous vehicle causes an accident.\nThere are concerns about bias in AI systems, particularly in job applications, where machine learning may evaluate candidates based on potentially biased criteria.\nThe development of autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.\nThere are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like image selection algorithms on social media platforms.', last_edit_date=None, url='https://faiss.local/audio/175#t=4630', num_tokens=0, block_metadata={'language': 'de', 'index_name': 'audio', 'course_name': 'KI1_[21S]', 'course_term': '2022 SS', 'start_ms': 4630520, 'start_sec': 4630.52, 'end_ms': 4899840, 'end_sec': 4899.84, 'video_id': 175, 'segment_index': 65}, similarity_score=0.24, probability_score=0.0, summary=['Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible when an autonomous vehicle causes an accident.', 'There are concerns about bias in AI systems, particularly in job applications, where machine learning may evaluate candidates based on potentially biased criteria.', 'The development of autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.', 'There are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like image selection algorithms on social media platforms.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Artificial Intelligence , Ethical , Computer Science', content='The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.\nIt mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.\nThe first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=0', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 0, 'start_sec': 0.0, 'end_ms': 87560, 'end_sec': 87.56, 'video_id': 230, 'segment_index': 1}, similarity_score=0.243, probability_score=0.0, summary=['The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.', 'It mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.', 'The first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.'])]
2025-10-20 20:23:06 | INFO | pipelines.chatbot |  [0, 1]
2025-10-20 20:23:11 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Sensors , Applications Thinkable , Military Applications', content='The passage discusses the ethical considerations of military applications of artificial intelligence, highlighting the use of adaptive technologies in rockets, cruise missiles, and armed drones.\nIt mentions the control loops in these technologies that allow them to compare terrain with digital maps and adjust to environmental changes, raising concerns about the implications of such capabilities in warfare.\nThe passage notes that advancements in AI for military purposes can lead to an arms race, as adversary parties develop similar technologies.', last_edit_date=None, url='https://faiss.local/audio/230#t=2905', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 2905660, 'start_sec': 2905.66, 'end_ms': 2986060, 'end_sec': 2986.06, 'video_id': 230, 'segment_index': 42}, similarity_score=0.238, probability_score=0.0, summary=['The passage discusses the ethical considerations of military applications of artificial intelligence, highlighting the use of adaptive technologies in rockets, cruise missiles, and armed drones.', 'It mentions the control loops in these technologies that allow them to compare terrain with digital maps and adjust to environmental changes, raising concerns about the implications of such capabilities in warfare.', 'The passage notes that advancements in AI for military purposes can lead to an arms race, as adversary parties develop similar technologies.']), SearchResultBlock(document_title='KI1_[21S] (Artificial Intelligence 1)', section_title='Also , Haben , Deep Learning', content='Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible when an autonomous vehicle causes an accident.\nThere are concerns about bias in AI systems, particularly in job applications, where machine learning may evaluate candidates based on potentially biased criteria.\nThe development of autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.\nThere are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like image selection algorithms on social media platforms.', last_edit_date=None, url='https://faiss.local/audio/175#t=4630', num_tokens=0, block_metadata={'language': 'de', 'index_name': 'audio', 'course_name': 'KI1_[21S]', 'course_term': '2022 SS', 'start_ms': 4630520, 'start_sec': 4630.52, 'end_ms': 4899840, 'end_sec': 4899.84, 'video_id': 175, 'segment_index': 65}, similarity_score=0.213, probability_score=0.0, summary=['Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible when an autonomous vehicle causes an accident.', 'There are concerns about bias in AI systems, particularly in job applications, where machine learning may evaluate candidates based on potentially biased criteria.', 'The development of autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.', 'There are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like image selection algorithms on social media platforms.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Know , Actually , Video', content='The ability to create synthetic audio tracks and deep fakes raises ethical concerns about what counts as evidence in news reporting and courtrooms, as realistic digital artifacts can be misleading.\nThe notion of evidence based on digital artifacts like audio or video clips is being challenged by advancements in technology, necessitating a reassessment of legal standards for truth.\nIntelligent weapon systems, which can comprehend, reason, and adapt to their environment, pose significant ethical concerns regarding their potential to cause mass destruction.\nThe development of adaptive military technologies, such as drones and missiles, contributes to an arms race among adversarial parties, raising further ethical implications.', last_edit_date=None, url='https://faiss.local/gpt/230#t=2754', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 2754700, 'start_sec': 2754.7, 'end_ms': 2973900, 'end_sec': 2973.9, 'video_id': 230, 'segment_index': 14}, similarity_score=0.225, probability_score=0.0, summary=['The ability to create synthetic audio tracks and deep fakes raises ethical concerns about what counts as evidence in news reporting and courtrooms, as realistic digital artifacts can be misleading.', 'The notion of evidence based on digital artifacts like audio or video clips is being challenged by advancements in technology, necessitating a reassessment of legal standards for truth.', 'Intelligent weapon systems, which can comprehend, reason, and adapt to their environment, pose significant ethical concerns regarding their potential to cause mass destruction.', 'The development of adaptive military technologies, such as drones and missiles, contributes to an arms race among adversarial parties, raising further ethical implications.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Human , Work , People', content='Ethical considerations of artificial intelligence include concerns regarding human dignity and identity as a worker, as people often identify themselves by their profession.\nThe issue of abstraction in AI raises ethical concerns, as it can reduce human subjects to mere numbers or data records, neglecting the human aspect behind the identity.\nCrowdsourcing platforms, like Amazon Mechanical Turk, exemplify the ethical problem of reducing workers to nameless, faceless entities, which can lead to a lack of personal connection and duty of care.\nThe use of killer drones highlights ethical issues in AI, as operators can cause harm to real human beings from a distance, often without a personal connection to the consequences of their actions.', last_edit_date=None, url='https://faiss.local/gpt/230#t=204', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 204160, 'start_sec': 204.16, 'end_ms': 500700, 'end_sec': 500.7, 'video_id': 230, 'segment_index': 3}, similarity_score=0.225, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include concerns regarding human dignity and identity as a worker, as people often identify themselves by their profession.', 'The issue of abstraction in AI raises ethical concerns, as it can reduce human subjects to mere numbers or data records, neglecting the human aspect behind the identity.', 'Crowdsourcing platforms, like Amazon Mechanical Turk, exemplify the ethical problem of reducing workers to nameless, faceless entities, which can lead to a lack of personal connection and duty of care.', 'The use of killer drones highlights ethical issues in AI, as operators can cause harm to real human beings from a distance, often without a personal connection to the consequences of their actions.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Sensors , Privacy , Kind', content='Ethical considerations of artificial intelligence include the use of adaptive technologies in military applications, such as rockets, cruise missiles, and armed drones, which can adjust to changes in the environment and follow plans while countering attempts to mislead.\nThe development of AI technologies can lead to an arms race among adversary parties, raising ethical concerns about their deployment in warfare.\nThe concept of "Privacy by Design," created by the Canadian Chief Privacy Officer in 2009, has been adapted to address ethical issues in AI, suggesting a framework for responsible AI development.\nThere are numerous ethical issues surrounding AI, with a focus on the responsibilities of those who build systems that may be considered semi-intelligent.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=2905', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 2905660, 'start_sec': 2905.66, 'end_ms': 3049660, 'end_sec': 3049.66, 'video_id': 230, 'segment_index': 36}, similarity_score=0.266, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include the use of adaptive technologies in military applications, such as rockets, cruise missiles, and armed drones, which can adjust to changes in the environment and follow plans while countering attempts to mislead.', 'The development of AI technologies can lead to an arms race among adversary parties, raising ethical concerns about their deployment in warfare.', 'The concept of "Privacy by Design," created by the Canadian Chief Privacy Officer in 2009, has been adapted to address ethical issues in AI, suggesting a framework for responsible AI development.', 'There are numerous ethical issues surrounding AI, with a focus on the responsibilities of those who build systems that may be considered semi-intelligent.'])]
2025-10-20 20:23:16 | INFO | pipelines.chatbot |  [0, 1, 2, 3, 4]
2025-10-20 20:23:20 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Hopefully Improve , Process Proposal , What Okay', content='Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.\nA notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.\nKey ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.\nThe discussion emphasizes the importance of an ethically guided development and research process for AI.', last_edit_date=None, url='https://faiss.local/audio/230#t=3325', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 3325500, 'start_sec': 3325.5, 'end_ms': 3527820, 'end_sec': 3527.82, 'video_id': 230, 'segment_index': 46}, similarity_score=0.261, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.', 'A notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.', 'Key ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.', 'The discussion emphasizes the importance of an ethically guided development and research process for AI.']), SearchResultBlock(document_title='Artificial_Intelligence_I_2022-2023 (Artificial Intelligence)', section_title='Very Very , Ethics , Meta Level', content='Ethics is a very important topic in the context of artificial intelligence.\nThere are seminars on the ethics of AI and philosophy of AI being conducted.\nA Humboldt professor, well-regarded in the ethics of AI, has been hired to give a course on ethics in AI in the next summer.\nIt is encouraged for engineers and scientists to consider the ethical implications of their work in AI.', last_edit_date=None, url='https://faiss.local/audio/315#t=2163', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Artificial_Intelligence_I_2022-2023', 'course_term': '2022-23 WS', 'start_ms': 2163280, 'start_sec': 2163.28, 'end_ms': 2250280, 'end_sec': 2250.28, 'video_id': 315, 'segment_index': 22}, similarity_score=0.26, probability_score=0.0, summary=['Ethics is a very important topic in the context of artificial intelligence.', 'There are seminars on the ethics of AI and philosophy of AI being conducted.', 'A Humboldt professor, well-regarded in the ethics of AI, has been hired to give a course on ethics in AI in the next summer.', 'It is encouraged for engineers and scientists to consider the ethical implications of their work in AI.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Ethics , Process , What', content='Ethical considerations in artificial intelligence should be proactive rather than reactive, meaning ethics should be built into the system from the beginning.\nEthics should be the default setting in AI development, not an afterthought or something added later.\nEthical norms should be embedded throughout the entire development process, ensuring that ethics are present at every stage.\nThe process of developing AI systems should be visible, transparent, and respect user values.\nIt is suggested that companies implement an ethics approval board similar to institutional review boards used in research, which would have the authority to approve or veto projects at various checkpoints in the development process.', last_edit_date=None, url='https://faiss.local/audio/230#t=2986', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 2986780, 'start_sec': 2986.78, 'end_ms': 3188300, 'end_sec': 3188.3, 'video_id': 230, 'segment_index': 43}, similarity_score=0.259, probability_score=0.0, summary=['Ethical considerations in artificial intelligence should be proactive rather than reactive, meaning ethics should be built into the system from the beginning.', 'Ethics should be the default setting in AI development, not an afterthought or something added later.', 'Ethical norms should be embedded throughout the entire development process, ensuring that ethics are present at every stage.', 'The process of developing AI systems should be visible, transparent, and respect user values.', 'It is suggested that companies implement an ethics approval board similar to institutional review boards used in research, which would have the authority to approve or veto projects at various checkpoints in the development process.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Ethics , Product Development , Approval Board', content='Ethical considerations in AI should be proactive rather than reactive, meaning ethics should be built into the design process from the beginning.\nEthics should be the default setting in AI development, not an afterthought added later.\nThe process of developing AI systems should be transparent and respect user values, with ethics being present throughout the entire development pipeline.\nAn ethics approval board should be consulted before starting research projects, similar to institutional review boards used in universities for experiments.\nCheckpoints for ethical review should be implemented at various stages of the development process to ensure ethical considerations are addressed before products are deployed.', last_edit_date=None, url='https://faiss.local/gpt/230#t=2974', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 2974940, 'start_sec': 2974.94, 'end_ms': 3516220, 'end_sec': 3516.22, 'video_id': 230, 'segment_index': 15}, similarity_score=0.258, probability_score=0.0, summary=['Ethical considerations in AI should be proactive rather than reactive, meaning ethics should be built into the design process from the beginning.', 'Ethics should be the default setting in AI development, not an afterthought added later.', 'The process of developing AI systems should be transparent and respect user values, with ethics being present throughout the entire development pipeline.', 'An ethics approval board should be consulted before starting research projects, similar to institutional review boards used in universities for experiments.', 'Checkpoints for ethical review should be implemented at various stages of the development process to ensure ethical considerations are addressed before products are deployed.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Artificial Intelligence , Ethical , Computer Science', content='The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.\nIt mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.\nThe first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=0', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 0, 'start_sec': 0.0, 'end_ms': 87560, 'end_sec': 87.56, 'video_id': 230, 'segment_index': 1}, similarity_score=0.263, probability_score=0.0, summary=['The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.', 'It mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.', 'The first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.'])]
2025-10-20 20:23:23 | INFO | pipelines.chatbot |  [0, 1, 2, 3, 4]
2025-10-20 20:23:25 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='KI1_[21S] (Artificial Intelligence 1)', section_title='Also , Haben , Deep Learning', content='Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible when an autonomous vehicle causes an accident.\nThere are concerns about bias in AI systems, particularly in job applications, where machine learning may evaluate candidates based on potentially biased criteria.\nThe development of autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.\nThere are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like image selection algorithms on social media platforms.', last_edit_date=None, url='https://faiss.local/audio/175#t=4630', num_tokens=0, block_metadata={'language': 'de', 'index_name': 'audio', 'course_name': 'KI1_[21S]', 'course_term': '2022 SS', 'start_ms': 4630520, 'start_sec': 4630.52, 'end_ms': 4899840, 'end_sec': 4899.84, 'video_id': 175, 'segment_index': 65}, similarity_score=0.265, probability_score=0.0, summary=['Ethical considerations in artificial intelligence include issues related to accountability, such as who is responsible when an autonomous vehicle causes an accident.', 'There are concerns about bias in AI systems, particularly in job applications, where machine learning may evaluate candidates based on potentially biased criteria.', 'The development of autonomous weapons raises significant ethical questions about allowing machines to make life-and-death decisions.', 'There are ongoing discussions about the implications of AI systems exhibiting racist or sexist biases, as seen in examples like image selection algorithms on social media platforms.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Hopefully Improve , Process Proposal , What Okay', content='Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.\nA notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.\nKey ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.\nThe discussion emphasizes the importance of an ethically guided development and research process for AI.', last_edit_date=None, url='https://faiss.local/audio/230#t=3325', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 3325500, 'start_sec': 3325.5, 'end_ms': 3527820, 'end_sec': 3527.82, 'video_id': 230, 'segment_index': 46}, similarity_score=0.238, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.', 'A notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.', 'Key ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.', 'The discussion emphasizes the importance of an ethically guided development and research process for AI.'])]
2025-10-20 20:23:29 | INFO | pipelines.chatbot |  [0, 1]
2025-10-20 20:23:31 | INFO | pipelines.chatbot |  [SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Hopefully Improve , Process Proposal , What Okay', content='Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.\nA notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.\nKey ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.\nThe discussion emphasizes the importance of an ethically guided development and research process for AI.', last_edit_date=None, url='https://faiss.local/audio/230#t=3325', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'audio', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 3325500, 'start_sec': 3325.5, 'end_ms': 3527820, 'end_sec': 3527.82, 'video_id': 230, 'segment_index': 46}, similarity_score=0.248, probability_score=0.0, summary=['Ethical considerations of artificial intelligence include the need for ongoing inspection of deployed machine learning models to prevent issues such as bias and discrimination.', 'A notable example is the Microsoft chatbot that became problematic due to retraining, highlighting the importance of regular reviews of AI systems.', 'Key ethical problems connected with AI include: automation, violation of privacy, fairness and algorithmic discrimination of minorities, bias, lack of transparency, lack of prior consent, e-propaganda (fake news), voice morphing and deepfakes, dual-use goods, and intelligent weapon systems.', 'The discussion emphasizes the importance of an ethically guided development and research process for AI.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Ethics , Product Development , Approval Board', content='Ethical considerations in AI should be proactive rather than reactive, meaning ethics should be built into the design process from the beginning.\nEthics should be the default setting in AI development, not an afterthought added later.\nThe process of developing AI systems should be transparent and respect user values, with ethics being present throughout the entire development pipeline.\nAn ethics approval board should be consulted before starting research projects, similar to institutional review boards used in universities for experiments.\nCheckpoints for ethical review should be implemented at various stages of the development process to ensure ethical considerations are addressed before products are deployed.', last_edit_date=None, url='https://faiss.local/gpt/230#t=2974', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'gpt', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 2974940, 'start_sec': 2974.94, 'end_ms': 3516220, 'end_sec': 3516.22, 'video_id': 230, 'segment_index': 15}, similarity_score=0.253, probability_score=0.0, summary=['Ethical considerations in AI should be proactive rather than reactive, meaning ethics should be built into the design process from the beginning.', 'Ethics should be the default setting in AI development, not an afterthought added later.', 'The process of developing AI systems should be transparent and respect user values, with ethics being present throughout the entire development pipeline.', 'An ethics approval board should be consulted before starting research projects, similar to institutional review boards used in universities for experiments.', 'Checkpoints for ethical review should be implemented at various stages of the development process to ensure ethical considerations are addressed before products are deployed.']), SearchResultBlock(document_title='Ethik_und_KI (Ethics and AI)', section_title='Artificial Intelligence , Ethical , Computer Science', content='The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.\nIt mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.\nThe first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.', last_edit_date=None, url='https://faiss.local/texttiling/230#t=0', num_tokens=0, block_metadata={'language': 'en', 'index_name': 'texttiling', 'course_name': 'Ethik_und_KI', 'course_term': '2023 SS', 'start_ms': 0, 'start_sec': 0.0, 'end_ms': 87560, 'end_sec': 87.56, 'video_id': 230, 'segment_index': 1}, similarity_score=0.254, probability_score=0.0, summary=['The passage discusses a survey of ethical problems related to artificial intelligence, highlighting that there are about 11 central ethical issues arising from AI and computer science.', 'It mentions the importance of understanding the ethical implications of artificial intelligence and proposes a more ethical development process.', 'The first ethical problem of artificial intelligence is noted as a fundamental issue that arises from computer science in general.'])]
2025-10-20 20:23:35 | INFO | pipelines.chatbot |  [0, 1, 2]
2025-10-20 20:58:46 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 20:58:46 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 20:59:00 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 20:59:09 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 20:59:14 | INFO | pipelines.chatbot | Search queries: [
  "ethical considerations of artificial intelligence",
  "AI ethics"
]
2025-10-20 20:59:37 | INFO | pipelines.chatbot |  The ethical considerations of artificial intelligence encompass a wide range of topics. Key issues include algorithmic biases, fairness, accountability, privacy, and the regulation of AI systems. For instance, machine learning algorithms can be biased if the training data contains hidden prejudices, which may lead to discrimination in areas such as employment and justice [1][2]. 

Accountability is another significant concern, particularly regarding who is responsible for the actions of autonomous systems, like self-driving vehicles. This raises questions about whether the responsibility lies with the developers, users, or the AI itself [2][5]. 

Privacy and data security are critical issues as well, given that AI systems often process large datasets that may include personal and sensitive information. This can lead to unauthorized data access and privacy violations, contributing to a potential surveillance society [7][9]. 

Moreover, the implications of AI in the workplace include job insecurity and the potential for technological unemployment, which can create stress and anxiety among workers [9][10]. 

Overall, the ethical landscape of AI is complex and requires careful consideration of these various factors to ensure responsible development and deployment of AI technologies [1][2][6].
2025-10-20 21:21:00 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 21:21:00 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 21:21:12 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:21:34 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:21:38 | INFO | pipelines.chatbot | Search queries: [
  "ethical considerations of artificial intelligence",
  "AI ethics"
]
2025-10-20 21:21:43 | INFO | pipelines.chatbot |  The ethical considerations of artificial intelligence encompass a wide range of topics. Key issues include algorithmic biases, fairness, accountability, privacy, and the regulation of AI systems. For instance, machine learning algorithms can be biased if the training data contains hidden prejudices, which may lead to discrimination in areas such as employment and justice [1][2]. 

Accountability is another significant concern, particularly regarding who is responsible for the actions of autonomous systems, like self-driving vehicles. This raises questions about whether the responsibility lies with the developers, users, or the AI itself [2][5]. 

Privacy and data security are critical issues as well, given that AI systems often process large datasets that may include personal and sensitive information. This can lead to unauthorized data access and privacy violations, contributing to a potential surveillance society [7][9]. 

Moreover, the implications of AI in the workplace include job insecurity and the potential for technological unemployment, which can create stress and anxiety among workers [9][10]. 

Overall, the ethical landscape of AI is complex and requires careful consideration of these various factors to ensure responsible development and deployment of AI technologies [1][2][6].
2025-10-20 21:41:06 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:42:20 | INFO | pipelines.chatbot | Search queries: [
  "What is Artificial Intelligence?",
  "Definition of Artificial Intelligence",
  "Types of Artificial Intelligence",
  "Applications of Artificial Intelligence"
]
2025-10-20 21:42:33 | INFO | pipelines.chatbot |  Artificial Intelligence (AI) is a branch of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence. This includes abilities such as language understanding, reasoning, problem-solving, and learning from experience [1][2]. AI systems can be designed to perceive their environment and take actions that maximize their chances of success, functioning as intelligent agents [2].

AI encompasses various techniques and approaches, including machine learning, natural language processing, and robotics. Machine learning allows systems to improve their performance over time by learning from data, while natural language processing enables computers to understand and interact with human languages [6][9]. Robotics involves designing machines that can perform physical tasks, integrating AI with sensors and mechanical systems [6].

The field of AI also explores different types of intelligence, such as systems that think and act like humans, and those that think and act rationally [7]. One of the more theoretical concepts in AI is Artificial General Intelligence (AGI), which refers to machines that can understand and adapt to a wide range of tasks autonomously, similar to human intelligence [8]. AI has applications across various domains, including healthcare, finance, and robotics, and is increasingly integrated into everyday technologies [10].
2025-10-20 21:43:48 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:45:47 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 21:45:47 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 21:45:58 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:46:03 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:46:09 | INFO | pipelines.chatbot | Search queries: [
  "ethical considerations of AI",
  "AI ethics"
]
2025-10-20 21:53:42 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:53:46 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:55:04 | DEBUG | tasks.main | Redis server is already running.
2025-10-20 21:55:04 | DEBUG | tasks.main | Loaded API key named OPENAI_API_KEY
2025-10-20 21:55:13 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia in 25 Languages'
2025-10-20 21:57:07 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-20 21:57:28 | INFO | pipelines.chatbot | Search queries: [
  "A* Algorithm explanation",
  "A* Algorithm how it works"
]
2025-10-21 01:14:09 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 02:46:13 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 02:46:47 | INFO | pipelines.chatbot | Search queries: [
  "ethical issues related to AI",
  "AI ethics concerns"
]
2025-10-21 02:49:05 | INFO | pipelines.chatbot | Search queries: [
  "A* algorithm explanation",
  "A* search algorithm",
  "A* algorithm in computer science"
]
2025-10-21 02:52:57 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 02:53:00 | INFO | pipelines.chatbot | Search queries: [
  "ethical considerations of AI",
  "AI ethics"
]
2025-10-21 02:54:27 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 02:54:29 | INFO | pipelines.chatbot | Search queries: [
  "What is Artificial Intelligence?",
  "Definition of Artificial Intelligence",
  "Artificial Intelligence overview"
]
2025-10-21 02:55:34 | INFO | pipelines.chatbot | Search queries: [
  "intelligent weapons artificial intelligence",
  "autonomous weapons systems AI"
]
2025-10-21 02:59:34 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 03:01:56 | INFO | pipelines.chatbot | Search queries: [
  "paper ethics by design",
  "ethics by design process introduction"
]
2025-10-21 05:28:48 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 09:26:23 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 12:16:14 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
2025-10-21 18:39:16 | DEBUG | backend_server.py | Using corpus with name 'Wikipedia + University Lectures'
